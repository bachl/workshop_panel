@Article{bellExplainingFixedEffects2015,
  title = {Explaining Fixed Effects: {{Random}} Effects Modeling of Time-Series Cross-Sectional and Panel Data},
  shorttitle = {Explaining {{Fixed Effects}}},
  author = {Andrew Bell and Kelvyn Jones},
  year = {2015},
  month = {jan},
  volume = {3},
  pages = {133--153},
  publisher = {{Cambridge University Press}},
  issn = {2049-8470, 2049-8489},
  doi = {10.1017/psrm.2014.7},
  abstract = {This article challenges Fixed Effects (FE) modeling as the `default' for time-series-cross-sectional and panel data. Understanding different within and between effects is crucial when choosing modeling strategies. The downside of Random Effects (RE) modeling\textemdash{}correlated lower-level covariates and higher-level residuals\textemdash{}is omitted-variable bias, solvable with Mundlak's (1978a) formulation. Consequently, RE can provide everything that FE promises and more, as confirmed by Monte-Carlo simulations, which additionally show problems with Pl{\"u}mper and Troeger's FE Vector Decomposition method when data are unbalanced. As well as incorporating time-invariant variables, RE models are readily extendable, with random coefficients, cross-level interactions and complex variance functions. We argue not simply for technical solutions to endogeneity, but for the substantive importance of context/heterogeneity, modeled using RE. The implications extend beyond political science to all multilevel datasets. However, omitted variables could still bias estimated higher-level variable effects; as with any model, care is required in interpretation.},
  file = {/Users/markobachl/Zotero/storage/LUVEBVBQ/Bell und Jones - 2015 - Explaining Fixed Effects Random Effects Modeling .pdf;/Users/markobachl/Zotero/storage/5SXS9HQC/0334A27557D15848549120FE8ECD8D63.html},
  journal = {Political Science Research and Methods},
  language = {en},
  number = {1},
}

@Article{vaiseyWhatYouCan2017,
  title = {What You Can\textemdash{}and Can't\textemdash{}Do with Three-Wave Panel Data},
  author = {Stephen Vaisey and Andrew Miles},
  year = {2017},
  month = {jan},
  volume = {46},
  pages = {44--67},
  issn = {0049-1241, 1552-8294},
  doi = {10.1177/0049124114547769},
  abstract = {The recent change in the general social survey (GSS) to a rotating panel design is a landmark development for social scientists. Sociological methodologists have argued that fixed-effects (FE) models are generally the best starting point for analyzing panel data because they allow analysts to control for unobserved time-constant heterogeneity. We review these treatments and demonstrate the advantages of FE models in the context of the GSS. We also show, however, that FE models have two rarely tested assumptions that can seriously bias parameter estimates when violated. We provide simple tests for these assumptions. We further demonstrate that FE models are extremely sensitive to the correct specification of temporal lags. We provide a simulation and a proof to show that the use of incorrect lags in FE models can lead to coefficients that are the opposite sign of the true parameter values.},
  file = {/Users/markobachl/Zotero/storage/SSZJI8DQ/Vaisey und Miles - 2017 - What You Can—and Can’t—Do With Three-Wave Panel Da.pdf},
  journal = {Sociological Methods \& Research},
  language = {en},
  number = {1},
}
@Article{kingHowRobustStandard2015,
  title = {How {{Robust Standard Errors Expose Methodological Problems They Do Not Fix}}, and {{What}} to {{Do About It}}},
  author = {Gary King and Margaret E. Roberts},
  year = {2015},
  volume = {23},
  pages = {159--179},
  publisher = {{Cambridge University Press}},
  issn = {1047-1987, 1476-4989},
  doi = {10.1093/pan/mpu015},
  abstract = {``Robust standard errors'' are used in a vast array of scholarship to correct standard errors for model misspecification. However, when misspecification is bad enough to make classical and robust standard errors diverge, assuming that it is nevertheless not so bad as to bias everything else requires considerable optimism. And even if the optimism is warranted, settling for a misspecified model, with or without robust standard errors, will still bias estimators of all but a few quantities of interest. The resulting cavernous gap between theory and practice suggests that considerable gains in applied statistics may be possible. We seek to help researchers realize these gains via a more productive way to understand and use robust standard errors; a new general and easier-to-use ``generalized information matrix test'' statistic that can formally assess misspecification (based on differences between robust and classical variance estimates); and practical illustrations via simulations and real examples from published research. How robust standard errors are used needs to change, but instead of jettisoning this popular tool we show how to use it to provide effective clues about model misspecification, likely biases, and a guide to considerably more reliable, and defensible, inferences. Accompanying this article is software that implements the methods we describe.},
  file = {/Users/markobachl/Zotero/storage/ZYKSSNWN/King und Roberts - 2015 - How Robust Standard Errors Expose Methodological P.pdf;/Users/markobachl/Zotero/storage/7LQNUNFL/7E2F393B16FC6BCD6DA8C19D8D5D1F6B.html},
  journal = {Political Analysis},
  language = {en},
  number = {2},
}
@Article{keeleCausalInterpretationEstimated2019,
  title = {The Causal Interpretation of Estimated Associations in Regression Models},
  author = {Luke Keele and Randolph T. Stevenson and Felix Elwert},
  year = {2019},
  pages = {1--13},
  issn = {2049-8470},
  doi = {10.1017/psrm.2019.31},
  abstract = {A common causal identification strategy in political science is selection on observables. This strategy assumes one observes a set of covariates that is, after statistical adjustment, sufficient to make treatment status as-if random. Under adjustment methods such as matching or inverse probability weighting, coefficients for control variables are treated as nuisance parameters and are not directly estimated. This is in direct contrast to regression approaches where estimated parameters are obtained for all covariates. Analysts often find it tempting to give a causal interpretation to all the parameters in such regression models\textemdash{}indeed, such interpretations are often central to the proposed research design. In this paper, we ask when we can justify interpreting two or more coefficients in a regression model as causal parameters. We demonstrate that analysts must appeal to causal identification assumptions to give estimates causal interpretations. Under selection on observables, this task is complicated by the fact that more than one causal effect might be identified. We show how causal graphs provide a framework for clearly delineating which effects are presumed to be identified and thus merit a causal interpretation, and which are not. We conclude with a set of recommendations for how researchers should interpret estimates from regression models when causal inference is the goal.},
  file = {/Users/markobachl/Zotero/storage/PJZL8FDL/causal_interpretation_of_estimated_association.pdf},
  journal = {Political Science Research and Methods},
  keywords = {Causal inference},
}
@book{wooldridge10,
	Author = {Wooldridge, Jeffrey M},
	Date-Added = {2017-10-23 20:25:39 +0000},
	Date-Modified = {2017-10-23 20:25:40 +0000},
	Publisher = {MIT press},
	Title = {Econometric analysis of cross section and panel data},
	Year = {2010}}@Book{gelmanDataAnalysisUsing2006,
  title = {Data Analysis Using Regression and Multilevel/Hierarchical Models},
  author = {A. Gelman and J. Hill},
  year = {2006},
  publisher = {{Cambridge University Press}},
  address = {{New York}},
  file = {/Users/markobachl/Zotero/storage/JY6IGG2X/[Andrew_Gelman,_Jennifer_Hill]_Data_Analysis_Using(Bookos.org).pdf},
  isbn = {0-521-86706-1},
}
