<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Abschnitt 4 Random effects Modelle | Mini-Workshop Panel Data Analysis</title>
  <meta name="description" content="Material für den Mini-Workshop Panel Data Analysis" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="Abschnitt 4 Random effects Modelle | Mini-Workshop Panel Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Material für den Mini-Workshop Panel Data Analysis" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Abschnitt 4 Random effects Modelle | Mini-Workshop Panel Data Analysis" />
  
  <meta name="twitter:description" content="Material für den Mini-Workshop Panel Data Analysis" />
  

<meta name="author" content="Marko Bachl (mit Material von Michael Scharkow)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="fixed-effects-modelle.html"/>
<link rel="next" href="hybride-within-between-modelle.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Panel Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Überblick</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#inhalt-des-virtuellen-mini-workshops"><i class="fa fa-check"></i><b>1.1</b> Inhalt des virtuellen Mini-Workshops</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#welche-inhalte-wir-nicht-behandeln"><i class="fa fa-check"></i><b>1.2</b> Welche Inhalte wir nicht behandeln</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#aufbau-des-workshops"><i class="fa fa-check"></i><b>1.3</b> Aufbau des Workshops</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="einführung.html"><a href="einführung.html"><i class="fa fa-check"></i><b>2</b> Einführung</a><ul>
<li class="chapter" data-level="2.1" data-path="einführung.html"><a href="einführung.html#längsschnittdaten"><i class="fa fa-check"></i><b>2.1</b> Längsschnittdaten</a></li>
<li class="chapter" data-level="2.2" data-path="einführung.html"><a href="einführung.html#beispiel-daten"><i class="fa fa-check"></i><b>2.2</b> Beispiel-Daten</a></li>
<li class="chapter" data-level="2.3" data-path="einführung.html"><a href="einführung.html#pooled-ols-wrong"><i class="fa fa-check"></i><b>2.3</b> Pooled OLS (WRONG!)</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html"><i class="fa fa-check"></i><b>3</b> Fixed effects Modelle</a><ul>
<li class="chapter" data-level="3.1" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html#konzeptionelle-einführung"><i class="fa fa-check"></i><b>3.1</b> Konzeptionelle Einführung</a></li>
<li class="chapter" data-level="3.2" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html#übungsaufgaben-1"><i class="fa fa-check"></i><b>3.2</b> Übungsaufgaben 1</a></li>
<li class="chapter" data-level="3.3" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html#fixed-effects-modelle-in-der-praktischen-anwendung"><i class="fa fa-check"></i><b>3.3</b> <em>Fixed effects</em> Modelle in der praktischen Anwendung</a></li>
<li class="chapter" data-level="3.4" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html#zusammenfassung-vor--und-nachteile-des-fixed-effects-modells"><i class="fa fa-check"></i><b>3.4</b> Zusammenfassung: Vor- und Nachteile des <em>fixed effects</em> Modells</a></li>
<li class="chapter" data-level="3.5" data-path="fixed-effects-modelle.html"><a href="fixed-effects-modelle.html#übungsaufgaben-2"><i class="fa fa-check"></i><b>3.5</b> Übungsaufgaben 2</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html"><i class="fa fa-check"></i><b>4</b> <em>Random effects</em> Modelle</a><ul>
<li class="chapter" data-level="4.1" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#einführung-random-effects-modelle-für-paneldaten"><i class="fa fa-check"></i><b>4.1</b> Einführung: Random effects Modelle für Paneldaten</a></li>
<li class="chapter" data-level="4.2" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#random-effects-modelle-mit-plm"><i class="fa fa-check"></i><b>4.2</b> Random effects Modelle mit <code>plm</code></a></li>
<li class="chapter" data-level="4.3" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#kurze-einführung-zu-mixed-effects-modellen"><i class="fa fa-check"></i><b>4.3</b> Kurze Einführung zu mixed effects Modellen</a></li>
<li class="chapter" data-level="4.4" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#übungsaufgaben-3"><i class="fa fa-check"></i><b>4.4</b> Übungsaufgaben 3</a></li>
<li class="chapter" data-level="4.5" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#random-effects-panel-modelle-mit-lme4"><i class="fa fa-check"></i><b>4.5</b> Random effects panel Modelle mit <code>lme4</code></a></li>
<li class="chapter" data-level="4.6" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#übungsaufgaben-4"><i class="fa fa-check"></i><b>4.6</b> Übungsaufgaben 4</a></li>
<li class="chapter" data-level="4.7" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#variierende-koeffizienten-random-slopes-und-ebenen-überschreitende-interaktionen-cross-level-interactions"><i class="fa fa-check"></i><b>4.7</b> Variierende Koeffizienten (random slopes) und Ebenen-überschreitende Interaktionen (cross-level interactions)</a></li>
<li class="chapter" data-level="4.8" data-path="random-effects-modelle.html"><a href="random-effects-modelle.html#übungsaufgaben-5"><i class="fa fa-check"></i><b>4.8</b> Übungsaufgaben 5</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="hybride-within-between-modelle.html"><a href="hybride-within-between-modelle.html"><i class="fa fa-check"></i><b>5</b> Hybride <em>within-between</em> Modelle</a><ul>
<li class="chapter" data-level="5.1" data-path="hybride-within-between-modelle.html"><a href="hybride-within-between-modelle.html#das-beste-aus-beiden-welten"><i class="fa fa-check"></i><b>5.1</b> Das Beste aus beiden Welten?</a></li>
<li class="chapter" data-level="5.2" data-path="hybride-within-between-modelle.html"><a href="hybride-within-between-modelle.html#spezifikation-des-within-between-modells"><i class="fa fa-check"></i><b>5.2</b> Spezifikation des <em>within-between</em> Modells</a></li>
<li class="chapter" data-level="5.3" data-path="hybride-within-between-modelle.html"><a href="hybride-within-between-modelle.html#übungsaufgaben-6"><i class="fa fa-check"></i><b>5.3</b> Übungsaufgaben 6</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="literatur.html"><a href="literatur.html"><i class="fa fa-check"></i>Literatur</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Mini-Workshop Panel Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="random-effects-modelle" class="section level1">
<h1><span class="header-section-number">Abschnitt 4</span> <em>Random effects</em> Modelle</h1>
<ul>
<li>In diesem Abschnitt beschäftigen wir uns mit <em>random effects</em> Modellen. Zuerst führen wir die Modellklasse ein. Dann betrachten wir kurz, wie die Modelle in der Tradition der Ökonometrie mit <code>plm</code> spezifiziert werden können, bevor wir zur allgemeineren Umsetzung mit dem Paket für Mehrebenen- bzw. <em>mixed effects</em> Modelle <code>lme4</code> kommen.</li>
</ul>
<div id="einführung-random-effects-modelle-für-paneldaten" class="section level2">
<h2><span class="header-section-number">4.1</span> Einführung: Random effects Modelle für Paneldaten</h2>
<div id="modellspezifikation" class="section level3 unnumbered">
<h3>Modellspezifikation</h3>
<ul>
<li><p>Anstatt wie im <em>fixed effects</em> Modell für jede Einheit (Person) eine separate Konstante <span class="math inline">\(\alpha_i\)</span> zu schätzen, können wir einen “soft constraint” <span class="citation">(Gelman and Hill <a href="#ref-gelmanDataAnalysisUsing2006" role="doc-biblioref">2006</a>, S. 257)</span> setzen, dass die personenspezifischen Konstanten bzw. Residuen einer Verteilung folgen:</p>
<ul>
<li><span class="math inline">\(\alpha_{i} ∼ \mathcal{N}(\mu_{\alpha},\sigma^2_\alpha)\)</span> mit <span class="math inline">\(i = 1,...,n\)</span></li>
</ul></li>
<li><p>Das <em>random effects</em> Panel-Modell wird geschätzt als</p>
<ul>
<li><span class="math inline">\(y_{it}=x_{it}&#39;\beta + z_i&#39;\gamma + v_{it}\)</span></li>
<li><span class="math inline">\(v_{it} = \alpha_{i} + u_{it}\)</span></li>
<li>mit <span class="math inline">\(y_{it}\)</span> über Personen (<span class="math inline">\(i\)</span>) und Zeit (<span class="math inline">\(t\)</span>) variierendes Kriterium, <span class="math inline">\(x_{it}&#39;\)</span> über Personen und Zeit variierende Prädiktoren, <span class="math inline">\(\beta\)</span> Koeffizienten der über Personen und Zeit variierenden Prädiktoren, <span class="math inline">\(z_i&#39;\)</span> über Personen variierende Prädiktoren, <span class="math inline">\(\gamma\)</span> Koeffizienten der über Personen variierenden Prädiktoren, <span class="math inline">\(v_{it}\)</span> gesamter Fehlerterm, <span class="math inline">\(\alpha_{i}\)</span> personenspezifische Konstanten, <span class="math inline">\(u_{it}\)</span> Residuen.</li>
</ul></li>
<li><p>Damit die Schätzer für <span class="math inline">\(\beta&#39;\)</span> unverzerrt sind, müssen zwei Annahmen erfüllt sein:</p>
<ol style="list-style-type: decimal">
<li>Keine über die Zeit konstante Heterogenität, deren Ursache nicht im Modell ist</li>
</ol>
<ul>
<li><span class="math inline">\({\displaystyle \operatorname {E} (\alpha _{i}|x_{it})=\operatorname {E} (\alpha _{i})=0}\)</span></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Keine über die Zeit variierende Heterogenität, deren Ursache nicht im Modell ist</li>
</ol>
<ul>
<li><span class="math inline">\({\displaystyle \operatorname {E} (u_{it}|x_{it},\alpha _{i})=0,\quad t=1,...,T.}\)</span></li>
</ul></li>
</ul>
</div>
<div id="vorteile-der-random-effects-modelle-für-panel-daten" class="section level3 unnumbered">
<h3>Vorteile der <em>random effects</em> Modelle für Panel-Daten</h3>
<ul>
<li>Schätzer für über die Zeit konstante Prädiktoren und gleichzeitig Konstante für jede Person.</li>
<li>Schätzer von über die Zeit variierenden und über die Zeit konstanten Prädiktoren können verglichen werden.</li>
<li>Vorhersagen für neue Personen außerhalb der Stichprobe können unter Einbeziehung aller Informationen und unter Berücksichtigung der gesamten Unsicherheit gemacht werden.</li>
<li>Die Annahme homogener Treatment-Effekte kann gelockert werden.</li>
</ul>
</div>
<div id="sind-die-annahmen-des-random-effects-modell-für-paneldaten-jemals-erfüllt" class="section level3 unnumbered">
<h3>Sind die Annahmen des <em>random effects</em> Modell für Paneldaten jemals erfüllt?</h3>
<blockquote>
<p>The only difference between RE and FE lies in the assumption they make about the relationship between υ and the observed predictors: RE models assume that the observed predictors in the model are not correlated with <span class="math inline">\(v\)</span> while FE models allow them to be correlated.</p>
</blockquote>
<blockquote>
<p>A moment’s reflection on what <span class="math inline">\(v\)</span> represents—-all unmeasured time-constant factors about the respondent—-should lead anyone to realize that the RE assumption is heroic in social research, to say the least.</p>
</blockquote>
<blockquote>
<p>The idea that the characteristics we don’t (or can’t) measure (like personality or genetic influences) are uncorrelated with the things we usually do measure (like income or church attendance) is implausible. — <span class="citation">Vaisey and Miles (<a href="#ref-vaiseyWhatYouCan2017" role="doc-biblioref">2017</a>)</span>, S. 47</p>
</blockquote>
</div>
<div id="hausman-test" class="section level3 unnumbered">
<h3>Hausman-Test</h3>
<ul>
<li>Der Hausman-Test prüft, ob das <em>random effects</em> Modell konsistent ist.</li>
<li>Nach der traditionellen Sichtweise der Ökonometrie spricht das Verwerfen der <span class="math inline">\(H_0\)</span> im Hausman-Test gegen das Schätzen eines <em>random effects</em> Modells.</li>
<li>Da das <em>random effects</em> Modell in der Lage ist, Forschungsfragen zu beantworten, an denen das <em>fixed effects</em> Modell per Definition scheitert, lässt sich die Wahl des <em>random effects</em> Modells auch inhaltlich begründen — ohne einen Hausman-Test durchzuführen <span class="citation">(Bell, Fairbrother, and Jones <a href="#ref-bellFixedRandomEffects2019" role="doc-biblioref">2019</a>)</span>.</li>
<li>Der Hausman-Test kann mit der Funktion <code>plm::phtest()</code> durchgeführt werden.</li>
</ul>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="random-effects-modelle.html#cb37-1"></a><span class="kw">phtest</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1, <span class="dt">data =</span> d, <span class="dt">index =</span> <span class="st">&quot;IDsosci&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Hausman Test
## 
## data:  verh1 ~ verhint1
## chisq = 301, df = 1, p-value &lt;2e-16
## alternative hypothesis: one model is inconsistent</code></pre>
<ul>
<li>In diesem Beispiel spricht der Hausman-Test dagegen, ein <em>random effects</em> Modell zu schätzen.</li>
</ul>
</div>
</div>
<div id="random-effects-modelle-mit-plm" class="section level2">
<h2><span class="header-section-number">4.2</span> Random effects Modelle mit <code>plm</code></h2>
<ul>
<li><em>Random effects</em> Modelle für Paneldaten in der ökonometrischen Tradition lassen sich mit <code>plm</code> schätzen. Die Schätzung erfolgt auf Basis von Transformationen im Least-squares-Framework (ich habe keine Ahnung, wie das funktioniert). Ich selbst nutze diese Funktionalität in der Praxis nicht. Die Modellspezifikationen sind im Folgenden der Vollständigkeit halber kurz aufgeführt.</li>
</ul>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="random-effects-modelle.html#cb39-1"></a><span class="co"># Einfaches RE Modell</span></span>
<span id="cb39-2"><a href="random-effects-modelle.html#cb39-2"></a><span class="kw">plm</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1, <span class="dt">data =</span> d, <span class="dt">index =</span> <span class="st">&quot;IDsosci&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;random&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## Oneway (individual) effect Random Effect Model 
##    (Swamy-Arora&#39;s transformation)
## 
## Call:
## plm(formula = verh1 ~ verhint1, data = d, model = &quot;random&quot;, index = &quot;IDsosci&quot;)
## 
## Balanced Panel: n = 576, T = 4, N = 2304
## 
## Effects:
##                  var std.dev share
## idiosyncratic 0.3206  0.5663  0.81
## individual    0.0744  0.2728  0.19
## theta: 0.28
## 
## Residuals:
##    Min. 1st Qu.  Median 3rd Qu.    Max. 
## -2.4448 -0.1055 -0.0727  0.0389  3.6473 
## 
## Coefficients:
##             Estimate Std. Error z-value Pr(&gt;|z|)    
## (Intercept)   0.5690     0.0276    20.6   &lt;2e-16 ***
## verhint1      0.5320     0.0120    44.5   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    1530
## Residual Sum of Squares: 823
## R-Squared:      0.463
## Adj. R-Squared: 0.462
## Chisq: 1981.77 on 1 DF, p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="random-effects-modelle.html#cb41-1"></a><span class="co"># Mit zusätzlichem Faktor Welle</span></span>
<span id="cb41-2"><a href="random-effects-modelle.html#cb41-2"></a><span class="kw">plm</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1, <span class="dt">data =</span> d, <span class="dt">index =</span> <span class="kw">c</span>(<span class="st">&quot;IDsosci&quot;</span>, <span class="st">&quot;wave&quot;</span>), <span class="dt">model =</span> <span class="st">&quot;random&quot;</span>, <span class="dt">effect =</span> <span class="st">&quot;twoways&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb41-3"><a href="random-effects-modelle.html#cb41-3"></a><span class="st">    </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## Twoways effects Random Effect Model 
##    (Swamy-Arora&#39;s transformation)
## 
## Call:
## plm(formula = verh1 ~ verhint1, data = d, effect = &quot;twoways&quot;, 
##     model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;))
## 
## Balanced Panel: n = 576, T = 4, N = 2304
## 
## Effects:
##                   var std.dev share
## idiosyncratic 0.31654 0.56262  0.80
## individual    0.07546 0.27470  0.19
## time          0.00263 0.05133  0.01
## theta: 0.285 (id) 0.585 (time) 0.254 (total)
## 
## Residuals:
##    Min. 1st Qu.  Median 3rd Qu.    Max. 
## -2.4799 -0.1144 -0.0697  0.0418  3.6722 
## 
## Coefficients:
##             Estimate Std. Error z-value Pr(&gt;|z|)    
## (Intercept)   0.5724     0.0390    14.7   &lt;2e-16 ***
## verhint1      0.5301     0.0121    43.7   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    1490
## Residual Sum of Squares: 817
## R-Squared:      0.453
## Adj. R-Squared: 0.453
## Chisq: 1906.68 on 1 DF, p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="random-effects-modelle.html#cb43-1"></a><span class="co"># Mit FE für Welle</span></span>
<span id="cb43-2"><a href="random-effects-modelle.html#cb43-2"></a><span class="kw">plm</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave), <span class="dt">data =</span> d, <span class="dt">index =</span> <span class="st">&quot;IDsosci&quot;</span>, <span class="dt">model =</span> <span class="st">&quot;random&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb43-3"><a href="random-effects-modelle.html#cb43-3"></a><span class="st">    </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## Oneway (individual) effect Random Effect Model 
##    (Swamy-Arora&#39;s transformation)
## 
## Call:
## plm(formula = verh1 ~ verhint1 + factor(wave), data = d, model = &quot;random&quot;, 
##     index = &quot;IDsosci&quot;)
## 
## Balanced Panel: n = 576, T = 4, N = 2304
## 
## Effects:
##                  var std.dev share
## idiosyncratic 0.3165  0.5626  0.81
## individual    0.0755  0.2747  0.19
## theta: 0.285
## 
## Residuals:
##    Min. 1st Qu.  Median 3rd Qu.    Max. 
## -2.5049 -0.1345 -0.0672  0.0510  3.6936 
## 
## Coefficients:
##               Estimate Std. Error z-value Pr(&gt;|z|)    
## (Intercept)    0.56642    0.03306   17.13   &lt;2e-16 ***
## verhint1       0.53001    0.01219   43.49   &lt;2e-16 ***
## factor(wave)2 -0.04533    0.03534   -1.28    0.200    
## factor(wave)3  0.06729    0.03539    1.90    0.057 .  
## factor(wave)4  0.00283    0.03580    0.08    0.937    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    1520
## Residual Sum of Squares: 817
## R-Squared:      0.463
## Adj. R-Squared: 0.462
## Chisq: 1983.94 on 4 DF, p-value: &lt;2e-16</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="random-effects-modelle.html#cb45-1"></a><span class="co"># Mit Prädiktor auf Personenebene (funktioniert nicht in FE, siehe oben)</span></span>
<span id="cb45-2"><a href="random-effects-modelle.html#cb45-2"></a><span class="kw">plm</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span>C_sex, <span class="dt">data =</span> d, <span class="dt">index =</span> <span class="kw">c</span>(<span class="st">&quot;IDsosci&quot;</span>, <span class="st">&quot;wave&quot;</span>), <span class="dt">model =</span> <span class="st">&quot;random&quot;</span>, </span>
<span id="cb45-3"><a href="random-effects-modelle.html#cb45-3"></a>    <span class="dt">effect =</span> <span class="st">&quot;twoways&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## Twoways effects Random Effect Model 
##    (Swamy-Arora&#39;s transformation)
## 
## Call:
## plm(formula = verh1 ~ verhint1 + C_sex, data = d, effect = &quot;twoways&quot;, 
##     model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;))
## 
## Balanced Panel: n = 576, T = 4, N = 2304
## 
## Effects:
##                   var std.dev share
## idiosyncratic 0.31654 0.56262  0.80
## individual    0.07478 0.27347  0.19
## time          0.00263 0.05133  0.01
## theta: 0.283 (id) 0.585 (time) 0.253 (total)
## 
## Residuals:
##    Min. 1st Qu.  Median 3rd Qu.    Max. 
## -2.4432 -0.1535 -0.0481  0.0479  3.7019 
## 
## Coefficients:
##             Estimate Std. Error z-value Pr(&gt;|z|)    
## (Intercept)   0.6420     0.0455    14.1   &lt;2e-16 ***
## verhint1      0.5276     0.0122    43.4   &lt;2e-16 ***
## C_sex        -0.1066     0.0356    -3.0   0.0027 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    1500
## Residual Sum of Squares: 815
## R-Squared:      0.456
## Adj. R-Squared: 0.455
## Chisq: 1927.32 on 2 DF, p-value: &lt;2e-16</code></pre>
</div>
<div id="kurze-einführung-zu-mixed-effects-modellen" class="section level2">
<h2><span class="header-section-number">4.3</span> Kurze Einführung zu mixed effects Modellen</h2>
<ul>
<li><p>Auch bekannt als <em>random effects</em>, <em>multilevel</em>/<em>Mehrebenen-</em> oder <em>hierarchical</em>/<em>hierarchische</em> Modelle; das Begriffswirrwarr ist ein großes Problem <span class="citation">(Gelman and Hill <a href="#ref-gelmanDataAnalysisUsing2006" role="doc-biblioref">2006</a>)</span>, das Denglisch macht es nicht besser.</p>
<ul>
<li>siehe auch: <a href="https://twitter.com/chelseaparlett/status/1262390299785072647" class="uri">https://twitter.com/chelseaparlett/status/1262390299785072647</a></li>
</ul></li>
<li><p>Wer mit diesen Modellen bereits vertraut ist, kann diesen Absatz überspringen.</p></li>
<li><p>Ganz allgemein gesprochen sind <em>mixed effects</em> Modelle Regressionsmodelle für Beobachtungen von Einheiten, die in irgendeiner Art miteinander zu tun haben, also nicht unabhängig voneinander sind.</p></li>
<li><p>Typische Beispiele sind Schüler*innen in Klassen in Schulen, Patient*innen in Krankenhäusern, Wähler*innen in Wahlkreisen, … .</p></li>
<li><p>Paneldaten haben immer eine hierarchische Struktur: Beobachtungen (Level 1) sind innerhalb der Personen (Level 2) gruppiert.</p></li>
<li><p>Die Bezeichnung <em>mixed effects</em> geht darauf zurück, dass in den Modellen sowohl <em>random effects</em> (Koeffizienten, die zwischen den Fällen innerhalb einer Gruppierung auf einer höheren Ebene variieren) als auch <em>fixed effects</em> (Koeffizienten, die für alle Fälle gleich sind) spezifiziert werden.</p></li>
</ul>
<div id="warum-wir-in-den-sozialwissenschaften-nicht-nur-die-traditionellen-ökonometrischen-modelle-verwenden" class="section level3 unnumbered">
<h3>Warum wir in den Sozialwissenschaften nicht nur die traditionellen ökonometrischen Modelle verwenden</h3>
<blockquote>
<p>Econometrics deal mostly with non-experimental data. Great emphasis is put on specification procedures and misspecification testing. Model specifications tend therefore to be very simple, while great attention is put on the issues of endogeneity of the regressors, dependence structures in the errors and robustness of the estimators under deviations from normality. — <span class="citation">Croissant and Millo (<a href="#ref-plm2008" role="doc-biblioref">2008</a>)</span></p>
</blockquote>
<ul>
<li><p>Historische Gründe und disziplinäre Entwicklungen: z.B. Ökonometriker*innen bevorzugen fast immer Least Squares, andere Disziplinen Maximum Likelihood oder Bayesianische Methoden.</p></li>
<li><p>Viele Sozialwissenschaften haben kompliziertere Datenstrukturen als das typische ökonometrische Panel, z.B. mehr als zwei Ebenen, nicht-hierarchische Datenstrukturen, heterogene Treatment-Effekte, … . Die flexible Modellierung solcher Strukturen gilt oft als wichtiger als die enger gefassten Schätz- und Identifikationsfragen, die die Ökonometrie umtreibt.</p></li>
<li><p>Die Ökonometrie betrachtet Abhängigkeitsstrukturen als eine Störgröße, deren Einfluss in den Modellen beschränkt werden soll. Andere sozialwissenschaftliche Disziplinen interessieren sich (auch, gerade) für diese Strukturen und ihre Konsequenzen.</p></li>
</ul>
</div>
<div id="vorteile-der-mixed-effects-modelle" class="section level3">
<h3><span class="header-section-number">4.3.1</span> Vorteile der <em>mixed effects</em> Modelle</h3>
<ul>
<li><p><em>Mixed effects</em> Modelle bieten einen einheitlichen Rahmen für die Modellierung von Datensätzen mit jeder Art von Abhängigkeitsstrukturen, seien sie hierarchisch, längsschnittlich oder eine Kombination aus beidem.</p></li>
<li><p>Die Schätzung basiert auf (Restricted) Maximum Likelihood, der Umstieg auf bayesianische Schätzmethoden ist relativ einfach. Im Vergleich dazu erfordern die Optionen, Tests und transformationsbasierten Least-Squares-Schätzer in der ökonometrischen Tradition erheblich mehr Einarbeitung, wenn man nicht auf eine entsprechende Ausbildung aufbauen kann.</p></li>
<li><p>Wer die Logik von <em>mixed effects</em> Modellen einmal verstanden hat, kann die Modelle für verschiedenste Forschungsfragen und -desings einsetzen, u.a. Ländervergleiche in der komparativen Forschung, experimentelle within-subject Desings, verschiedene Längsschnittsdesigns wie experience sampling, Tagebücher, digitale Kommunikations- und Verhaltensspuren (z.B. Kommentare zu Posts auf Social Media Plattformen), … Mehrebenenstrukturen sind überall.</p></li>
<li><p>Das Denken in Varianzkomponenten (siehe nächster Absatz) hilft uns, konzeptionell über die Bedeutung von Prädiktoren auf verschiedenen Ebenen nachzudenken.</p></li>
<li><p>Einfache praktische Umsetzung: Das Paket <code>lme4</code> ist einfach zu verwenden, wenn man bereits etwas Erfahrung mit <code>stats::lm()</code> hat, und auch ein guter Einstieg in ähnlich aufgebaute Pakte zur bayesianischen Schätzung solcher Modelle (z.B. <code>rstanarm</code>, <code>brms</code>).</p></li>
</ul>
</div>
<div id="varianzdekomposition-und-intraklassen-korrelation" class="section level3 unnumbered">
<h3>Varianzdekomposition und Intraklassen-Korrelation</h3>
<ul>
<li><p>Wir interessieren uns dafür, welcher Anteil in der Varianz in <span class="math inline">\(Y\)</span> auf stabile Unterschiede zwischen den Personen zurück geht und welcher auf Veränderungen innerhalb von Personen (potentielle kausale Effekte).</p></li>
<li><p>In <em>mixed effects</em> Modellen können wir die Varianz-Anteile in einem so genannten Null-Modell, das nur die Struktur der Daten abbildet, aber keine Prädiktoren enthält, bestimmen:</p>
<ul>
<li><span class="math inline">\(y_{it}= \alpha + v_{it}\)</span> und <span class="math inline">\(v_{it} = \alpha_{i}+ u_{it}\)</span></li>
</ul></li>
<li><p>Ohne die Konstante <span class="math inline">\(\alpha\)</span> erhalten wir</p>
<ul>
<li><span class="math inline">\(y_{it} = \alpha_{i}+ u_{it}\)</span></li>
</ul></li>
<li><p>Da die Varianzen von <span class="math inline">\(\alpha_i\)</span> und <span class="math inline">\(u_{it}\)</span> im Modell geschätzt werden, können wir den Anteil der personenspezifischen (Level 2) Varianz und den Anteil der idiosynkratischen Varianz in <span class="math inline">\(Y\)</span> berechnen. Der Anteil der Level 2 Varianz an der gesamten Varianz wird auch als Intraklassen-Korrelation (intra-class correlation, ICC, <span class="math inline">\(\rho\)</span>) bezeichnet.</p></li>
<li><p>In unserem Beispiel möchten wir wissen, welcher Anteil der Varianz im Verlassen der Wohnung ohne triftigen Grund auf konstante Unterschiede zwischen den Personen zurückgeht (manche Personen wollen oder müssen, aus welchen Gründen auch immer, die Wohnung häufiger verlassen als andere).</p></li>
<li><p>Dazu spezifizieren wir das Null-Modell mit <code>lme4::lmer()</code>. Das genaue Vorgehen beim Spezifizieren der Modelle folgt im nächsten Abschnitt. Wichtig ist an dieser Stelle, dass mit <code>(1 | IDsosci)</code> jede Person eine eigene Konstante erhält (<span class="math inline">\(\alpha_i\)</span> in der Gleichung oben), die als Abweichung vom Gesamtmittel (<span class="math inline">\(\alpha\)</span>) geschätzt wird.</p></li>
</ul>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="random-effects-modelle.html#cb47-1"></a><span class="co"># Null-Modell</span></span>
<span id="cb47-2"><a href="random-effects-modelle.html#cb47-2"></a>m0 =<span class="st"> </span><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb47-3"><a href="random-effects-modelle.html#cb47-3"></a></span>
<span id="cb47-4"><a href="random-effects-modelle.html#cb47-4"></a>m0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>()</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verh1 ~ 1 + (1 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 5576
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -4.139 -0.227 -0.121 -0.121  4.813 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  IDsosci  (Intercept) 0.594    0.771   
##  Residual             0.407    0.638   
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##             Estimate Std. Error       df t value Pr(&gt;|t|)    
## (Intercept)   1.5286     0.0347 575.0000      44   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="random-effects-modelle.html#cb49-1"></a><span class="co"># ICC &#39;von Hand&#39;</span></span>
<span id="cb49-2"><a href="random-effects-modelle.html#cb49-2"></a><span class="fl">0.5938</span><span class="op">/</span>(<span class="fl">0.5938</span> <span class="op">+</span><span class="st"> </span><span class="fl">0.4065</span>)</span></code></pre></div>
<pre><code>## [1] 0.59</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="random-effects-modelle.html#cb51-1"></a><span class="co"># Mit performance::icc()</span></span>
<span id="cb51-2"><a href="random-effects-modelle.html#cb51-2"></a><span class="kw">icc</span>(m0)</span></code></pre></div>
<pre><code>## # Intraclass Correlation Coefficient
## 
##      Adjusted ICC: 0.594
##   Conditional ICC: 0.594</code></pre>
<ul>
<li><p>Die Informationen zu den Varianzkomponenten findet sich im Output von <code>summary()</code> unter <code>Random effects</code>. Aus diesen Angaben können wir die ICC berechnen. Oder wir nutzen die Funktion <code>performance::icc()</code>.</p></li>
<li><p>Fast 60% der Varianz im Verlassen der Wohnung geht auf Unterschiede zwischen Personen zurück.</p></li>
<li><p>Im <em>fixed effects</em> Modell wird diese Varianz einfach aus den Daten entfernt. Über mehr als die Hälfte der Unterschiede können wir mit <em>fixed effects</em> Modellen also per Spezifikationslogik nichts aussagen.</p></li>
<li><p>Kausale Effekte innerhalb der Personen können damit <em>maximal</em> für 40% der Varianz verantwortlich sein.</p></li>
<li><p>Allerdings müssen wir dabei beachten, dass auch der gesamte Messfehler (zumindest die zufällige Messfehlervarianz nach der CTT) ebenfalls in diesem Varianzanteil steckt.</p></li>
<li><p>Wir können die Schätzer der <em>random intercepts</em> für die Personen im Null-Modell auch dazu nutzen, uns einen Überblick zu verschaffen über die Verteilung der personenspezifischen Tendenz, die Wohnung ohne triftigen Grund zu verlassen. Die Schätzer können wir mit <code>ranef()</code> extrahieren, mit <code>broom.mixed::augment()</code> erhalten wir zusätzlich Standardfehler und Konfidenzintervalle in einem tidy data.frame.</p></li>
</ul>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="random-effects-modelle.html#cb53-1"></a><span class="co"># tibble der RE und ihre Verteilung als Histogramm</span></span>
<span id="cb53-2"><a href="random-effects-modelle.html#cb53-2"></a>m0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ranef</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>(<span class="dt">ci.level =</span> <span class="fl">0.95</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">print</span>(<span class="dt">n =</span> <span class="dv">12</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb53-3"><a href="random-effects-modelle.html#cb53-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(estimate)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>()</span></code></pre></div>
<pre><code>## # A tibble: 576 x 8
##    grp     variable    level  estimate       qq std.error     lb    ub
##    &lt;fct&gt;   &lt;fct&gt;       &lt;fct&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
##  1 IDsosci (Intercept) 01PQGO  -0.451  -3.13        0.295 -1.03  0.126
##  2 IDsosci (Intercept) 02E6C8  -0.451  -2.79        0.295 -1.03  0.126
##  3 IDsosci (Intercept) 050IPY   1.47    1.53        0.295  0.892 2.05 
##  4 IDsosci (Intercept) 05J4R8   0.189   0.571       0.295 -0.388 0.766
##  5 IDsosci (Intercept) 08BDZJ   1.26    1.41        0.295  0.679 1.83 
##  6 IDsosci (Intercept) 0BHGLF   0.402   0.779       0.295 -0.175 0.980
##  7 IDsosci (Intercept) 0EB6C1  -0.451  -2.62        0.295 -1.03  0.126
##  8 IDsosci (Intercept) 0EO9L2   2.32    2.02        0.295  1.75  2.90 
##  9 IDsosci (Intercept) 0F5L9Z   1.68    1.63        0.295  1.11  2.26 
## 10 IDsosci (Intercept) 0KAKHF   2.54    2.05        0.295  1.96  3.11 
## 11 IDsosci (Intercept) 0KYYAJ  -0.238  -0.00653     0.295 -0.815 0.339
## 12 IDsosci (Intercept) 0ONV4O  -0.0245  0.321       0.295 -0.602 0.553
## # … with 564 more rows</code></pre>
<p><img src="workshop_panel_files/figure-html/ranef-1.png" width="672" /></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="random-effects-modelle.html#cb55-1"></a><span class="co"># RE mit 95%-CIs (aus Darstellungsgründen nur jede fünfte Person)</span></span>
<span id="cb55-2"><a href="random-effects-modelle.html#cb55-2"></a>m0 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ranef</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>(<span class="dt">ci.level =</span> <span class="fl">0.95</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">nrow</span>(.), <span class="dt">by =</span> <span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb55-3"><a href="random-effects-modelle.html#cb55-3"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(estimate, level, <span class="dt">xmin =</span> lb, <span class="dt">xmax =</span> ub)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_pointrangeh</span>() <span class="op">+</span><span class="st"> </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;IDsosci&quot;</span>)</span></code></pre></div>
<p><img src="workshop_panel_files/figure-html/ranef-2.png" width="672" /></p>
<ul>
<li>Die <em>random intercepts</em> Schätzer quantifizieren die Abweichung vom Schätzer der Konstanten in der Gesamtpopulation, hier die Abweichung von 1.5. Die diskreten Werte kommen zustande, da es (wie bei einer Index-Bildung) mit 5 Ausprägungen und 4 Wellen nur eine begrenzte Anzahl an möglichen Personen-Mittelwerten gibt.</li>
<li>Die Mehrheit der Personen tendiert dazu, eher selten ihre Wohnung ohne triftigen Grund zu verlassen.</li>
</ul>
</div>
<div id="mehr-als-ein-gruppierungsfaktor" class="section level3 unnumbered">
<h3>Mehr als ein Gruppierungsfaktor</h3>
<ul>
<li>Mit <code>lme4</code> können prinzipiell beliebig viele und arbiträr angeordnete (sie müssen nicht hierarchisch sein) <em>random effects</em> in ein Modell aufgenommen werden.</li>
<li>Zu viele Faktoren oder Faktoren mit zu wenigen Ausprägungen können aber zu Problemen bei der (restricted) maximum likelihood Schätzung führen (Bayesianische Schätzverfahren können hier helfen).</li>
<li>Wir könnten z.B. die geographische Region, in der die Personen leben, als einen weiteren, hierarchisch oberhalb der Person angesiedelten Faktor aufnehmen. Hätten wir eine sehr große Stichprobe mit ausreichend geographischer Variation, wäre dies spannend, da wir uns durchaus regionale Unterschiede vorstellen könnten.</li>
<li>In Panel-Modellen liegt die Idee nahe, <em>random effects</em> für die Panel-Wellen aufzunehmen. Dieser Faktor ist nicht hierarchisch zu den Personen. Stattdessen gehört jede Messung zu genau einer Person und genau einer Welle. Diese Struktur wird auch <em>kreuzklassifiziert</em> / <em>cross-classified</em> / <em>crossed</em> genannt.
<ul>
<li>Wir nehmen den Faktor Welle auf, indem wir <code>+ (1 | wave)</code> in der Modell-Formel ergänzen.</li>
<li>Da wir nur Daten aus vier Wellen haben und die Varianz zwischen den Wellen sehr klein ist, kommt die <em>restricted maximum likelihood</em> Schätzung hier an ihre Grenzen. Eine Warnung wird ausgegeben. Wir könnten das Problem durch Herumfrickeln an den Einstellungen des Optimizer beheben, würden aber inhaltlich zu keiner anderen Schlussfolgerungen kommen. Um den Einstieg in die technischen Details zu vermeiden, verwenden wir hier aber das Modell mit der Warnmeldung.</li>
<li>Im Weiteren lösen wir das Problem, indem wir <em>fixed effects</em> für die Wellen aufnehmen.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="random-effects-modelle.html#cb56-1"></a><span class="co"># Null-Modell mit zwei Gruppierungsfaktoren</span></span>
<span id="cb56-2"><a href="random-effects-modelle.html#cb56-2"></a><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>wave), <span class="dt">data =</span> d) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">icc</span>(<span class="dt">by_group =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # ICC by Group
## 
## Group   |   ICC
## ---------------
## IDsosci | 0.595
## wave    | 0.018</code></pre>
<ul>
<li>Nur ein sehr geringer Teil der gesamten Varianz geht auf über alle Personen homogene Veränderungen zwischen den Wellen zurück.</li>
</ul>
</div>
</div>
<div id="übungsaufgaben-3" class="section level2">
<h2><span class="header-section-number">4.4</span> Übungsaufgaben 3</h2>
<ol style="list-style-type: decimal">
<li>Analysiere die Varianzkomponenten in der Intention, weniger als 1.5m Abstand zu einer Person zu halten, die nicht im eigenen Haushalt lebt (<code>verhint3</code>).
<ul>
<li>Spezifiziere zuerst ein Modell mit <em>random effects</em> für die Personen.</li>
<li>Nimm dann die Welle als zweiten Gruppierungsfaktor auf.</li>
</ul></li>
<li>Analysiere die Varianzkomponenten in weiteren Variablen, die dich interessieren.</li>
</ol>
</div>
<div id="random-effects-panel-modelle-mit-lme4" class="section level2">
<h2><span class="header-section-number">4.5</span> Random effects panel Modelle mit <code>lme4</code></h2>
<div id="wiederholung-der-wichtigsten-begriffe" class="section level3 unnumbered">
<h3>Wiederholung der wichtigsten Begriffe</h3>
<ul>
<li>Ganz allgemein gesprochen ist ein <em>mixed effects</em> Modell ein Modell, das <em>fixed</em> und <em>random</em> Koeffizienten enthält.</li>
<li><span class="citation">Gelman and Hill (<a href="#ref-gelmanDataAnalysisUsing2006" role="doc-biblioref">2006</a>)</span> verwenden die (imo) besser verständlichen Begriffe <em>varying intercepts</em> (für zwischen Einheiten auf höherer Ebene variierende Regressionskonstanten) und <em>varying slopes</em> (für zwischen Einheiten auf höherer Ebene variierende Regressionskoeffizienten).</li>
<li>Im <em>random effects</em> Panelmodell sind die Einheiten auf höherer Ebene die Personen. Die Konstanten bzw. Koeffizienten variieren zwischen Personen.</li>
<li>In der Sprache von <em>mixed effects</em> Modellen wird das einfachste Modell als <em>fixed slope, random</em> (oder <em>varying</em>) <em>intercept</em> Modell bezeichnet.
<ul>
<li>Die Regressionskonstante variiert zwischen den Personen (jede Person erhält eine eigene Konstante, die aus einer Normalverteilung mit der Populationskonstante als Mittelwert und der personenspezifischen Varianz als Streuung stammt).
Die übrigen Regressionskoeffizienten sind für alle Personen gleich (<em>fixed</em>).</li>
</ul></li>
</ul>
</div>
<div id="einfaches-random-effects-panel-modell" class="section level3 unnumbered">
<h3>Einfaches random effects panel Modell</h3>
<ul>
<li><p>Wir modellieren wieder die Häufigkeit, ohne triftigen Grund die Wohnung zu verlassen, in Abhängigkeit der Intention, dies zu tun.</p></li>
<li><p>Die Spezifikation in <code>lme4::lmer()</code> folgt der in <code>R</code> üblichen Logik. Das Modell enthält <code>verhint1</code> als Prädiktor mit einem für alle Personen gleichen Koeffizienten (homogener Treatment-Effekt) und <code>(1 | IDsosci)</code> als <em>varying intercept</em> für jede Person.</p></li>
<li><p>Hinweis: <code>lme4</code> selbst weist keine Freiheitsgrade und entsprechend auch keine <em>p</em>-Werte für die Koeffizienten aus. Wenn – wie hier – zusätzlich das Paket <code>lmerTest</code> geladen wurde, werden diese automatisch ergänzt.</p></li>
</ul>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="random-effects-modelle.html#cb58-1"></a>m1 =<span class="st"> </span><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb58-2"><a href="random-effects-modelle.html#cb58-2"></a></span>
<span id="cb58-3"><a href="random-effects-modelle.html#cb58-3"></a>m1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verh1 ~ verhint1 + (1 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 4554
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -4.524 -0.202 -0.085  0.165  5.793 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  IDsosci  (Intercept) 0.111    0.334   
##  Residual             0.341    0.584   
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##              Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)    0.5987     0.0287  975.4311    20.9   &lt;2e-16 ***
## verhint1       0.5155     0.0122 1747.0982    42.3   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<ul>
<li><p>Mit jedem Punkt auf der Skala zur Verhaltensintention steigt die Häufigkeit des Rausgehens ohne triftigen Grund um 0.5 Punkte.</p></li>
<li><p>Wir können das Modell mit dem Prädiktor <code>verhint1</code> mit dem Null-Modell vergleichen.</p>
<ul>
<li>Mit <code>anova()</code> erhalten wir verschiedene Informationskriterien und einen Likelihood Ratio (Wald) Test. Die Test-Statistik folgt einer <span class="math inline">\(\chi^2\)</span>-Verteilung.</li>
<li>Durch einen Vergleich der Varianzkomponenten der Modelle erhalten wir ein Maß, das konzeptionell ähnlich <span class="math inline">\(\Delta R^2\)</span> interpretiert werden kann. Die Funktion <code>performance::r2(by_group = TRUE)</code> implementiert diesen Vergleich für ein Modell und das Null-Modell. Die manuelle Berechnung ist auch schrittweise für mehre Modelle möglich, die zunehmend mehr Prädiktoren enthalten. Wichtig: Die <span class="math inline">\(\Delta R^2\)</span>-Logik funktioniert nur in Modellen mit identischen <em>random effects</em>.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="random-effects-modelle.html#cb60-1"></a><span class="co"># Wald Test und Informationskriterien</span></span>
<span id="cb60-2"><a href="random-effects-modelle.html#cb60-2"></a><span class="kw">anova</span>(m0, m1)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m0: verh1 ~ 1 + (1 | IDsosci)
## m1: verh1 ~ verhint1 + (1 | IDsosci)
##    Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)    
## m0  3 5577 5595  -2786     5571                            
## m1  4 4549 4572  -2270     4541  1031      1     &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="random-effects-modelle.html#cb62-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) - manuell</span></span>
<span id="cb62-2"><a href="random-effects-modelle.html#cb62-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sigma</span>(m1)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sigma</span>(m0)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># L1</span></span></code></pre></div>
<pre><code>## [1] 0.16</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="random-effects-modelle.html#cb64-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m1)<span class="op">$</span>IDsosci)<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m0)<span class="op">$</span>IDsosci))  <span class="co"># L2</span></span></code></pre></div>
<pre><code>## [1] 0.81</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="random-effects-modelle.html#cb66-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) - mit performance::r2() (Vergleicht immer mit</span></span>
<span id="cb66-2"><a href="random-effects-modelle.html#cb66-2"></a><span class="co"># Null-Modell)</span></span>
<span id="cb66-3"><a href="random-effects-modelle.html#cb66-3"></a><span class="kw">r2</span>(m1, <span class="dt">by_group =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # Explained Variance by Level
## 
## Level   |    R2
## ---------------
## Level 1 | 0.161
## IDsosci | 0.812</code></pre>
<ul>
<li>Die Berücksichtigung der Verhaltensintention verbessert das Modell.
<ul>
<li>Die Werte der Informationskriterien <em>AIC</em> und <em>BIC</em> liegen deutlich unter dem Null-Modell (niedriger ist besser).</li>
<li>Nach dem <em>Wald-Test</em> wird die <span class="math inline">\(H_0\)</span>, dass beide Modelle gleich gut zu den Daten passen, verworfen.</li>
<li>Die Aufnahme der Verhaltensintention erklärt über 80% der Varianz zwischen den Personen und 16% der Varianz innerhalb der Personen — TPB ftw! ;)</li>
</ul></li>
<li>Es zeigt sich, dass die über die Zeit variierenden Prädiktoren sowohl Varianz innerhalb als auch Varianz zwischen den Personen erklären. Das macht die Interpretation des Koeffizienten schwieriger als die des entsprechenden Koeffizienten im <em>fixed effects</em> Modell, der sich klar nur auf die kausalen Effekte innerhalb von Personen bezieht. Auf diesen Punkt kommen wir in der Überleitung zum <em>within-between</em>-Modell im letzten Abschnitt zurück.</li>
</ul>
</div>
<div id="einfache-erweiterungen-des-random-effects-panel-modells" class="section level3 unnumbered">
<h3>Einfache Erweiterungen des random effects panel Modells</h3>
<ul>
<li>In den folgenden Absätzen erweitern wir das einfache Modell. Wir berücksichtigen <em>fixed effects</em> für die Panelwellen und ergänzen dann weitere über die Zeit konstante und variierende Prädiktoren.</li>
<li>Die Texte dazu halte ich an den meisten Stellen knapp, da die grundsätzliche Spezifikation und Interpretation nun klar sein dürfte.</li>
</ul>
</div>
<div id="fixed-effects-für-die-panelwellen" class="section level3 unnumbered">
<h3>Fixed effects für die Panelwellen</h3>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="random-effects-modelle.html#cb68-1"></a><span class="co"># Modellspezifikation</span></span>
<span id="cb68-2"><a href="random-effects-modelle.html#cb68-2"></a>m2 =<span class="st"> </span><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb68-3"><a href="random-effects-modelle.html#cb68-3"></a></span>
<span id="cb68-4"><a href="random-effects-modelle.html#cb68-4"></a>m2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verh1 ~ verhint1 + factor(wave) + (1 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 4558
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -4.647 -0.220 -0.066  0.186  5.891 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  IDsosci  (Intercept) 0.113    0.336   
##  Residual             0.339    0.582   
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)      0.5921     0.0336 1776.7887   17.62   &lt;2e-16 ***
## verhint1         0.5128     0.0124 1668.8271   41.20   &lt;2e-16 ***
## factor(wave)2   -0.0397     0.0345 1599.1054   -1.15    0.250    
## factor(wave)3    0.0735     0.0346 1605.1846    2.12    0.034 *  
## factor(wave)4    0.0127     0.0350 1651.7107    0.36    0.718    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="random-effects-modelle.html#cb70-1"></a><span class="co"># Modellvergleich Wald und Info-Kriterien</span></span>
<span id="cb70-2"><a href="random-effects-modelle.html#cb70-2"></a><span class="kw">anova</span>(m0, m1, m2)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m0: verh1 ~ 1 + (1 | IDsosci)
## m1: verh1 ~ verhint1 + (1 | IDsosci)
## m2: verh1 ~ verhint1 + factor(wave) + (1 | IDsosci)
##    Df  AIC  BIC logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    
## m0  3 5577 5595  -2786     5571                             
## m1  4 4549 4572  -2270     4541 1030.9      1     &lt;2e-16 ***
## m2  7 4543 4584  -2265     4529   11.2      3      0.011 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="random-effects-modelle.html#cb72-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) gegenüber M0</span></span>
<span id="cb72-2"><a href="random-effects-modelle.html#cb72-2"></a><span class="kw">r2</span>(m2, <span class="dt">by_group =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # Explained Variance by Level
## 
## Level   |    R2
## ---------------
## Level 1 | 0.166
## IDsosci | 0.809</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="random-effects-modelle.html#cb74-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) gegenüber M1</span></span>
<span id="cb74-2"><a href="random-effects-modelle.html#cb74-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sigma</span>(m2)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sigma</span>(m1)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># L1</span></span></code></pre></div>
<pre><code>## [1] 0.0067</code></pre>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="random-effects-modelle.html#cb76-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m2)<span class="op">$</span>IDsosci)<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m1)<span class="op">$</span>IDsosci))  <span class="co"># L2</span></span></code></pre></div>
<pre><code>## [1] -0.016</code></pre>
<ul>
<li>Der Effekt der Verhaltensintention bleibt auch bei Berücksichtigung von Periodeneffekten praktisch unverändert.</li>
<li>Die Periodeneffekte sind substantiell relativ unbedeutend.</li>
<li>Die statistischen Indikatoren für oder gegen die Aufnahme der Periodeneffekte sind gemischt. Der <em>Wald-Test</em> (signifikant) und das <em>AIC</em> (etwas niedriger im Vergleich zu M1) sprechen dafür. Das <em>BIC</em>, das Modellkomplexität stärker bestraft, spricht dagegen (etwas höher im Vergleich zu M1).</li>
<li>Die Varianzaufklärung gegenüber M0 entspricht substantiell der von M1.</li>
<li>Im Vergleich zu M1 wird minimal mehr Varianz innerhalb der Personen erklärt. Die Varianzaufklärung auf Ebene der Personen sinkt sogar leicht. Dieses auf den ersten Blick wenig intuitive Ergebnis erklärt sich dadurch, dass die Periodeneffekte im Design mit den Personen kreuzklassifiziert sind. Ein geringer Varianzanteil, der in M1 fälschlicherweise den Personen zugerechnet wurde (hier konkret: die zwischen den Personen konstanten, parallelen Veränderungen von Intention und Handlung), wird nun auf die “korrekte” Ebene verschoben.</li>
<li>Mein Fazit: Ich würde die Periodeneffekte immer berücksichtigen, da sie einen wichtigen Bestandteil des datengenerierenden Prozesses im Modell abbildet. Diese Entscheidung hängt nicht von den Ergebnissen der statistischen Tests ab. Substantiell lernen wir an dieser Stelle lediglich, dass homogene Veränderungen über die Zeit relativ unbedeutend waren (siehe auch ICC des Modells mit <em>random effects</em> für die Perioden.</li>
</ul>
</div>
<div id="aufnahme-eines-personenmerkmals" class="section level3 unnumbered">
<h3>Aufnahme eines Personenmerkmals</h3>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="random-effects-modelle.html#cb78-1"></a><span class="co"># Modellspezifikation</span></span>
<span id="cb78-2"><a href="random-effects-modelle.html#cb78-2"></a>m3 =<span class="st"> </span><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span>C_sex <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb78-3"><a href="random-effects-modelle.html#cb78-3"></a></span>
<span id="cb78-4"><a href="random-effects-modelle.html#cb78-4"></a>m3 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verh1 ~ verhint1 + C_sex + factor(wave) + (1 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 4554
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -4.609 -0.244 -0.058  0.215  5.930 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev.
##  IDsosci  (Intercept) 0.112    0.334   
##  Residual             0.338    0.582   
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)      0.6629     0.0416 1145.4314   15.94   &lt;2e-16 ***
## verhint1         0.5106     0.0125 1675.1966   41.01   &lt;2e-16 ***
## C_sex           -0.1106     0.0380  450.4352   -2.91   0.0038 ** 
## factor(wave)2   -0.0390     0.0345 1602.5800   -1.13   0.2582    
## factor(wave)3    0.0743     0.0346 1608.6417    2.15   0.0318 *  
## factor(wave)4    0.0139     0.0350 1655.0226    0.40   0.6916    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="random-effects-modelle.html#cb80-1"></a><span class="co"># Modellvergleich Wald und Info-Kriterien</span></span>
<span id="cb80-2"><a href="random-effects-modelle.html#cb80-2"></a><span class="kw">anova</span>(m0, m1, m2, m3)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m0: verh1 ~ 1 + (1 | IDsosci)
## m1: verh1 ~ verhint1 + (1 | IDsosci)
## m2: verh1 ~ verhint1 + factor(wave) + (1 | IDsosci)
## m3: verh1 ~ verhint1 + C_sex + factor(wave) + (1 | IDsosci)
##    Df  AIC  BIC logLik deviance   Chisq Chi Df Pr(&gt;Chisq)    
## m0  3 5577 5595  -2786     5571                              
## m1  4 4549 4572  -2270     4541 1030.94      1     &lt;2e-16 ***
## m2  7 4543 4584  -2265     4529   11.16      3     0.0109 *  
## m3  8 4537 4583  -2260     4521    8.49      1     0.0036 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="random-effects-modelle.html#cb82-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) gegenüber M0</span></span>
<span id="cb82-2"><a href="random-effects-modelle.html#cb82-2"></a><span class="kw">r2</span>(m3, <span class="dt">by_group =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # Explained Variance by Level
## 
## Level   |    R2
## ---------------
## Level 1 | 0.167
## IDsosci | 0.812</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="random-effects-modelle.html#cb84-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) gegenüber M2</span></span>
<span id="cb84-2"><a href="random-effects-modelle.html#cb84-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sigma</span>(m3)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sigma</span>(m2)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># L1</span></span></code></pre></div>
<pre><code>## [1] 0.0015</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="random-effects-modelle.html#cb86-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m3)<span class="op">$</span>IDsosci)<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m2)<span class="op">$</span>IDsosci))  <span class="co"># L2</span></span></code></pre></div>
<pre><code>## [1] 0.013</code></pre>
<ul>
<li>Im Gegensatz zum <em>fixed effects</em> Modell können wir nun auch Personenmerkmale als Prädiktoren berücksichtigen. Frauen gehen im Durchschnitt etwas seltener ohne triftigen Grund aus dem Haus als Männer. Hier wird ein wichtiger Vorteil des <em>random effects</em> Modells gegenüber dem <em>fixed effects</em> Modell deutlich. Es könnte aus verschiedensten Gründen relevant sein, zu wissen, dass eher Männer als Frauen zu diesem riskanten Verhalten neigen. Beispielsweise könnte eine Fokussierung einer Kampagne auf Männer sinnvoll sein.</li>
<li>Wald-Test und Informationskriterien sprechen für die Berücksichtigung des Geschlechts.</li>
<li>Die Varianzaufklärung auf Ebene der Personen macht ca. 1% aus. Die Aufklärung innerhalb der Personen kann ignoriert werden.</li>
</ul>
</div>
<div id="aufnahme-eines-weiteren-über-die-zeit-variierender-prädiktors" class="section level3 unnumbered">
<h3>Aufnahme eines weiteren, über die Zeit variierender Prädiktors</h3>
<ul>
<li>Wie im Beispiel zu <em>fixed effects</em> wechseln wir hier das Modell, damit wir die kausale Interpretierbarkeit aller Koeffizienten von über die Zeit variablen Prädiktoren beibehalten.
<ul>
<li><em>Zur Wiederholung</em>: Nach der TPB dürfen wir dieses Modell annehmen, da die drei Prädiktoren auf derselben kausalen Stufe stehen: Verhaltensintention ~ Einstellung + Deskriptive Norm + Injunktive Norm. Hier schätzen wir das Modell für die Verhaltensintention <em>Rausgehen ohne triftigen Grund</em>.</li>
<li>Der folgende Code wiederholt damit auch nochmals den schrittweisen Aufbau des Modells und das modellvergleichende Vorgehen. Es bietet auch eine Gelegenheit, eine leicht angepasste Spezifikationslogik zu erklären.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="random-effects-modelle.html#cb88-1"></a><span class="co"># Null-Modell</span></span>
<span id="cb88-2"><a href="random-effects-modelle.html#cb88-2"></a>m0_int1 =<span class="st"> </span><span class="kw">lmer</span>(verhint1 <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb88-3"><a href="random-effects-modelle.html#cb88-3"></a><span class="kw">icc</span>(m0_int1)  <span class="co"># conditional ICC takes the fixed effects variances into account</span></span></code></pre></div>
<pre><code>## # Intraclass Correlation Coefficient
## 
##      Adjusted ICC: 0.573
##   Conditional ICC: 0.558</code></pre>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="random-effects-modelle.html#cb90-1"></a><span class="co"># Modelle mit Prädiktoren</span></span>
<span id="cb90-2"><a href="random-effects-modelle.html#cb90-2"></a>m1_int1 =<span class="st"> </span><span class="kw">lmer</span>(verhint1 <span class="op">~</span><span class="st"> </span>ein1 <span class="op">+</span><span class="st"> </span>desnormp1 <span class="op">+</span><span class="st"> </span>injnormp1 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), </span>
<span id="cb90-3"><a href="random-effects-modelle.html#cb90-3"></a>    <span class="dt">data =</span> d)</span>
<span id="cb90-4"><a href="random-effects-modelle.html#cb90-4"></a>m1_int1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">coef</span>()</span></code></pre></div>
<pre><code>##               Estimate Std. Error   df t value Pr(&gt;|t|)
## (Intercept)       0.21      0.053 1623     3.9  9.1e-05
## ein1              0.48      0.019 1950    25.6 1.7e-124
## desnormp1         0.10      0.026 2297     3.9  8.5e-05
## injnormp1         0.12      0.026 2292     4.5  5.7e-06
## factor(wave)2     0.15      0.046 1686     3.4  8.2e-04
## factor(wave)3     0.18      0.047 1703     3.8  1.2e-04
## factor(wave)4     0.29      0.047 1740     6.2  6.3e-10</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="random-effects-modelle.html#cb92-1"></a>m2_int1 =<span class="st"> </span><span class="kw">lmer</span>(verhint1 <span class="op">~</span><span class="st"> </span>ein1 <span class="op">+</span><span class="st"> </span>desnormp1 <span class="op">+</span><span class="st"> </span>injnormp1 <span class="op">+</span><span class="st"> </span>C_sex <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span></span>
<span id="cb92-2"><a href="random-effects-modelle.html#cb92-2"></a><span class="st">    </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb92-3"><a href="random-effects-modelle.html#cb92-3"></a>m2_int1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">coef</span>()</span></code></pre></div>
<pre><code>##               Estimate Std. Error   df t value Pr(&gt;|t|)
## (Intercept)       0.31      0.062 1211     5.0  6.3e-07
## ein1              0.48      0.019 1938    25.6 4.4e-125
## desnormp1         0.10      0.026 2296     3.9  8.5e-05
## injnormp1         0.12      0.026 2292     4.5  6.6e-06
## C_sex            -0.16      0.050  518    -3.2  1.3e-03
## factor(wave)2     0.16      0.046 1687     3.4  8.0e-04
## factor(wave)3     0.18      0.047 1704     3.9  1.2e-04
## factor(wave)4     0.29      0.047 1741     6.2  5.8e-10</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="random-effects-modelle.html#cb94-1"></a><span class="co"># Modellvergleiche Wald und Info-Kriterien</span></span>
<span id="cb94-2"><a href="random-effects-modelle.html#cb94-2"></a><span class="kw">anova</span>(m0_int1, m1_int1, m2_int1)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m0_int1: verhint1 ~ 1 + factor(wave) + (1 | IDsosci)
## m1_int1: verhint1 ~ ein1 + desnormp1 + injnormp1 + factor(wave) + (1 | 
## m1_int1:     IDsosci)
## m2_int1: verhint1 ~ ein1 + desnormp1 + injnormp1 + C_sex + factor(wave) + 
## m2_int1:     (1 | IDsosci)
##         Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)    
## m0_int1  6 6672 6706  -3330     6660                            
## m1_int1  9 5885 5936  -2933     5867 792.9      3     &lt;2e-16 ***
## m2_int1 10 5876 5934  -2928     5856  10.5      1     0.0012 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="random-effects-modelle.html#cb96-1"></a><span class="co"># Varianzreduktion Vorsicht: Das ergibt hier keinen Sinn, da Vergleich mit M00</span></span>
<span id="cb96-2"><a href="random-effects-modelle.html#cb96-2"></a><span class="co"># (ohne Periodeneffekte) Reduktion der Varianz (Delta R^2) gegenüber M0</span></span>
<span id="cb96-3"><a href="random-effects-modelle.html#cb96-3"></a><span class="kw">r2</span>(m1_int1, <span class="dt">by_group =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<pre><code>## # Explained Variance by Level
## 
## Level   |    R2
## ---------------
## Level 1 | 0.155
## IDsosci | 0.773</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="random-effects-modelle.html#cb98-1"></a><span class="co"># Wir sehen stattdessen das Modell mit Perioden-FE als Null-Referenz Reduktion</span></span>
<span id="cb98-2"><a href="random-effects-modelle.html#cb98-2"></a><span class="co"># der Varianz (Delta R^2) in M1_int gegenüber M0_int</span></span>
<span id="cb98-3"><a href="random-effects-modelle.html#cb98-3"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sigma</span>(m1_int1)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sigma</span>(m0_int1)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># L1</span></span></code></pre></div>
<pre><code>## [1] 0.086</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="random-effects-modelle.html#cb100-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m1_int1)<span class="op">$</span>IDsosci)<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m0_int1)<span class="op">$</span>IDsosci))  <span class="co"># L2</span></span></code></pre></div>
<pre><code>## [1] 0.78</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="random-effects-modelle.html#cb102-1"></a><span class="co"># Reduktion der Varianz (Delta R^2) in M2_int gegenüber M1_int</span></span>
<span id="cb102-2"><a href="random-effects-modelle.html#cb102-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">sigma</span>(m2_int1)<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sigma</span>(m1_int1)<span class="op">^</span><span class="dv">2</span>)  <span class="co"># L1</span></span></code></pre></div>
<pre><code>## [1] 0.00025</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="random-effects-modelle.html#cb104-1"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m2_int1)<span class="op">$</span>IDsosci)<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m1_int1)<span class="op">$</span>IDsosci))  <span class="co"># L2</span></span></code></pre></div>
<pre><code>## [1] 0.027</code></pre>
<ul>
<li><p>Als Null-Modell spezifizieren wir ein Modell mit <em>random effects</em> für Personen und <em>fixed effects</em> für Panelwellen. Meiner Meinung nach ist dies ein angemessenes Null-Modell, da nur die Eigenschaften des Designs abgebildet werden. Für die Panelwellen eigenen sich <em>fixed effects</em>, da es nur vier Messzeitpunkte gibt.</p></li>
<li><p>Für das Null-Modell können wir die ICC ausweisen. Da im Modell auch <em>fixed effects</em> sind, interpretieren wir die <em>conditional ICC</em>. Mehr als die Hälfte der Varianz in der Intention, ohne triftigen Grund die Wohnung zu verlassen, liegt zwischen den Personen.</p></li>
<li><p>Die Einstellung hat einen deutlichen Effekt auf die Verhaltensintention. Die Wahrnehmungen deskriptiver und injunktiver Normen haben vergleichsweise geringe, statistisch signifikante Effekte.</p></li>
<li><p>Die Informationskriterien und der Wald-Test zeigen klar, dass sich das Modell durch die Aufnahme der drei Prädiktoren verbessert.</p></li>
<li><p>Die drei Prädiktoren erklären 9% der Varianz innerhalb der Personen und 78% der Varianz zwischen den Personen. Da wir ein angepasstes Null-Modell mit <em>fixed effects</em> für die Wellen als Referenz wählen, müssen wir die Varianzreduktion selbst berechnen. <code>performance::r2()</code> bezieht sich immer auf das “leere” Null-Modell. Es bezieht in diesem Fall die Erklärungskraft der <em>fixed effects</em> für die Wellen mit ein.</p></li>
<li><p>Zusätzlich wollen wir Geschlecht als Prädiktor auf Personen-Ebene berücksichtigen. Frauen haben im Vergleich zu Männern seltener vor, die Wohnung ohne triftigen Grund zu verlassen.</p></li>
<li><p>Informationskriterien und Wald-Test zeigen eine Modellverbesserung an. Das Geschlecht erklärt zusätzliche 3% der Varianz zwischen den Personen.</p></li>
</ul>
</div>
</div>
<div id="übungsaufgaben-4" class="section level2">
<h2><span class="header-section-number">4.6</span> Übungsaufgaben 4</h2>
<ol style="list-style-type: decimal">
<li>Schätze den kausalen Effekt der Einstellung zum Verhalten, weniger als 1.5m Abstand zu Personen zu halten, die nicht im gleichen Haushalt leben (<code>ein3</code>), auf die diesbezügliche Verhaltensintention (<code>verhint3</code>). Berücksichtige dabei die Periodeneffekte der Panelwellen. Siehe dazu auch Übung 2.
<ul>
<li>Schätze zuerst ein geeignetes Null-Modell mit <em>random intercept</em> als Referenz. Betrachte die ICC.</li>
<li>Schätze dann das <em>random intercept</em> Panelmodell.</li>
<li>Nimm zusätzlich die wahrgenommene deskriptive Norm (<code>desnormp3</code>) in das Modell auf.</li>
<li>Prüfe, ob sich die Intention zwischen Männer und Frauen unterscheidet (<code>C_sex</code>).</li>
</ul></li>
<li>Spezifiziere, schätze und interpretiere ein eigenes <em>random effects</em> Panelmodell mit <em>random intercept</em> mit Daten aus dem Beispieldatensatz. Gehe dabei von einem geeigneten Null-Modell aus und erweitere das Modell dann.</li>
</ol>
</div>
<div id="variierende-koeffizienten-random-slopes-und-ebenen-überschreitende-interaktionen-cross-level-interactions" class="section level2">
<h2><span class="header-section-number">4.7</span> Variierende Koeffizienten (random slopes) und Ebenen-überschreitende Interaktionen (cross-level interactions)</h2>
<ul>
<li>Bisher haben wir Modelle betrachtet, in denen die Personen-Konstanten um den Populationsschätzer variieren (<em>random intercepts</em>). Diese Modelle können wir erweitern, indem wir auch den Schätzer eines (oder mehrerer) Koeffizienten zwischen den Personen variieren lassen (<em>random slopes</em>).</li>
<li>Damit lockern wir die Annahme eines homogenen Treatment-Effekts: Wir gehen nicht mehr davon aus, dass der Effekt eines Prädiktors für alle Personen gleich ist, sondern lassen eine Streuung um den durchschnittlichen Treatment-Effekt zu.</li>
<li>Die Standardabweichung (oder die Varianz) des <em>random</em> oder <em>varying slope</em> ist ein Indikator dafür, wie stark ein Effekt zwischen den Personen variiert.</li>
<li>Wir können testen, ob sich diese Varianz der Koeffizienten von 0 unterscheidet. Dazu werden zwei Tests empfohlen:
<ul>
<li>Vergleich der Modelle mit und ohne <em>random slopes</em> mit einem Likelihood-Ratio-Test (Wald-Test)</li>
<li>Prüfen, ob das Konfidenzintervalls um die Varianzkomponente die 0 enthält.</li>
<li>Es ist in der Literatur zu <em>mixed effects</em> Modellen umstritten, ob das Testen einer Varianzkomponente sinnvoll ist.
<ul>
<li><span class="citation">Barr et al. (<a href="#ref-barrRandomEffectsStructure2013" role="doc-biblioref">2013</a>)</span> fordern, dass <em>alle</em> Koeffizienten, die dem Design einer Studie nach variieren müssen (im Panel-Design eigentlich alle Effekte von über die Zeit variierenden Prädiktoren), als <em>random slopes</em> geschätzt werden sollen. Entfernt werden sollen dann nur die Varianzkomponenten, bei denen die Daten eine Varianz von (nahe) 0 nahelegen.</li>
<li><span class="citation">Matuschek et al. (<a href="#ref-matuschekBalancingTypeError2017" role="doc-biblioref">2017</a>)</span> sprechen sich dafür aus, sparsame Modelle zu spezifizieren. Wenn die Theorie oder das Forschungsinteresse nicht an Effekt-Heterogenität interessiert sind, kann das sparsamere Modell ohne <em>random slope</em> bevorzugt werden.</li>
<li>Das Verzichten auf einige <em>random slope</em> Terme ist in der (Restricted) Maximum-Likelihood-Schätzung häufig auch pragmatisch erforderlich, um die Modelle schätzbar zu machen.</li>
</ul></li>
</ul></li>
<li>In unserem Beispiel wollen wir den Effekt der Intention, ohne triftigen Grund raus zu gehen, zwischen den Personen variieren lassen.
<ul>
<li>Dazu ergänzen wir den Prädiktor in der Klammer, in der die <em>random effects</em> spezifiziert werden: <code>+ (verhint1 | IDsosci)</code>.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="random-effects-modelle.html#cb106-1"></a><span class="co"># Modellspezifikation</span></span>
<span id="cb106-2"><a href="random-effects-modelle.html#cb106-2"></a>m4 =<span class="st"> </span><span class="kw">lmer</span>(verh1 <span class="op">~</span><span class="st"> </span>verhint1 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(verhint1 <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span></code></pre></div>
<pre><code>## boundary (singular) fit: see ?isSingular</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="random-effects-modelle.html#cb108-1"></a>m4 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verh1 ~ verhint1 + factor(wave) + (verhint1 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 3859
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -6.089 -0.268 -0.102 -0.054  8.014 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  IDsosci  (Intercept) 0.0891   0.299         
##           verhint1    0.0971   0.312    -1.00
##  Residual             0.2446   0.495         
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)      0.5798     0.0314 1087.2900   18.44   &lt;2e-16 ***
## verhint1         0.4706     0.0215  347.4913   21.94   &lt;2e-16 ***
## factor(wave)2   -0.0167     0.0299 2002.4198   -0.56   0.5759    
## factor(wave)3    0.0825     0.0299 2008.1778    2.76   0.0059 ** 
## factor(wave)4    0.0633     0.0305 2035.1883    2.07   0.0382 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## convergence code: 0
## boundary (singular) fit: see ?isSingular</code></pre>
<ul>
<li>Wenn wir das Modell zu schätzen, erhalten wir eine Warnung, dass die Lösung ein <em>singulärer Fit</em> ist. Ein Auszug aus <code>?lme4::isSingular</code>:</li>
</ul>
<blockquote>
<p>While singular models are statistically well defined (it is theoretically sensible for the true maximum likelihood estimate to correspond to a singular fit), there are real concerns that (1) singular fits correspond to overfitted models that may have poor power; (2) chances of numerical problems and mis-convergence are higher for singular models (e.g. it may be computationally difficult to compute profile confidence intervals for such models); (3) standard inferential procedures such as Wald statistics and likelihood ratio tests may be inappropriate.</p>
</blockquote>
<ul>
<li>Ein singulärer Fit ist ein Hinweis darauf, dass die Daten nicht ausreichen, um alle Varianzkomponenten mit (Restricted) Maximum-Likelihood zu schätzen. Dies ist in typischen Befragungspanels mit relativ wenigen Messzeitpunkten häufig der Fall. Es gibt für jeden Befragten nur vier Beobachtungen, aus denen wir in diesem Modell drei Varianz-Kovarianz-Koeffizienten schätzen.</li>
<li>In diesem Fall finden wir eine Korrelation von <span class="math inline">\(-1\)</span> zwischen den Personen-spezifischen Konstanten und den Personen-spezifischen Effekten der Verhaltensintention. Das heißt, dass aus der Personen-spezifischen Konstante perfekt vorhergesagt werden kann, wo der Personen-spezifische Effekt liegt. Je höher die durchschnittliche Häufigkeit des Rausgehens ohne Grund ist, desto negativer ist der Effekt der Verhaltensintention. Etwas abstrakter ausgedrückt: Wir können hier nicht analytisch zwischen durchschnittlichem Niveau und Effekt für eine Person unterscheiden.</li>
<li>In der Praxis würden wir hier meist mit dem <em>random intercept</em> Modell weiter arbeiten. Wenn wir nur an den <em>fixed effects</em> interessiert sind, können wir auch das Modell mit <em>random slope</em> verwenden, solange wir die im Zitat oben genannten Einschränkungen beachten.</li>
</ul>
<div id="ein-weiteres-beispiel" class="section level3 unnumbered">
<h3>Ein weiteres Beispiel</h3>
<ul>
<li>Um das weitere Vorgehen mit dem <em>random slope</em> Modell zu erläutern, wechseln wir die Variablen. Ein Modell, in dem die Intention, sich mit Personen außerhalb des eigenen Haushalts zu treffen (<code>verhint2</code>), durch die Einstellung zu diesem Verhalten (<code>ein2</code>) erklärt wird, lässt sich mit den vorliegenden Daten schätzen.</li>
<li>Im folgenden Code-Snippet schätzen wir zuerst als Referenz das Modell mit <em>random intercept</em> (<code>m_ri</code>). Dann lassen wir den Effekt der Einstellung zwischen den Personen variieren (<code>m_rs</code>).</li>
</ul>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="random-effects-modelle.html#cb110-1"></a><span class="co"># Modell mit Random Intercept als Referenz</span></span>
<span id="cb110-2"><a href="random-effects-modelle.html#cb110-2"></a>m_ri =<span class="st"> </span><span class="kw">lmer</span>(verhint2 <span class="op">~</span><span class="st"> </span>ein2 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb110-3"><a href="random-effects-modelle.html#cb110-3"></a></span>
<span id="cb110-4"><a href="random-effects-modelle.html#cb110-4"></a><span class="co"># Modell mit Random Slope</span></span>
<span id="cb110-5"><a href="random-effects-modelle.html#cb110-5"></a>m_rs =<span class="st"> </span><span class="kw">lmer</span>(verhint2 <span class="op">~</span><span class="st"> </span>ein2 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(ein2 <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb110-6"><a href="random-effects-modelle.html#cb110-6"></a>m_rs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verhint2 ~ ein2 + factor(wave) + (ein2 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 6217
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.184 -0.421 -0.202  0.247  4.353 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  IDsosci  (Intercept) 0.230    0.480         
##           ein2        0.111    0.334    -0.62
##  Residual             0.639    0.799         
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                Estimate Std. Error        df t value     Pr(&gt;|t|)    
## (Intercept)      0.8226     0.0517  794.3368   15.91      &lt; 2e-16 ***
## ein2             0.4033     0.0269  371.7795   14.97      &lt; 2e-16 ***
## factor(wave)2    0.1130     0.0483 1573.1786    2.34        0.019 *  
## factor(wave)3    0.1970     0.0483 1587.1670    4.07 0.0000485440 ***
## factor(wave)4    0.2880     0.0490 1646.3075    5.87 0.0000000052 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="random-effects-modelle.html#cb112-1"></a><span class="co"># profile confidence intervals</span></span>
<span id="cb112-2"><a href="random-effects-modelle.html#cb112-2"></a><span class="kw">confint</span>(m_rs, <span class="dt">oldNames =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>##                               2.5 % 97.5 %
## sd_(Intercept)|IDsosci        0.317   0.61
## cor_ein2.(Intercept)|IDsosci -0.749  -0.39
## sd_ein2|IDsosci               0.280   0.39
## sigma                         0.770   0.83
## (Intercept)                   0.718   0.93
## ein2                          0.348   0.46
## factor(wave)2                 0.018   0.21
## factor(wave)3                 0.102   0.29
## factor(wave)4                 0.191   0.38</code></pre>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="random-effects-modelle.html#cb114-1"></a><span class="co"># Wald-Test</span></span>
<span id="cb114-2"><a href="random-effects-modelle.html#cb114-2"></a><span class="kw">anova</span>(m_ri, m_rs)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m_ri: verhint2 ~ ein2 + factor(wave) + (1 | IDsosci)
## m_rs: verhint2 ~ ein2 + factor(wave) + (ein2 | IDsosci)
##      Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)    
## m_ri  7 6403 6444  -3195     6389                            
## m_rs  9 6211 6262  -3096     6193   197      2     &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="random-effects-modelle.html#cb116-1"></a><span class="co"># RE mit 95%-CIs (aus Darstellungsgründen nur jede fünfte Person)</span></span>
<span id="cb116-2"><a href="random-effects-modelle.html#cb116-2"></a>m_rs <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ranef</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">augment</span>(<span class="dt">ci.level =</span> <span class="fl">0.95</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">filter</span>(variable <span class="op">==</span><span class="st"> </span></span>
<span id="cb116-3"><a href="random-effects-modelle.html#cb116-3"></a><span class="st">    &quot;ein2&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">slice</span>(<span class="kw">seq</span>(<span class="dv">1</span>, <span class="kw">nrow</span>(.), <span class="dt">by =</span> <span class="dv">5</span>)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">mutate</span>(<span class="dt">level =</span> <span class="kw">reorder</span>(level, </span>
<span id="cb116-4"><a href="random-effects-modelle.html#cb116-4"></a>    estimate)) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(estimate, level, <span class="dt">xmin =</span> lb, <span class="dt">xmax =</span> ub)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_pointrangeh</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb116-5"><a href="random-effects-modelle.html#cb116-5"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;IDsosci&quot;</span>)</span></code></pre></div>
<p><img src="workshop_panel_files/figure-html/lmer-random-slope2-1.png" width="672" /></p>
<ul>
<li><p>Mit jedem Punkt auf der Einstellungsskala steigt die Intention, sich mit anderen Personen außerhalb des Haushalts zu treffen, um ca. 0.4 Punkte.</p></li>
<li><p>Die Personen-spezifischen Effekte streuen mit einer Standardabweichung von ca. 0.3 Punkten um diesen durchschnittlichen Effekt durchaus wahrnehmbar. Die typischen Effekte (+/- 1 SD) liegen zwischen sehr geringen Effekten und deutlichen Effekten. Ein negativer Effekt der Einstellung auf die Intention ist selten.</p></li>
<li><p>Das Konfidenzintervall für die Standardabweichung des <em>random slope</em> liegt deutlich über 0. Wir können davon ausgehen, dass es Heterogenität im Treatment-Effekt gibt. Manche Personen passen ihre Verhaltensintention ihren Einstellungen stärker an, bei anderen entwickeln sich Einstellung und Verhaltensintention weniger systematisch.</p></li>
<li><p>Der Likelihood-Ratio-Test und die Informationskriterien zeigen, dass das Modell mit <em>random slope</em> wesentlich besser zu den Daten passt als das Modell nur mit <em>random intercept</em>.</p></li>
<li><p>Die Abbildung vermittelt einen Eindruck von der Treatment-Effekt-Heterogenität. Dargestellt ist die die Abweichung vom durchschnittlichen Effekt (0.4). Neben der Verteilung sollten auch die weiten Intervalle beachtet werden. Auf Basis von nur vier Beobachtungen pro Person lassen sich die individuellen Abweichungen vom durchschnittlichen Effekt nur recht unpräzise quantifizieren.</p></li>
</ul>
</div>
<div id="ebenen-überschreitende-interaktionen-cross-level-interactions" class="section level3 unnumbered">
<h3>Ebenen-überschreitende Interaktionen (cross-level interactions)</h3>
<ul>
<li><p><em>Random slopes</em> zeigen nur eine allgemeine Heterogenität zwischen den Personen. Wir wissen nun, dass der Effekt der Einstellung auf das Verhalten bei verschiedenen Personen unterschiedlich ausfällt. Wir wissen aber nicht, an welchen Eigenschaften der Personen dies liegen könnte.</p></li>
<li><p>Wenn wir theoretisch von Effekt-Heterogenität ausgehen oder empirisch durch ein <em>random slope</em> Modell Evidenz dafür gefunden haben, können wir in einem weiteren Schritt versuchen, diese Heterogenität zu erklären.</p></li>
<li><p>Dazu prüfen wir, ob eine Interaktion zwischen einem Personen-Merkmal und dem Prädiktor die allgemeine Heterogenität des Treatment-Effekts reduziert. Da das Personen-Merkmal auf Level 2 und der Prädiktor als über die Zeit variierende Variable auf Level 1 angesiedelt ist, spricht man hier auch von einer <em>cross-level interaction</em>.</p></li>
<li><p>Im Beispiel wollen wir betrachten, ob die Berücksichtigung des Geschlechts einen Teil der Treatment-Effekt-Heterogenität erklären kann.</p>
<ul>
<li>Dazu spezifizieren wir zwei weitere Modelle:
<ul>
<li><code>m_rs_sex1</code> enthält den einfachen Haupteffekt des Geschlechts.</li>
<li><code>m_rs_sex2</code> enthält zudem die Interaktion zwischen der Einstellung und dem Geschlecht.</li>
</ul></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="random-effects-modelle.html#cb117-1"></a><span class="co"># Modell mit Random Slope als Referenz</span></span>
<span id="cb117-2"><a href="random-effects-modelle.html#cb117-2"></a>m_rs =<span class="st"> </span><span class="kw">lmer</span>(verhint2 <span class="op">~</span><span class="st"> </span>ein2 <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(ein2 <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb117-3"><a href="random-effects-modelle.html#cb117-3"></a></span>
<span id="cb117-4"><a href="random-effects-modelle.html#cb117-4"></a><span class="co"># Modell mit HE Geschlecht</span></span>
<span id="cb117-5"><a href="random-effects-modelle.html#cb117-5"></a>m_rs_sex1 =<span class="st"> </span><span class="kw">lmer</span>(verhint2 <span class="op">~</span><span class="st"> </span>ein2 <span class="op">+</span><span class="st"> </span>C_sex <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(ein2 <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb117-6"><a href="random-effects-modelle.html#cb117-6"></a>m_rs_sex1 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verhint2 ~ ein2 + C_sex + factor(wave) + (ein2 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 6221
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.184 -0.424 -0.205  0.247  4.349 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  IDsosci  (Intercept) 0.231    0.481         
##           ein2        0.112    0.334    -0.62
##  Residual             0.639    0.799         
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                 Estimate Std. Error         df t value     Pr(&gt;|t|)    
## (Intercept)      0.82744    0.06062  758.00715   13.65      &lt; 2e-16 ***
## ein2             0.40322    0.02696  371.85383   14.96      &lt; 2e-16 ***
## C_sex           -0.00757    0.05279  386.27700   -0.14        0.886    
## factor(wave)2    0.11304    0.04829 1573.33025    2.34        0.019 *  
## factor(wave)3    0.19704    0.04834 1587.36240    4.08 0.0000480989 ***
## factor(wave)4    0.28810    0.04904 1646.41878    5.87 0.0000000051 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="random-effects-modelle.html#cb119-1"></a><span class="co"># Modell mit IA Geschlecht*Einstellung</span></span>
<span id="cb119-2"><a href="random-effects-modelle.html#cb119-2"></a>m_rs_sex2 =<span class="st"> </span><span class="kw">lmer</span>(verhint2 <span class="op">~</span><span class="st"> </span>ein2 <span class="op">*</span><span class="st"> </span>C_sex <span class="op">+</span><span class="st"> </span><span class="kw">factor</span>(wave) <span class="op">+</span><span class="st"> </span>(ein2 <span class="op">|</span><span class="st"> </span>IDsosci), <span class="dt">data =</span> d)</span>
<span id="cb119-3"><a href="random-effects-modelle.html#cb119-3"></a>m_rs_sex2 <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">summary</span>(<span class="dt">correlation =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<pre><code>## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [
## lmerModLmerTest]
## Formula: verhint2 ~ ein2 * C_sex + factor(wave) + (ein2 | IDsosci)
##    Data: d
## 
## REML criterion at convergence: 6224
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -3.190 -0.432 -0.213  0.244  4.340 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr 
##  IDsosci  (Intercept) 0.230    0.480         
##           ein2        0.111    0.333    -0.62
##  Residual             0.639    0.799         
## Number of obs: 2304, groups:  IDsosci, 576
## 
## Fixed effects:
##                Estimate Std. Error        df t value Pr(&gt;|t|)    
## (Intercept)      0.8733     0.0770  584.4186   11.34  &lt; 2e-16 ***
## ein2             0.3702     0.0435  375.7244    8.51  4.1e-16 ***
## C_sex           -0.0811     0.0932  458.4467   -0.87     0.38    
## factor(wave)2    0.1128     0.0483 1573.3027    2.34     0.02 *  
## factor(wave)3    0.1973     0.0483 1587.2271    4.08  4.7e-05 ***
## factor(wave)4    0.2877     0.0490 1646.3174    5.87  5.3e-09 ***
## ein2:C_sex       0.0527     0.0551  367.9806    0.96     0.34    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## convergence code: 0
## Model failed to converge with max|grad| = 0.00291019 (tol = 0.002, component 1)</code></pre>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="random-effects-modelle.html#cb121-1"></a><span class="co"># Wald-Test</span></span>
<span id="cb121-2"><a href="random-effects-modelle.html#cb121-2"></a><span class="kw">anova</span>(m_rs, m_rs_sex1, m_rs_sex2)</span></code></pre></div>
<pre><code>## Data: d
## Models:
## m_rs: verhint2 ~ ein2 + factor(wave) + (ein2 | IDsosci)
## m_rs_sex1: verhint2 ~ ein2 + C_sex + factor(wave) + (ein2 | IDsosci)
## m_rs_sex2: verhint2 ~ ein2 * C_sex + factor(wave) + (ein2 | IDsosci)
##           Df  AIC  BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq)
## m_rs       9 6211 6262  -3096     6193                        
## m_rs_sex1 10 6213 6270  -3096     6193  0.02      1       0.89
## m_rs_sex2 11 6214 6277  -3096     6192  0.92      1       0.34</code></pre>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="random-effects-modelle.html#cb123-1"></a><span class="co"># Reduktion der Varianz in random slope durch Interaktion</span></span>
<span id="cb123-2"><a href="random-effects-modelle.html#cb123-2"></a><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>(<span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m_rs_sex2)<span class="op">$</span>IDsosci[<span class="st">&quot;ein2&quot;</span>, <span class="st">&quot;ein2&quot;</span>]<span class="op">/</span><span class="kw">as.numeric</span>(<span class="kw">VarCorr</span>(m_rs_sex1)<span class="op">$</span>IDsosci[<span class="st">&quot;ein2&quot;</span>, </span>
<span id="cb123-3"><a href="random-effects-modelle.html#cb123-3"></a>    <span class="st">&quot;ein2&quot;</span>])))</span></code></pre></div>
<pre><code>## [1] 0.0047</code></pre>
<ul>
<li>Das Geschlecht macht nur einen unwesentlichen Unterschied in der Intention, sich mit Personen außerhalb des Haushalts zu treffen, aus (<code>m_rs_sex1</code>).</li>
<li>Der Effekt der Einstellung auf die Intention unterscheidet sich kaum für Männer und Frauen (<code>m_rs_sex2</code>). Wichtig: In diesem Modell mit Interaktionseffekt haben die Koeffizienten der Prädiktoren eine andere Bedeutung als im Modell ohne Interaktionseffekt. Sie quantifizieren nicht mehr “Haupteffekte”, sondern “einfache” Effekte (<em>simple effects</em>). Der Koeffizient für <code>ein2</code> quantifiziert den Effekt, wenn <code>C_sex</code> gleich 0 ist — also den Effekt für Männer. Der Koeffizient des Interaktionsterms <code>ein2:C_sex</code> quantifiziert den Unterschied im Effekt zwischen Männern und Frauen.</li>
<li>Der Likelihood-Ratio-Test und die Informationskriterien zeigen, dass weder die Aufnahme des Geschlechts noch die Interaktion der Einstellungen mit dem Geschlecht zur Verbesserung des Modells beitragen.</li>
<li>Durch den Vergleich der Varianz der <em>random slopes</em> zwischen <code>m_rs_sex1</code> und <code>m_rs_sex2</code> können wir quantifizieren, welchen Anteil der Effekt-Heterogenität durch die Interaktion erklärt werden kann. In diesem Beispiel ist die Erklärungskraft der Interaktion zu vernachlässigen.</li>
<li>Ein “erfolgreiches” Modell mit <em>random slopes</em> und <em>cross-level interaction</em> findet ihr in der folgenden Übungsaufgabe.</li>
</ul>
</div>
</div>
<div id="übungsaufgaben-5" class="section level2">
<h2><span class="header-section-number">4.8</span> Übungsaufgaben 5</h2>
<ol style="list-style-type: decimal">
<li>Schätze den kausalen Effekt der Einstellung zum Verhalten, weniger als 1.5m Abstand zu Personen zu halten, die nicht im gleichen Haushalt leben (<code>ein3</code>), auf die diesbezügliche Verhaltensintention (<code>verhint3</code>). Berücksichtige dabei die Periodeneffekte der Panelwellen. Siehe dazu auch Übung 4.
<ul>
<li>Schätze zuerst ein geeignetes Null-Modell mit <em>random intercept</em> als Referenz.</li>
<li>Schätze dann das <em>random intercept</em> Panelmodell.</li>
<li>Lasse den Effekt nun um den durchschnittlichen Effekt variieren. Prüfe, ob die Daten für Effekt-Heterogenität sprechen.</li>
<li>Prüfe, ob sich der Effekt zwischen Personen ab 50 Jahren und Jüngeren unterscheidet. Wie stark kann das Berücksichtigen dieser Interaktion die Effekt-Heterogenität verringern?</li>
</ul></li>
<li>Spezifiziere, schätze und interpretiere ein eigenes <em>random effects</em> Panelmodell mit <em>random slope</em> und <em>cross-level interaction</em> mit Daten aus dem Beispieldatensatz. Beachte dabei, dass wir hier an die Grenzen der Informationshaltigkeit der Daten für eine ML-Schätzung stoßen. Es ist recht wahrscheinlich, dass singuläre Fits oder nicht konvergierte Modelle vorkommen werden.</li>
</ol>

</div>
</div>
<h3>Literatur</h3>
<div id="refs" class="references">
<div id="ref-barrRandomEffectsStructure2013">
<p>Barr, Dale J., Roger Levy, Christoph Scheepers, and Harry J. Tily. 2013. “Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.” <em>Journal of Memory and Language</em> 68 (3): 255–78. <a href="https://doi.org/http://dx.doi.org/10.1016/j.jml.2012.11.001">https://doi.org/http://dx.doi.org/10.1016/j.jml.2012.11.001</a>.</p>
</div>
<div id="ref-bellFixedRandomEffects2019">
<p>Bell, Andrew, Malcolm Fairbrother, and Kelvyn Jones. 2019. “Fixed and Random Effects Models: Making an Informed Choice.” <em>Quality &amp; Quantity</em> 53 (2): 1051–74. <a href="https://doi.org/10.1007/s11135-018-0802-x">https://doi.org/10.1007/s11135-018-0802-x</a>.</p>
</div>
<div id="ref-plm2008">
<p>Croissant, Yves, and Giovanni Millo. 2008. “Panel Data Econometrics in R: The plm Package.” <em>Journal of Statistical Software</em> 27 (2): 1–43. <a href="https://doi.org/10.18637/jss.v027.i02">https://doi.org/10.18637/jss.v027.i02</a>.</p>
</div>
<div id="ref-gelmanDataAnalysisUsing2006">
<p>Gelman, A., and J. Hill. 2006. <em>Data Analysis Using Regression and Multilevel/Hierarchical Models</em>. New York: Cambridge University Press.</p>
</div>
<div id="ref-matuschekBalancingTypeError2017">
<p>Matuschek, Hannes, Reinhold Kliegl, Shravan Vasishth, Harald Baayen, and Douglas Bates. 2017. “Balancing Type I Error and Power in Linear Mixed Models.” <em>Journal of Memory and Language</em> 94 (June): 305–15. <a href="https://doi.org/10.1016/j.jml.2017.01.001">https://doi.org/10.1016/j.jml.2017.01.001</a>.</p>
</div>
<div id="ref-vaiseyWhatYouCan2017">
<p>Vaisey, Stephen, and Andrew Miles. 2017. “What You Can—and Can’t—Do with Three-Wave Panel Data.” <em>Sociological Methods &amp; Research</em> 46 (1): 44–67. <a href="https://doi.org/10.1177/0049124114547769">https://doi.org/10.1177/0049124114547769</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="fixed-effects-modelle.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hybride-within-between-modelle.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["workshop_panel.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
