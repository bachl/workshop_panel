[
["index.html", "Mini-Workshop Panel Data Analysis Abschnitt 1 Überblick 1.1 Inhalt des virtuellen Mini-Workshops 1.2 Welche Inhalte wir nicht behandeln 1.3 Aufbau des Workshops", " Mini-Workshop Panel Data Analysis Marko Bachl (mit Material von Michael Scharkow) Sommersemester 2020 | IJK Hannover Abschnitt 1 Überblick 1.1 Inhalt des virtuellen Mini-Workshops Der Mini-Workshop bietet eine pragmatische Einführung in die Analyse von Panel-Daten aus Erhebungen mit mindestens drei Wellen. Konkret liegt der Fokus auf so genannten micro panels, also Datensätzen mit relativ vielen Fällen und relativ wenigen Messzeitpunkten (das klassische Befragungspanel). In der Analyse beschränken uns hier auf Varianten der linearen Regressionsmodelle. Wir beginnen mit den grundlegenden fixed effects und random effects Modellen. Dann betrachten wir das within-between Modell, das als eine Integration des fixed effects Modell in das random effects Modell verstanden werden kann. Dies ist auch eine gute Grundlage für den Einstieg in verschiedene Erweiterungen, zum Beispiel zu verallgemeinerten linearen Modellen oder zu Wachstumskurvenmodellen. Diese sind aber nicht Teil dieses Mini-Workshops. Wir schätzen die Modelle mit etablierten least-squares und maximum likelihood Methoden. Gerade bei den within-between Modellen sind bayesianische Schätzmethoden, z.B. MCMC sampling (implementiert in Stan), unabhängig von statistisch-philosophischen Überlegungen sehr interessant. Bei Interesse kann ich nur empfehlen, hier einen Einstieg zu finden. Zur Aufbereitung der Daten, Visualisierung und Modell-Schätzung verwenden wir R mit dem tidyverse und eine kleine Zahl spezialisierter Pakete für die Modellschätzung. Der Fokus des Workshops liegt aber auf der substantiellen Arbeit mit den Modellen, nicht auf der Umsetzung in R. 1.2 Welche Inhalte wir nicht behandeln Der Workshop ist kein Statistik- oder Ökonometrie-Kurs. Ich bin — wie auch ihr — ausgebildeter Sozialwissenschaftler. Die statistischen Grundlagen, auf denen der Workshop aufbaut, gehen aus den Grundlagentexten (Bell and Jones 2015; Vaisey and Miles 2017) hervor. Grundkenntnisse in R setze ich voraus, insbesondere Datentransformationen innerhalb des tidyverse. Wir werden aber keine komplizierten Dinge in R tun. Auch ohne weiterführende R-Kenntnisse sollten die Inhalte des Workshops in Bezug auf die datenanalytischen Verfahren klar werden. Wir werden nicht viel Zeit auf die verschiedenen Schätzer, deren Effizienz und Bias, die verschiedenen Algorithmen und Datentransformationen verwenden. Wir werden keine Beweise oder Ableitungen besprechen. Wir setzen keine Kenntnisse in Matrixalgebra voraus — weder meiner- noch eurerseits. Wir behandeln einen sehr kleinen Ausschnitt möglicher Modelle für Panel-Daten. Wir konzentrieren uns auf regressionsbasierte Modelle zur Schätzung kausaler Effekte. Damit behandeln wir insbesondere nicht die vielfältigen Verfahren, die in einem SEM-Framework verortet sind: längsschnittliche Messmodelle, Prozessmodelle, (random intercept) cross-lagged panel Modelle, Latent State-Trait Modelle, etc. Auch Modelle, in denen die Zeit-Variable als kontinuierlich (z.B. Tag der Erhebung im Gegensatz zu Indikator für Panelwelle) verwendet wird (z.B. Continuous Time Structural Equation Modeling), behandeln wir nicht. Fehlende Daten (Panelmortalität, Ausfall von Einheiten in einzelnen Wellen) sind ein großes Thema in der Längsschnittanalyse. Wir werden es hier ignorieren, bis auf den Hinweis, dass alle Fälle, die in mindestens zwei bzw. drei Wellen Daten haben, grundsätzlich Informationen zur Schätzung beitragen. 1.3 Aufbau des Workshops Inhaltlicher Aufbau: Siehe Kapitel-Gliederung Material Dieses Dokument + R Skripte: (Hoffentlich) mehr oder weniger selbsterklärendes Material Kuratierte Form ist dieses HTML-Dokument Es gibt auch ein PDF, das ich aber nicht formatiert habe Screencast: Ich gehe über das Material und erkläre es auf der Audio-Spur. Mal sehen, wie hilfreich das ist. Die Screencasts stelle ich über das LMS zur Verfügung. Übungen: Zu einigen Analysen gibt es Übungsaufgaben. Bei der Wiederholung geht es darum, die Modelle leicht zu verändern (durch Anpassen der R-Skripte aus dem Material) und die Ergebnisse der angepassten Modelle zu interpretieren. Bei der Anwendung geht es darum, in Anlehnung an die Beispiele eigene Modelle zu spezifizieren und diese zu interpretieren. Pakete Wir verwenden die folgenden Pakete if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(tidyverse, ggstance, broom, broom.mixed, haven, plm, lmtest, lme4, lmerTest, performance) theme_set(theme_bw()) # ggplot theme tibble(package = c(&quot;R&quot;, sort(pacman::p_loaded()))) %&gt;% mutate(version = map_chr(package, ~as.character(pacman::p_version(package = .x)))) %&gt;% knitr::kable() package version R 3.6.2 broom 0.5.4 broom.mixed 0.2.4 dplyr 0.8.4 forcats 0.4.0 ggplot2 3.2.1 ggstance 0.3.3 haven 2.2.0 lme4 1.1.21 lmerTest 3.1.2 lmtest 0.9.37 Matrix 1.2.18 pacman 0.5.1 performance 0.4.6 plm 2.2.3 purrr 0.3.3 readr 1.3.1 stringr 1.4.0 tibble 2.1.3 tidyr 1.0.2 tidyverse 1.3.0 zoo 1.8.7 Literatur "]
]
