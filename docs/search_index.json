[
["random-effects-modelle.html", "Abschnitt 4 Random effects Modelle 4.1 Einführung: Random effects Modelle für Paneldaten 4.2 Random effects Modelle mit plm 4.3 Kurze Einführung zu mixed effects Modellen 4.4 Übungsaufgaben 3 4.5 Random effects panel Modelle mit lme4", " Abschnitt 4 Random effects Modelle In diesem Abschnitt beschäftigen wir uns mit random effects Modellen. Zuerst führen wir die Modellklasse ein. Dann betrachten wir kurz, wie die Modelle in der Tradition der Ökonometrie mit plm spezifiziert werden können, bevor wir zur allgemeineren Umsetzung mit dem Paket für Mehrebenen- bzw. mixed effects Modelle lme4 kommen. 4.1 Einführung: Random effects Modelle für Paneldaten Modellspezifikation Anstatt für jede Einheit (Person) eine separate Konstante \\(\\alpha_i\\) zu schätzen, können wir den “soft constraint” (Gelman and Hill 2006, S. 257) setzen, dass die personenspezifischen Konstanten bzw. Residuen einer Verteilung folgen: \\(\\alpha_{i} ∼ \\mathcal{N}(\\mu_{\\alpha},\\sigma^2_\\alpha)\\) mit \\(i = 1,...,n\\) Das random effects Panel-Modell wird geschätzt als \\(y_{it}=x_{it}&#39;\\beta + z_i&#39;\\gamma + v_{it}\\) \\(v_{it} = \\alpha_{i} + u_{it}\\) mit \\(y_{it}\\) über Personen (\\(i\\)) und Zeit (\\(t\\)) variierendes Kriterium, \\(x_{it}&#39;\\) über Personen und Zeit variierende Prädiktoren, \\(\\beta\\) Koeffizienten der über Personen und Zeit variierenden Prädiktoren, \\(z_i&#39;\\) über Personen variierende Prädiktoren, \\(\\gamma\\) Koeffizienten der über Personen variierenden Prädiktoren, \\(v_{it}\\) gesamter Fehlerterm, \\(\\alpha_{i}\\) personenspezifische Konstanten, \\(u_{it}\\) Residuen. Damit die Schätzer für \\(\\beta&#39;\\) unverzerrt sind, müssen zwei Annahmen erfüllt sein: Keine über die Zeit konstante Heterogenität, deren Ursache nicht im Modell ist \\({\\displaystyle \\operatorname {E} (\\alpha _{i}|x_{it})=\\operatorname {E} (\\alpha _{i})=0}\\) Keine über die Zeit variierende Heterogenität, deren Ursache nicht im Modell ist \\({\\displaystyle \\operatorname {E} (u_{it}|x_{it},\\alpha _{i})=0,\\quad t=1,...,T.}\\) Vorteile der random effects Modelle für Panel-Daten Schätzer für über die Zeit konstante Prädiktoren und gleichzeitig Konstante für jede Person. Schätzer von über die Zeit variierenden und über die Zeit konstanten Prädiktoren können verglichen werden. Vorhersagen für neue Personen außerhalb der Stichprobe können unter Einbeziehung aller Informationen und unter Berücksichtigung der gesamten Unsicherheit gemacht werden. Die Annahme homogener Treatment-Effekte kann gelockert werden (mit dem within-between-Modell; siehe nächsten Abschnitt). Sind die Annahmen des random effects Modell für Paneldaten jemals erfüllt? The only difference between RE and FE lies in the assumption they make about the relationship between υ and the observed predictors: RE models assume that the observed predictors in the model are not correlated with \\(v\\) while FE models allow them to be correlated. A moment’s reflection on what \\(v\\) represents—–all unmeasured time-constant factors about the respondent—–should lead anyone to realize that the RE assumption is heroic in social research, to say the least. The idea that the characteristics we don’t (or can’t) measure (like personality or genetic influences) are uncorrelated with the things we usually do measure (like income or church attendance) is implausible. — Vaisey and Miles (2017), S. 47 Hausman-Test Der Hausman-Test prüft, ob das random effects Modell konsistent ist (~ geschätzt werden darf). Nach der traditionellen Sichtweise der Ökonometrie spricht das Verwerfen der \\(H_0\\) im Hausman-Test gegen das Schätzen eines random effects Modells. Da das random effects Modell in der Lage ist, Forschungsfragen zu beantworten, an denen das fixed effects Modell per Definition scheitert, lässt sich die Wahl des random effects Modells auch inhaltlich begründen — ohne einen Hausman-Test durchzuführen. Der Hausman-Test kann mit der Funktion plm::phtest() durchgeführt werden. phtest(verh1 ~ verhint1, data = d, index = &quot;IDsosci&quot;) ## ## Hausman Test ## ## data: verh1 ~ verhint1 ## chisq = 300.58, df = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: one model is inconsistent In diesem Beispiel spricht der Hausman-Test dagegen, ein random effects Modell zu schätzen. 4.2 Random effects Modelle mit plm Random effects Modelle für Paneldaten in der ökonometrischen Tradition lassen sich mit plm schätzen. Die Schätzung erfolgt auf Basis von Transformationen im Least-squares-Framework (ich habe keine Ahnung, wie das funktioniert). Ich selbst nutze diese Funktionalität in der Praxis nicht. Die Modellspezifikationen sind im Folgenden der Vollständigkeit halber kurz aufgeführt. # Einfaches RE Modell d %&gt;% plm(verh1 ~ verhint1, data = ., index = &quot;IDsosci&quot;, model = &quot;random&quot;) %&gt;% summary() ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., model = &quot;random&quot;, index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.32064 0.56625 0.812 ## individual 0.07443 0.27283 0.188 ## theta: 0.2799 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.444787 -0.105500 -0.072748 0.038935 3.647334 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.56905 0.02764 20.587 &lt; 2.2e-16 *** ## verhint1 0.53198 0.01195 44.517 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1531.9 ## Residual Sum of Squares: 823.22 ## R-Squared: 0.46262 ## Adj. R-Squared: 0.46239 ## Chisq: 1981.77 on 1 DF, p-value: &lt; 2.22e-16 # Mit zusätzlichem Faktor Welle d %&gt;% plm(verh1 ~ verhint1, data = ., index = c(&quot;IDsosci&quot;, &quot;wave&quot;), model = &quot;random&quot;, effect = &quot;twoways&quot;) %&gt;% summary() ## Twoways effects Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., effect = &quot;twoways&quot;, ## model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;)) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.316542 0.562621 0.802 ## individual 0.075459 0.274699 0.191 ## time 0.002634 0.051326 0.007 ## theta: 0.2845 (id) 0.5845 (time) 0.2541 (total) ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.479856 -0.114351 -0.069742 0.041790 3.672248 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.572357 0.038978 14.684 &lt; 2.2e-16 *** ## verhint1 0.530146 0.012141 43.666 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1494.2 ## Residual Sum of Squares: 817.26 ## R-Squared: 0.45304 ## Adj. R-Squared: 0.4528 ## Chisq: 1906.68 on 1 DF, p-value: &lt; 2.22e-16 # Mit FE für Welle d %&gt;% plm(verh1 ~ verhint1 + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;random&quot;) %&gt;% summary() ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1 + factor(wave), data = ., model = &quot;random&quot;, ## index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.31654 0.56262 0.808 ## individual 0.07546 0.27470 0.192 ## theta: 0.2845 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.504920 -0.134512 -0.067223 0.050991 3.693574 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.5664150 0.0330635 17.1311 &lt; 2e-16 *** ## verhint1 0.5300058 0.0121863 43.4918 &lt; 2e-16 *** ## factor(wave)2 -0.0453317 0.0353413 -1.2827 0.19960 ## factor(wave)3 0.0672896 0.0353937 1.9012 0.05728 . ## factor(wave)4 0.0028266 0.0358023 0.0789 0.93707 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1521.3 ## Residual Sum of Squares: 816.62 ## R-Squared: 0.46322 ## Adj. R-Squared: 0.46229 ## Chisq: 1983.94 on 4 DF, p-value: &lt; 2.22e-16 # Mit Prädiktor auf Personenebene (funktioniert nicht in FE, siehe oben) d %&gt;% plm(verh1 ~ verhint1 + C_sex, data = ., index = c(&quot;IDsosci&quot;, &quot;wave&quot;), model = &quot;random&quot;, effect = &quot;twoways&quot;) %&gt;% summary() ## Twoways effects Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1 + C_sex, data = ., effect = &quot;twoways&quot;, ## model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;)) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.316542 0.562621 0.803 ## individual 0.074785 0.273468 0.190 ## time 0.002634 0.051326 0.007 ## theta: 0.283 (id) 0.5845 (time) 0.2527 (total) ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.443232 -0.153532 -0.048115 0.047936 3.701927 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.642039 0.045454 14.1249 &lt; 2.2e-16 *** ## verhint1 0.527641 0.012153 43.4168 &lt; 2.2e-16 *** ## C_sex -0.106628 0.035587 -2.9963 0.002733 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1497.8 ## Residual Sum of Squares: 815.06 ## R-Squared: 0.45581 ## Adj. R-Squared: 0.45534 ## Chisq: 1927.32 on 2 DF, p-value: &lt; 2.22e-16 4.3 Kurze Einführung zu mixed effects Modellen Auch bekannt als random effects, multilevel/Mehrebenen- oder hierarchical/hierarchische Modelle; das Begriffswirrwarr ist ein großes Problem, das Denglisch macht es nicht besser (Gelman and Hill 2006). siehe auch: https://twitter.com/chelseaparlett/status/1262390299785072647 Wer mit diesen Modellen bereits vertraut ist, kann diesen Absatz überspringen. Ganz allgemein gesprochen sind mixed effects Modelle Regressionsmodelle für Beobachtungen von Einheiten, die in irgendeiner Art miteinander zu tun haben, also nicht unabhängig voneinander sind. Typische Beispiele sind Schüler*innen in Klassen in Schulen, Patient*innen in Krankenhäusern, Wähler*innen in Wahlkreisen, … . Paneldaten haben immer eine hierarchische Struktur: Beobachtungen (Level 1) sind innerhalb der Personen (Level 2) gruppiert. Die Bezeichnung mixed effects geht darauf zurück, dass in den Modellen sowohl random effects (Koeffizienten, die zwischen den Fällen innerhalb einer Gruppierung auf einer höheren Ebene variieren) als auch fixed effects (Koeffizienten, die für alle Fälle gleich sind) spezifiziert werden. Warum wir in den Sozialwissenschaften nicht nur die traditionellen ökonometrischen Modelle verwenden Econometrics deal mostly with non-experimental data. Great emphasis is put on specification procedures and misspecification testing. Model specifications tend therefore to be very simple, while great attention is put on the issues of endogeneity of the regressors, dependence structures in the errors and robustness of the estimators under deviations from normality. — Croissant and Millo (2008) Historische Gründe und disziplinäre Entwicklungen: z.B. Ökonometriker bevorzugen fast immer Least Squares, andere Disziplinen Maximum Likelihood oder Bayesianische Methoden. Viele Sozialwissenschaften haben kompliziertere Datenstrukturen als das typische ökonometrische Panel, z.B. mehr als zwei Ebenen, nicht-hierarchische Datenstrukturen, heterogene Treatment-Effekte, … . Die flexible Modellierung solcher Strukturen gilt oft als wichtiger als die enger gefassten Schätz- und Identifikationsfragen, die Ökonometriker umtreiben. Die Ökonometrie betrachtet Abhängigkeitsstrukturen als eine Störgröße, deren Einfluss in den Modellen beschränkt werden soll. Andere sozialwissenschaftliche Disziplinen interessieren sich (auch, gerade) für diese Strukturen und ihre Konsequenzen. 4.3.1 Vorteile der mixed effects Modelle Mixed effects Modelle bieten einen einheitlichen Rahmen für die Modellierung von Datensätzen mit jeder Art von Abhängigkeitsstrukturen, seien sie hierarchisch, längsschnittlich oder eine Kombination aus beidem. Die Schätzung basiert auf (Restricted) Maximum Likelihood, der Umstieg auf bayesianische Schätzmethoden ist relativ einfach. Im Vergleich dazu erfordern die Optionen, Tests und transformationsbasierten Least-Squares-Schätzer in der ökonometrischen Tradition erheblich mehr Einarbeitung, wenn man nicht auf eine entsprechende Ausbildung aufbauen kann. Wenn man die Logik von mixed effects Modellen einmal verstanden hat, kann man die Modelle für verschiedenste Forschungsfragen und -desings einsetzen, u.a. Ländervergleiche in der komparativen Forschung, experimentelle within-subject Desings, verschiedene Längsschnittsdesigns wie experience sampling, Tagebücher, digitale Kommunikations- und Verhaltensspuren, … . Das Denken in Varianzkomponenten (siehe nächster Absatz) hilft uns, konzeptionell über die Bedeutung von Prädiktoren auf verschiedenen Ebenen nachzudenken. Einfache praktische Umsetzung: Das Paket lme4 ist einfach zu verwenden, wenn man bereits etwas Erfahrung mit stats::lm() hat, und auch ein guter Einstieg in ähnlich aufgebaute Pakte zur bayesianischen Schätzung solcher Modelle (z.B. rstanarm, brms). Varianzdekomposition und Intraklassen-Korrelation Wir interessieren uns dafür, welcher Anteil in der Varianz in \\(Y\\) auf stabile Unterschiede zwischen den Personen zurück geht und welcher auf Veränderungen innerhalb von Personen (potentielle kausale Effekte). In mixed effects Modellen können wir die Varianz-Anteile in einem so genannten Null-Modell, das nur die Struktur der Daten abbildet, aber keine Prädiktoren enthält, bestimmen: \\(y_{it}= \\alpha + v_{it}\\) und \\(v_{it} = \\alpha_{i}+ u_{it}\\) Ohne die Konstante \\(\\alpha\\) erhalten wir \\(y_{it} = \\alpha_{i}+ u_{it}\\) Da die Varianzen von \\(\\alpha_i\\) und \\(u_{it}\\) im Modell geschätzt werden, können wir den Anteil der personenspezifischen (Level 2) Varianz und den Anteil der idiosynkratischen Varianz in \\(Y\\) berechnen. Der Anteil der Level 2 Varianz an der gesamten Varianz wird auch als Intraklassen-Korrelation (intra-class correlation, ICC, \\(\\rho\\)) bezeichnet. In unserem Beispiel möchten wir wissen, welcher Anteil der Varianz im Verlassen der Wohnung ohne triftigen Grund auf konstante Unterschiede zwischen den Personen zurückgeht (manche Personen wollen oder müssen, aus welchen Gründen auch immer, die Wohnung häufiger verlassen als andere). Dazu spezifizieren wir das Null-Modell mit lme4::lmer(). Das genaue Vorgehen beim Spezifizieren der Modelle folgt im nächsten Abschnitt. Wichtig ist an dieser Stelle, dass mit (1 | IDsosci) jede Person eine eigene Konstante erhält (\\(\\alpha_i\\) in der Gleichung oben), die als Abweichung vom Gewaltmittel (\\(\\alpha\\)) geschätzt wird. # Null-Modell m0 = lmer(verh1 ~ 1 + (1 | IDsosci), data = d) m0 %&gt;% summary() ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: verh1 ~ 1 + (1 | IDsosci) ## Data: d ## ## REML criterion at convergence: 5576.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.1387 -0.2268 -0.1212 -0.1212 4.8131 ## ## Random effects: ## Groups Name Variance Std.Dev. ## IDsosci (Intercept) 0.5938 0.7706 ## Residual 0.4065 0.6376 ## Number of obs: 2304, groups: IDsosci, 576 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 1.52865 0.03475 574.99999 43.99 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # ICC &#39;von Hand&#39; round(0.5938/(0.5938 + 0.4065), 3) ## [1] 0.594 # Mit performance::icc() icc(m0) ## # Intraclass Correlation Coefficient ## ## Adjusted ICC: 0.594 ## Conditional ICC: 0.594 Die Informationen zu den Varianzkomponenten findet sich im Output von summary() unter Random effects. Aus diesen Angaben können wir die ICC berechnen. Oder wir nutzen die Funktion performance::icc(). Fast 60% der Varianz im Verlassen der Wohnung geht auf Unterschiede zwischen Personen zurück. Im fixed effects Modell wird diese Varianz einfach aus den Daten entfernt. Über mehr als die Hälfte der Unterschiede können wir mit diesen Modellen also per Spezifikationslogik nichts aussagen. Kausale Effekte innerhalb der Personen können damit maximal für 40% der Varianz verantwortlich sein. Allerdings müssen wir dabei beachten, dass auch der gesamte Messfehler (zumindest die zufällige Messfehlervarianz nach der CTT) ebenfalls in diesem Varianzanteil steckt. Wir können die Schätzer der random effects für die Personen im Null-Modell auch dazu nutzen, uns einen Überblick zu verschaffen über die Verteilung der personenspezifischen Tendenz, die Wohnung ohne triftigen Grund zu verlassen. Die Schätzer können wir mit ranef() extrahieren, mit broom.mixed::augment() erhalten wir zusätzlich Standardfehler und Konfidenzintervalle in einem tidy data.frame. # tibble der RE und ihre Verteilung als Histogramm m0 %&gt;% ranef() %&gt;% augment(ci.level = 0.95) %&gt;% as_tibble() %&gt;% print(n = 12) %&gt;% ggplot(aes(estimate)) + geom_histogram() ## # A tibble: 576 x 8 ## grp variable level estimate qq std.error lb ub ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 IDsosci (Intercept) 01PQGO -0.451 -3.13 0.295 -1.03 0.126 ## 2 IDsosci (Intercept) 02E6C8 -0.451 -2.79 0.295 -1.03 0.126 ## 3 IDsosci (Intercept) 050IPY 1.47 1.53 0.295 0.892 2.05 ## 4 IDsosci (Intercept) 05J4R8 0.189 0.571 0.295 -0.388 0.766 ## 5 IDsosci (Intercept) 08BDZJ 1.26 1.41 0.295 0.679 1.83 ## 6 IDsosci (Intercept) 0BHGLF 0.402 0.779 0.295 -0.175 0.980 ## 7 IDsosci (Intercept) 0EB6C1 -0.451 -2.62 0.295 -1.03 0.126 ## 8 IDsosci (Intercept) 0EO9L2 2.32 2.02 0.295 1.75 2.90 ## 9 IDsosci (Intercept) 0F5L9Z 1.68 1.63 0.295 1.11 2.26 ## 10 IDsosci (Intercept) 0KAKHF 2.54 2.05 0.295 1.96 3.11 ## 11 IDsosci (Intercept) 0KYYAJ -0.238 -0.00653 0.295 -0.815 0.339 ## 12 IDsosci (Intercept) 0ONV4O -0.0245 0.321 0.295 -0.602 0.553 ## # … with 564 more rows # RE mit 95%-CIs (aus Darstellungsgründen nur jede fünfte Person) m0 %&gt;% ranef() %&gt;% augment(ci.level = 0.95) %&gt;% slice(seq(1, nrow(.), by = 5)) %&gt;% ggplot(aes(estimate, level, xmin = lb, xmax = ub)) + geom_pointrangeh() + labs(y = &quot;IDsosci&quot;) Der random effects Schätzer quantifziert die Abweichung vom Schätzer der Konstanten in der Gesamtpopulation, hier die Abweichung von 1.5. Die diskreten Werte kommen zustande, da es (wie bei einer Index-Bildung) mit 5 Ausprägungen und 4 Wellen nur eine begrenzte Anzahl an möglichen Personen-Mittelwerten gibt. Die Mehrheit der Personen tendiert dazu, eher selten ihre Wohnung ohne triftigen Grund zu verlassen. Mehr als ein Gruppierungsfaktor Mit lme4 können prinzipiell beliebig viele und arbiträr angeordnete (sie müssen nicht hierarchisch sein) random effects in ein Modell aufgenommen werden. Zu viele Faktoren oder Faktoren mit zu wenigen Ausprägungen können aber zu Problemen bei der (restricted) maximum likelihood Schätzung führen (Bayesianische Schätzverfahren können hier helfen). Wir könnten z.B. die geographische Region, in der die Personen leben, als einen weiteren, hierarchisch oberhalb der Person angesiedelten Faktor aufnehmen. Hätten wir eine sehr große Stichprobe mit ausreichend geographischer Variation, wäre dies spannend, da wir uns durchaus regionale Unterschiede vorstellen könnten. In Panel-Modellen liegt die Idee nahe, random effects für die Panel-Wellen aufzunehmen. Dieser Faktor ist nicht hierarchisch zu den Personen. Stattdessen gehört jede Messung zu genau einer Person und genau einer Welle. Diese Spezifikation wird auch kreuzklassifiziert / cross-classified / crossed genannt. Wir nehmen den Faktor Welle auf, indem wir + (1 | wave) in der Modell-Formel ergänzen. Da wir nur Daten aus vier Wellen haben und die Varianz zwischen den Wellen sehr klein ist, kommt die restricted maximum likelihood Schätzung hier an ihre Grenzen. Eine Warnung wird ausgegeben. Wir könnten das Problem durch Herumfrickeln an den Einstellungen des Optimizer beheben, würden aber inhaltlich zu keiner anderen Schlussfolgerungen kommen. Um den Einstieg in die technischen Details zu vermeiden, verwenden wir hier aber das Modell mit der Warnmeldung. Im Weiteren lösen wir das Problem, indem wir fixed effects für die Wellen aufnehmen. # Null-Modell mit zwei Gruppierungsfaktoren lmer(verh1 ~ 1 + (1 | IDsosci) + (1 | wave), data = d) %&gt;% icc(by_group = TRUE) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.00262857 (tol = 0.002, component 1) ## # ICC by Group ## ## Group | ICC ## --------------- ## IDsosci | 0.595 ## wave | 0.018 Nur ein sehr geringer Teil der gesamten Varianz geht auf über alle Personen homogene Veränderungen zwischen den Wellen zurück. 4.4 Übungsaufgaben 3 Analysiere die Varianzkomponenten in der Intention, weniger als 1.5m Abstand zu einer Person zu halten, die nicht im eigenen Haushalt lebt (verhint3). Spezifiziere zuerst ein Modell mit random effects für die Personen. Nimm dann die Welle als zweiten Gruppierungsfaktor auf. Analysiere die Varianzkomponenten in weiteren Variablen, die dich interessieren. 4.5 Random effects panel Modelle mit lme4 Wiederholung der wichtigsten Begriffe Ganz allgemein gesprochen ist ein mixed effects Modell ein Modell, das fixed und random Koeffizienten enthält. gelmanDataAnalysisUsing2006 verwenden die (imo) besser verständlichen Begriffe varying intercepts (für zwischen Einheiten auf höherer Ebene variierende Regressionskonstanten) und varying slopes (für zwischen Einheiten auf höherer Ebene variierende Regressionskoeffizienten). Im random effects Panelmodell sind die Einheiten auf höherer Ebene die Personen. Die Konstanten bzw. Koeffizienten variieren zwischen Personen. In der Sprache von mixed effects Modellen wird das einfachste Modell als fixed slope, random (or varying) intercept Modell bezeichnet. Die Regressionskonstante variiert zwischen den Personen (jede Person erhält eine eigene Konstante, die aus einer Normalverteilung mit der Populationskonstante als Mittelwert und der personenspezifischen Varianz als Streuung stammt). Die übrigen Regressionskoeffizienten sind für alle Personen gleich (fixed). 4.5.1 Einfaches random effects panel Modell Wir modellieren wieder die Häufigkeit, ohne triftigen Grund die Wohnung zu verlassen, in Abhängigkeit der Intention, dies zu tun. Die Spezifikation in lme4::lmer() folgt der in R üblichen Logik. Das Modell enthält verhint1 als Prädiktor mit einem für alle Personen gleichen Koeffizienten (homogener Treatment-Effekt) und (1 | IDsosci) als varying intercept für jede Person. Hinweis: lme4 selbst weist keine Freiheitsgrade und entsprechend auch keine p-Werte für die Koeffizienten aus. Wenn zusätzlich das Paket lmerTest geladen wurde, werden diese automatisch ergänzt. m1 = lmer(verh1 ~ verhint1 + (1 | IDsosci), data = d) m1 %&gt;% summary() ## Linear mixed model fit by REML. t-tests use Satterthwaite&#39;s method [ ## lmerModLmerTest] ## Formula: verh1 ~ verhint1 + (1 | IDsosci) ## Data: d ## ## REML criterion at convergence: 4553.7 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.5240 -0.2022 -0.0848 0.1650 5.7931 ## ## Random effects: ## Groups Name Variance Std.Dev. ## IDsosci (Intercept) 0.1114 0.3338 ## Residual 0.3412 0.5842 ## Number of obs: 2304, groups: IDsosci, 576 ## ## Fixed effects: ## Estimate Std. Error df t value Pr(&gt;|t|) ## (Intercept) 5.987e-01 2.872e-02 9.754e+02 20.85 &lt;2e-16 *** ## verhint1 5.155e-01 1.219e-02 1.747e+03 42.30 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Correlation of Fixed Effects: ## (Intr) ## verhint1 -0.765 Mit jedem Punkt auf der Skala zur Verhaltensintention steigt die Häufigkeit des Rausgehens ohne triftigen Grund um 0.5 Punkte. Wir können das Modell mit dem Prädiktor verhint1 mit dem Null-Modell vergleichen. Mit anova() erhalten wir verschiedene Informationskriterien und einen Likelihood Ratio (Wald) Test. Die Test-Statistik folgt einer \\(\\Chi^2\\)-Verteilung. Durch einen Vergleich der Varianzkomponenten der Modelle erhalten wir ein Maß, das konzeptionell ähnlich \\(\\Delta R^2\\) interpretiert werden kann. Die Funktion performance::r2(by_group = TRUE) implementiert diesen Vergleich für ein Modell und das Null-Modell. Die manuelle Berechnung ist auch schrittweise für mehre Modelle möglich, die zunehmend mehr Prädiktoren enthalten. Wichtig: Die \\(\\Delta R^2\\)-Logik funktioniert nur in Modellen mit identischen random effects. # Wald Test anova(m0, m1) ## Data: d ## Models: ## m0: verh1 ~ 1 + (1 | IDsosci) ## m1: verh1 ~ verhint1 + (1 | IDsosci) ## Df AIC BIC logLik deviance Chisq Chi Df Pr(&gt;Chisq) ## m0 3 5577.5 5594.7 -2785.7 5571.5 ## m1 4 4548.5 4571.5 -2270.3 4540.5 1030.9 1 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 # Reduktion der Varianz (delta R^2) - manuell 1 - (sigma(m1)^2/sigma(m0)^2) # L1 ## [1] 0.1606004 1 - (as.numeric(VarCorr(m1)$IDsosci)/as.numeric(VarCorr(m0)$IDsosci)) # L2 ## [1] 0.8124145 # Reduktion der Varianz (Delta R^2) - mit performance::r2 (Vergleicht immer mit # Null-Modell) r2(m1, by_group = TRUE) ## # Explained Variance by Level ## ## Level | R2 ## --------------- ## Level 1 | 0.161 ## IDsosci | 0.812 Literatur "]
]
