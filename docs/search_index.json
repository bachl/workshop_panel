[
["index.html", "Mini-Workshop Panel Data Analysis Abschnitt 1 Überblick 1.1 Inhalt des virtuellen Mini-Workshops 1.2 Welche Inhalte wir nicht behandeln 1.3 Aufbau des Workshops", " Mini-Workshop Panel Data Analysis Marko Bachl (mit Material von Michael Scharkow) Sommersemester 2020 | IJK Hannover Abschnitt 1 Überblick 1.1 Inhalt des virtuellen Mini-Workshops Der Mini-Workshop bietet eine pragmatische Einführung in die Analyse von Panel-Daten aus Erhebungen mit mindestens drei Wellen. Konkret liegt der Fokus auf sogenannten micro panels, also Datensätzen mit relativ vielen Fällen und relativ wenigen Messzeitpunkten (das klassische Befragungspanel). In der Analyse beschränken uns hier auf Varianten der linearen Regressionsmodelle. Wir beginnen mit den grundlegenden fixed effects und random effects Modellen. Dann betrachten wir das within-between Modell, das als eine Integration des fixed effects Modell in das random effects Modell verstanden werden kann. Dies ist auch eine gute Grundlage für den Einstieg in verschiedene Erweiterungen, zum Beispiel zu verallgemeinerten linearen Modellen oder zu Wachstumskurvenmodellen. Diese sind aber nicht Teil dieses Mini-Workshops. Wir schätzen die Modelle mit etablierten least-squares und maximum likelihood Methoden. Gerade bei den within-between Modellen sind bayesianische Schätzmethoden, z.B. MCMC sampling (implementiert in Stan), unabhängig von statistisch-philosophischen Überlegungen sehr interessant. Bei Interesse kann ich nur empfehlen, hier einen Einstieg zu finden. Zur Aufbereitung der Daten, Visualisierung und Modell-Schätzung verwenden wir R mit dem tidyverse und eine kleine Zahl speziallisierter Pakete für die Modellschätzung. Der Fokus des Workshops liegt aber auf der substantiellen Arbeit mit den Modellen, nicht auf der Umsetzung in R. 1.2 Welche Inhalte wir nicht behandeln Der Workshop ist kein Statistik- oder Ökonometrie-Kurs. Ich bin — wie auch ihr — ausgebildeter Sozialwissenschaftler. Die statistischen Grundlagen, auf denen der Workshop aufbaut, gehen aus den Grundlagentexten (Bell and Jones 2015; Vaisey and Miles 2017) hervor. Grundkentnisse in R setze ich voraus, insbesondere Datentransformationen innerhalb des tidyverse. Wir werden aber keine komplizierten Dinge in R tun. Auch ohne weiterführende R-Kenntnisse sollten die Inhalte des Workshops in Bezug auf die datenanalystischen Verfahren klar werden. Wir werden nicht viel Zeit auf die verschiedenen Schätzer, deren Effizienz und Bias, die verschiedenen Algorithmen und Datentransformationen verwenden. Wir werden keine Beweise oder Ableitungen besprechen. Wir setzen keine Kenntnisse in Matrixalgebra voraus — weder meiner- noch eurerseits. Wir behandeln einen sehr kleinen Ausschnitt möglicher Modelle für Panel-Daten. Wir konzentrieren uns auf regressionsbasierte Modelle zur Schätzung kausaler Effekte. Damit behandeln wir insbesondere nicht die vielfälltigen Verfahren, die in einem SEM-Framework verortet sind: längsschnittliche Messmodelle, Prozessmodelle, (random intercept) cross-lagged panel Modelle, Latent State-Trait Modelle, etc. Auch Modelle, in denen die Zeit-Variable als kontinuierlich (z.B. Tag der Erhebung im Gegensatz zu Indikator für Panelwelle) verwendet wird (z.B. Continuous Time Structural Equation Modeling), behandeln wir nicht. Fehlende Daten (Panelmortalität, Ausfall von Einheiten in einzelnen Wellen) sind ein großes Thema in der Längsschnittanalyse. Wir werden es hier ignorieren, bis auf den Hinweis, dass alle Fälle, die in mindestens zwei bzw. drei Wellen Daten haben, grundsätzlich Informationen zur Schätzung beitragen. 1.3 Aufbau des Workshops Inhaltlicher Aufbau: Siehe Kapitel-Gliederung Material Dieses Dokument + R Skripte: (Hoffentlich) mehr oder weniger selbsterklärendes Material Kuratierte Form ist dieses HTML-Dokument Es gibt auch ein PDF, das ich aber nicht formatiert habe Screencast: Ich gehe über das Material und erkläre es auf der Audio-Spur. Mal sehen, wie hilfreich das ist. Die Screencasts stelle ich über das LMS zur Verfügung. Übungen: Zu einigen Analysen gibt es Übungsaufgaben. Bei der Wiederholung geht es darum, die Modelle leicht zu verändern (durch Anpassen der R-Skripte aus dem Material) und die Ergebnisse der angepassten Modelle zu interpretieren. Bei der Anwendung geht es darum, in Anlehung an die Beispiele eigene Modelle zu spezifizieren und diese zu interpretieren. Pakete Wir verwenden die folgenden Pakete if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(tidyverse, ggstance, broom, broom.mixed, haven, plm, lmtest, lme4, performance) theme_set(theme_bw()) # ggplot theme tibble(package = c(&quot;R&quot;, sort(pacman::p_loaded()))) %&gt;% mutate(version = map_chr(package, ~as.character(pacman::p_version(package = .x)))) %&gt;% knitr::kable() package version R 3.6.2 broom 0.5.4 broom.mixed 0.2.4 dplyr 0.8.4 forcats 0.4.0 ggplot2 3.2.1 ggstance 0.3.3 haven 2.2.0 lme4 1.1.21 lmtest 0.9.37 Matrix 1.2.18 pacman 0.5.1 performance 0.4.6 plm 2.2.3 purrr 0.3.3 readr 1.3.1 stringr 1.4.0 tibble 2.1.3 tidyr 1.0.2 tidyverse 1.3.0 zoo 1.8.7 Literatur "],
["einführung.html", "Abschnitt 2 Einführung 2.1 Längsschnittdaten 2.2 Beispiel-Daten 2.3 Pooled OLS (WRONG!)", " Abschnitt 2 Einführung 2.1 Längsschnittdaten Begriffe Wiederholte Querschnittserhebungen (time series cross sectional, TSCS): \\(n\\) unabhängige Fälle (repräsentativ für dieselbe Grundgesamtheit) zu mehreren Messzeitpunkten \\(t\\). Zeitreihe: Eine Einheit mit vielen Messzeitpunkten (\\(n = 1\\), \\(t &gt; 30\\)). Paneldaten: Dieselben Einheiten mit wiederholten Messungen (\\(n &gt; 30\\), \\(t \\ge 2\\)) Macro panel: \\(n\\) klein, \\(t\\) groß (z.B. jährliche Untersuchung von Staaten, 1950–2015) Micro panel: \\(n\\) groß, \\(t\\) klein (typisches Befragungspanel) In diesem Workshop geht es um micro panels mit \\(t &gt; 2\\) Vorteile von Paneldaten Paneldaten erlauben die Identifikation von kausalen Effekten unter schwächeren Annahmen (im Vergleich zu Querschnittsdaten). Wir haben einige (aber nicht perfekte!) Informationen über die zeitliche Abfolge von Veränderungen. Wir können untersuchen, ob, und wenn ja, wie ein Ereignis (eine Veränderung eines Prädiktors) das Kriterium verändert. Paneldaten erlauben die Untersuchung von individuellen Verläufen Kausale Effekte mit Paneldaten schätzen Bedingungen Kovariation zwischen \\(X\\) und \\(Y\\) (bivariate Korrelation \\(r_{XY}\\) ) \\(X\\) muss logisch vor \\(Y\\) liegen Keine (nicht beobachteten) Störvariablen (kein \\(Z\\) mit kausalem Effekt auf \\(X\\) und \\(Y\\)) Herausforderungen (auch bzw. gerade mit Paneldaten) Entsprechung der zeitlichen Entfalltung des Effekts und des Designs (Abstände, Verläufe) Reliabilität und Konstruktstabilität Reliabilität: Bei geringer Reliabilität beobachten wir Veränderungen, die aber auf Rauschen in der Messung zurückgehen. Konstruktstabilität: Wenn die Messungen über die Zeit ihre Bedeutung verändern, modellieren wir keine Veränderung des latenten Konstrukts von Interesse. Panelmortalität und Paneleffekte Panelmortalität: Einheiten (Befragte) fallen aus, möglicherweise systematisch mit Bezug auf die Konstrukte oder Effekte, die uns interessieren. Paneleffekte: Einheiten (Befragte) verändern sich durch die Messung (z.B. Lernen von Wissensfragen, Anregung durch Fragen zu Medienangeboten) Format von Datensätzen mit Paneldaten \\(i\\) indiziert Einheiten, \\(t\\) indiziert Messzeitpunkte, \\(y\\) ist eine Variable Die Modelle in diesem Workshop nutzen das long format Datensätze können von einem ins andere Format transformiert werden, z.B. im tidyverse: tidyr::gather() und tidyr::spread() (verwende ich in R/data.R) oder tidyr::pivot_longer() und tidyr::pivot_wider() 2.2 Beispiel-Daten Titel: Soziale Normen im alltäglichen Umgang mit den Konsequenzen der Corona-Krise sponsored by Jule Scheper und Sophie Bruns Thema der Erhebung: Die Corona-Pandemie hat Regierungen auf der ganzen Welt dazu veranlasst, Reglungen zur Reduzierung der raschen Ausbreitung des Virus einzuführen. Die deutsche Bundesregierung hat am 22. März 2020 mehrere Maßnahmen zur Einschränkung sozialer Kontakte beschlossen. Diese Einschränkungen im sozialen Leben sind vollkommen neu und jede*r Einzelne muss sich auf diese Regelungen und die neue Lebenssituation einstellen. Diese Studie beschäftigt sich mit der Frage, wie Menschen sich im Alltag mit der Corona-Pandemie beschäftigen und wie sie mit den Regelungen zur Beschränkung sozialer Kontakte umgehen. Im Mittelpunkt der Untersuchung steht die Entstehung und Veränderung von sozialen Normen und persönlichen Einstellungen zur Beschränkung sozialer Kontakte über die Zeit. Im Rahmen des Workshops steht der Einfluss der sozialen Normen und der eigenen Einstellung zum Verhalten auf das tatsächliche Social Distancing-Verhalten im Mittelpunkt. Zeitraum der Erhebung: 1.4.-28.4.2020 Datum der Messzeitpunkte: Die Befragung besteht aus vier Wellen. Jede Welle war für eine Woche im Feld und bezog sich immer auf die vorherige Kalenderwoche. Welle 1: Erhebungszeitraum vom 1.4.-7.4., Bezugszeitraum vom 23.3. bis 29.4. Welle 2: Erhebungszeitraum vom 8.4.-14.4., Bezugszeitraum vom 30.3. bis 5.4. Welle 3: Erhebungszeitraum vom 15.4.-21.4., Bezugszeitraum vom 6.4. bis 12.4. Welle 4: Erhebungszeitraum vom 22.4.-28.4., Bezugszeitraum vom 13.4. bis 19.4. Nachvollziehen der Aufbereitung in R/data.R Direkt laden (z.B. für Übungen) aus R/data/data.rds Der Datensatz ist bereits im long format. IDsosci ist der Indikator für die Person, wave ist der Indikator für die Erhebungswelle. Inhaltliche Variablen im Datensatz Alter, Geschlecht (Dummy für weiblich), Bildung und Kollektivismus sind konstante Personenmerkmale. Alle übrigen Variablen wurden in den vier Wellen wiederholt gemessen (mit Ausnahme von desnorm4, injnorm4, verh4-6, verhint4-6, die erst ab Welle 2 erfasst wurden). Variablenname Label alter Alter besorg1 Ich bin besorgt, wenn ich an Corona denke. bildung Bildungsabschluss desnormp1 …sind in der letzten Woche rausgegangen, auch wenn es sich nicht um einen Arztbesuch, Arbeitsweg, Spaziergang/Sport, Einkauf oder Hilfestellungen handelte. desnormp2 …haben sich in der letzten Woche in ihrer Freizeit mit mehr als einer anderen Person getroffen, die nicht im gleichen Haushalt lebt. desnormp3 …haben in der letzten Woche weniger als 1,5 Meter Abstand zu Personen gehalten, die nicht im gleichen Haushalt leben. desnormp4 …haben sich in der letzten Woche strikt an die Maßnahmen zur Beschränkung sozialer Kontakte gehalten. ein1 Ich finde es in Ordnung, wenn man rausgeht, auch wenn es sich nicht um einen Arztbesuch, Arbeitsweg, Spaziergang/Sport, Einkauf oder Hilfe handelt. ein2 Ich finde es in Ordnung, wenn man sich in seiner Freizeit mit mehr als einer anderen Person trifft, die nicht im gleichen Haushalt lebt. ein3 Ich finde es in Ordnung, wenn man weniger als 1,5 Meter Abstand zu Personen hält, die nicht im gleichen Haushalt leben. ein4 Ich finde es wichtig, dass die Empfehlung zur Beschränkung sozialer Kontakte strikt eingehalten werden. ein5 Ich finde es richtig, dass generell Abstand gehalten werden soll. injnormp1 …finden es in Ordnung, wenn man rausgeht, auch wenn es sich nicht um einen Arztbesuch, Arbeitsweg, Spaziergang/Sport, Einkauf oder Hilfestellungen handelt. injnormp2 … finden es in Ordnung, wenn man sich in seiner Freizeit mit mehr als einer anderen Person trifft, die nicht im gleichen Haushalt lebt. injnormp3 …finden es in Ordnung, wenn man weniger als 1,5 Meter Abstand zu Personen hält, die nicht im gleichen Haushalt leben. injnormp4 …finden es in Ordnung, wenn man sich strikt an die Maßnahmen zur Beschränkung sozialer Kontakte hält. kompeer_s1 Freunde kompeer_s2 Familie und Partner oder Partnerin kompeer_s3 Bekannte (z.B. Arbeitskollegen und -kolleginnen, Vereinsmitglieder) kompeer_s4 Prominente und/oder Influencer med1 Zeitungen &amp; Zeitschriften (z.B. Die ZEIT, Bild, Focus, der Spiegel) med2 Öffentlich-rechtliche Fernsehsender (z.B. ARD, ZDF, h1) med3 Private Fernsehsender (z.B. RTL, ProSieben) med4 Öffentlich-Rechtliche Radiosender (z.B. DLF, n-joy, NDR) med5 Private Radiosender (z.B. 89.0 RTL, ffn) sex Geschlecht W4 dummy stress Ich fühle mich durch die Corona-Pandemie gestresst. verh1 Ich bin rausgegangen, auch wenn es sich nicht um einen Arztbesuch, Arbeitsweg, Einkauf, Spaziergang/Sport oder Hilfestellung gehandelt hat. verh2 Ich habe mich mit mehr als einer Person getroffen, die nicht in meinem Haushalt lebt. verh3 Ich habe weniger 1,5 Meter Abstand zu Personen gehalten, die nicht in meinem Haushalt leben. verh4 Ich habe mich strikt an die Maßnahmen zur Beschränkung sozialer Kontakte gehalten. verh5 Ich habe mich im Privaten mit Freunden oder Familienmitgliedern getroffen, die nicht in meinem Haushalt leben. verh6 Ich war länger draußen als für einen üblichen Spaziergang (z.B. saß auf der Wiese oder am See). verhint1 Rausgehen, auch wenn es sich nicht um einen Arztbesuch, Arbeitsweg, Einkauf, Spaziergang/Sport oder Hilfestellung handelt. verhint2 Mich mit mehr als einer Person treffen, die nicht in meinem Haushalt lebt. verhint3 Weniger als 1,5 Meter Abstand zu Personen halten, die nicht in meinem Haushalt leben. verhint4 Mich strikt an die Maßnahmen zur Beschränkung sozialer Kontakte halten. verhint5 Mich im Privaten mit Freunden oder Familienmitgliedern treffen, die nicht in meinem Haushalt leben. verhint6 Mich länger draußen aufhalten als für einen üblichen Spaziergang (z.B. auf der Wiese oder am See sitzen). veruns Ich bin verunsichert durch die Corona-Krise. 2.3 Pooled OLS (WRONG!) Als erstes Beispiel wollen wir uns einer klassischen Frage aus der Theory of Planned Behavior zuwenden. Wir interessieren uns für den Effekt der Verhaltensintention auf das (berichtete) Verhalten (schließlich würden wir zum Start des Workshops ja gerne etwas finden ;)). Konkret betrachten wir den Effekt des Vorhabens, entgegen der Empfehlungen ohne relevanten Grund die Wohnung zu verlassen, auf den Selbstbericht, dies auch zu tun. Die beiden relevanten Variablen sind verh1 und verhint1. Höhere Werte bedeuten eine häufigere Ausübung des Verhaltens bzw. eine höhere Wahrscheinlichkeit, das Verhalten auszuüben (gemessen auf Skala von 1 bis 5). Die Abbildung zeigt die Entwicklung der beiden Variablen über die vier Wellen für 10 zufällig ausgewählte Personen. id_smple = sample(unique(d$IDsosci), 10) d %&gt;% filter(IDsosci %in% id_smple) %&gt;% select(IDsosci, wave, verh1, verhint1) %&gt;% gather(variable, value, -IDsosci, -wave) %&gt;% ggplot(aes(wave, value, group = IDsosci, color = IDsosci)) + geom_line(position = position_jitter(height = 0.1, width = 0), show.legend = FALSE) + facet_wrap(&quot;variable&quot;) Das einfachste Modell, diesen Effekt zu schätzen, ist eine einfache OLS Regression der Verhaltensintention auf das Verhalten. lm(verh1 ~ verhint1, data = d) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.46 0.02 19.2 0 ## 2 verhint1 0.59 0.01 53.8 0 Das Modell besagt, dass die Häufigkeit, ohne triftigen Grund raus zu gehen, mit jedem Punkt auf der Intentionsskala um ca. \\(b_{verhint1} = 0.6\\) Punkte steigt. Warum ist Pooled OLS immer falsch? Statistische Theorie Wir nennen dieses Modell pooled OLS, da alle Beobachtungen einfach zusammengeworfen werden, ohne zu beachten, dass einige von ihnen zusammen gehören, da sie von denselben Personen stammen. Exogenitätsannahme ist verletzt, \\(E(u_i|x_i) \\neq 0\\) Korrelationen zwischen den Variablen \\(x\\) gehen auf nicht gemessene Eigenschaften der Einheiten zurück, z.B. Eigenschaften der Person \\(z_i\\), die sowohl \\(x_i\\) als auch \\(y_i\\) beeinflussen. Auch bekannt als omitted variable bias Könnte behoben werden, wenn alle \\(z_i\\) im Modell wären; diese Idee wird später wichtig Annahmen Homoskedastizität und unkorrelierte Residuen sind (wahrscheinlich) verletzt Systematische Variation der Residuen zwischen Einheiten Wahrscheinlich serielle Korreationen durch die zeitliche Abhängigkeit der Messungen Annahme der Unabhängigkeit der Bebobachtungen verletzt Überschätzung der Information von abhängigen Fällen (dieselbe Information ist mehrmals im Datensatz) Zu kleine Standardfehler, zu große Zahl der Freiheitsgrade in Signifikanz-Tests Die wahre Fallzahl (effective sample size) ist kleiner als Zahl der Zeilen im Datensatz (long format) Warum ist pooled OLS immer falsch? Inhaltliche Überlegungen Unser Ziel ist es, den wahren kausalen Effekt von \\(X\\) auf \\(Y\\) zu schätzen. Pooled OLS vermischt aber zwei Quellen von Unterschieden in den Daten: Den (kausalen) Effekt innerhalb der Personen (within) und die Unterschiede zwischen Personen (between). Within und between Effekte können sich in Größe und sogar in der Richtung unterscheiden! Die Schätzung aus einem poold OLS Modell vermischt den kausalen Effekt und die interindividuellen Unterschiede. In der Sprache von Interventionsstudien ist das ein Selbstselektions-Problem: Was passiert, wenn Personen, die vor dem Treatment \\(x\\) schon höhere Werte in \\(y\\) haben, das Treatment häufiger auswählen als Personen, die niedrig in $x§ sind? Außerdem fällt auf, dass im einfachen OLS Modell nichts darauf hindeutet, dass es sich um Paneldaten handelt. Selbst wenn wir die genannten Probleme nicht hätten, hätten wir auch nichts durch die Paneldaten gewonnen. Pooled OLS, within und between - eine Illustration Zum Abschluss noch ein imaginäres Beispiel, um den Unterschied von intraindividuellen (within) Effekten und interindividuellen Unterschieden zu verdeutlichen. Wir führen eine Panel-Studie mit acht Personen und sechs Messzeitpunkten zum Zusammenhang von Bier-Konsum und Hangover durch. Wir interessieren uns für die kausale Frage, ob mehr Bier zu einem schlimmeren Kater führt. In der pooled OLS Analyse wird einfach die Rergressionsgerade durch alle Beobachung gelegt. Es zeigt sich ein negativer Zusammenhang. Je mehr Bier konsumiert wurde, desto schwächer fällt der Hangover aus. Wenn wir aber für alle acht Personen separat den Zusammenhang zwischen Bierkonsum und Kater berechnen (so genanntes no pooling Modell), ergibt sich ein anderes Bild. Für alle Personen gilt mehr oder weniger deutlich: Je mehr Bier konsumiert wurde, desto stärker fällt der Hangover aus (within). Dazu kommt ein systematischer Unterschied zwischen den Personen (between): Personen, die im Durchschnitt mehr Bier trinken, haben im Durchschnitt einen schwächeren Hangover. Dies könnte auf eine nicht beobachte Drittvariable auf Ebene der Personen zurück gehen: Vielleicht trinken Personen, die wissen, dass sie nicht so anfällig für einen Hangover sind, mehr, während Personen, die immer einen starken Kater haben, schon aus Angst vor dem nächsten Tag weniger trinken. Oder es ist ein Gewöhnungseffekt: Personen, die häufig viel trinken, gewöhnen sich an den Kater und nehmen ihn als weniger schlimm wahr. Oder mit Lemmy: “A kid once said to me “Do you get hangovers?” I said, “To get hangovers you have to stop drinking.”&quot; Mit den vorliegenden Daten können wir die Frage nach dem Prozess nicht beantworten, da wir die Drittvariable nicht gemessen haben. Wir können aber alle Variablen kontrollieren, die auf Personenebene liegen, z.B., indem wir wie in der Abbildung für jede Person ein separates Modell schätzen. Dann können Unterschiede zwischen den Einheiten per Modelldefinition keinen Einfluss auf die Schätzung haben. Etwas ähnliches passiert im fixed effects Modell, das wir im nächsten Abschnitt besprechen. An diesem Beispiel lässt sich übrigens auch schön sehen, warum uns Querschnittsdaten nicht bei der Identifikation kausaler Effekte helfen, wenn wir nicht für \\(Z\\) kontrollieren können. Wenn wir jede Panel-Welle für sich ananlysieren (die Daten also als unabhängige Querschnittserhebungen behandeln), finden wir jeweils einen negativen Zusammenhang zwischen Bierkonsum und Hangover. "],
["fixed-effects-modelle.html", "Abschnitt 3 Fixed effects Modelle 3.1 Konzeptionelle Einführung 3.2 Übungsaufgaben 1 3.3 Fixed effects Modelle in der praktischen Anwendung 3.4 Conclusio: Vor- und Nachteile des fixed effects Modells 3.5 Übungsaufgaben 2", " Abschnitt 3 Fixed effects Modelle 3.1 Konzeptionelle Einführung Im ersten Teil des Abschnitts zu fixed effects Modellen beschäftigen wir uns mit den Grundlagen der Modellierung. Dazu nutzen wir stats::lm() (übliche OLS-Schätzung linearer Modelle in R). Wie können wir den kausalen (within-person) Effekt mit Paneldaten schätzen? Separate OLS Modelle für jede Person schätzen und Koeffizienten mitteln (no pooling). Alle \\(X\\) und \\(Y\\) Variablen um die Mittelwerte der Person zentrieren (within transformation). Dummy-Variablen für jede Person in das Regressionsmodell aufnehmen (least squares dummy variables [LSDV] estimation). Alle drei Varianten entfernen die (beobachteten und nicht beobachten,) über die Zeit konstanten Unterschiede zwischen den Personen. Varianten 2 und 3 entsprechen dem klassischen fixed effects Modell. Die Unterschiede zwischen den Personen werden kontrolliert, indem die personenspezifischen Mittelwerte vor der Schätzung entfernt werden (2) oder für jede Person im Modell geschätzt werden (3). \\(y_{it}-\\bar{y_{i}} = (x_{it} - \\bar{x_{i}})&#39;\\beta + (u_{it} - \\bar{u_{i}})\\) oder \\(y_{it} = \\beta&#39; x_{it}&#39; + \\alpha_i + u_{it}\\) In Variante 1 dürfen die kausalen within-person Effekte zwischen den Personen variieren. Unter der Annahme homogener Treatment-Effekte (entspricht der typischen Annahme im randomisierten Between-Subject-Experiment) entspricht das Ergebnis asymptotisch den Varianten 2 und 3. Der Schätzer ist aber weniger effizient, da zufällige Unterschiede in den Effekten zwischen den Personen aufgegriffen werden. Im letzten Teil des Abschnitts zum within-between-Modell kommen wir auf diesen Punkt zurück, wenn wir die Annahme homogener Treatment-Effekte lockern. No pooling d %&gt;% group_by(IDsosci) %&gt;% nest() %&gt;% mutate(mdls = map(data, ~tidy(lm(verh1 ~ verhint1, data = .x)))) %&gt;% unnest(mdls) %&gt;% ungroup() %&gt;% select(-data) %&gt;% na.omit() %&gt;% filter(statistic != Inf) %&gt;% filter(term == &quot;verhint1&quot;) %&gt;% mutate_if(is.numeric, round, 2) %&gt;% print %&gt;% summarise(estimate = mean(estimate), std.error = sqrt(mean(std.error^2))) # simple approximation ## # A tibble: 232 x 6 ## IDsosci term estimate std.error statistic p.value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 050IPY verhint1 1.25 0.56 2.24e+ 0 0.15 ## 2 05J4R8 verhint1 0.45 0.18 2.50e+ 0 0.13 ## 3 08BDZJ verhint1 0.33 0.53 6.30e- 1 0.59 ## 4 0EO9L2 verhint1 1.67 0.67 2.50e+ 0 0.13 ## 5 0F5L9Z verhint1 0 0.71 0. 1 ## 6 0KYYAJ verhint1 0.45 0.18 2.50e+ 0 0.13 ## 7 0ONV4O verhint1 1 0 9.01e+15 0 ## 8 0ZCKB5 verhint1 -0.35 0.5 -6.90e- 1 0.56 ## 9 114OWA verhint1 0.33 0.33 1.00e+ 0 0.42 ## 10 16YGN0 verhint1 0.5 0.25 2.00e+ 0 0.18 ## # … with 222 more rows ## # A tibble: 1 x 2 ## estimate std.error ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0.502 0.521 Wir erhalten für jede Person einen Schätzer mit Standardfehler. Wir können diese mitteln, um einen Schätzer des durchschnittlichen kausalen Effekts zu erhalten. Wir müssen die Schätzer entfernen, bei denen es wegen eines perfekten Zusammenhangs oder wegen fehlender intraindividueller Varianz keine OLS Lösung gibt. Within Transformation Wir ziehen von jedem Messwert den Personenmittelwert ab. In das Modell gehen dann die um den Personenmittelwert bereinigten Variablen ein. d_wi = d %&gt;% select(IDsosci, verh1, verhint1) %&gt;% group_by(IDsosci) %&gt;% mutate(verh1_wi = verh1 - mean(verh1), verhint1_wi = verhint1 - mean(verhint1)) %&gt;% ungroup() d_wi %&gt;% select(-IDsosci) %&gt;% summary ## verh1 verhint1 verh1_wi verhint1_wi ## Min. :1.000 Min. :1.000 Min. :-3.00 Min. :-3.00 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:-0.25 1st Qu.:-0.25 ## Median :1.000 Median :1.000 Median : 0.00 Median : 0.00 ## Mean :1.529 Mean :1.804 Mean : 0.00 Mean : 0.00 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.: 0.00 3rd Qu.: 0.00 ## Max. :5.000 Max. :5.000 Max. : 3.00 Max. : 3.00 d_wi %&gt;% lm(verh1_wi ~ verhint1_wi, data = .) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) ## # A tibble: 2 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0 0.01 0 1 ## 2 verhint1_wi 0.35 0.01 24.9 0 Intuitive Interpretation: Eine Abweichung vom Personen-Durchschnitt in \\(X\\) um einen Punkt führt zu einer Abweichung vom Personen-Durchschnitt in \\(Y\\) um \\(b_{X}\\) Punkte. Hier: Wenn eine Person um einen Punkt wahrscheinlicher rausgehen möchte als üblich, dann wird sie 0.34 Punkte häufiger rausgehen (beides auf 5er Skalen). Das ist durchaus ein bedeutsamer Effekt. Aber zur Erinnerung: Der naiven pooled OLS Schätzung zufolge war der Effekt fast doppelt so groß. Es scheint also auch einen Unterschied zwischen Personen zugeben. Personen, die im Durchschnitt wahrscheinlicher raus gehen wollen, gehen im Durchschnitt auf häufiger raus. Least Squares mit Dummy Variablen (LSDV) Es wird ein Dummy-Indiktator für jede \\(n-1\\)te Person in das Modell aufgenommen. d %&gt;% lm(verh1 ~ verhint1 + factor(IDsosci), data = .) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) %&gt;% print(n = 17) ## # A tibble: 577 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.65 0.28 2.31 0.02 ## 2 verhint1 0.35 0.02 21.5 0 ## 3 factor(IDsosci)02E6C8 -0.35 0.4 -0.86 0.39 ## 4 factor(IDsosci)050IPY 1.21 0.4 3.01 0 ## 5 factor(IDsosci)05J4R8 0.32 0.4 0.79 0.43 ## 6 factor(IDsosci)08BDZJ 0.96 0.4 2.39 0.02 ## 7 factor(IDsosci)0BHGLF 0.570 0.4 1.42 0.16 ## 8 factor(IDsosci)0EB6C1 0 0.4 0 1 ## 9 factor(IDsosci)0EO9L2 1.95 0.4 4.82 0 ## 10 factor(IDsosci)0F5L9Z 1.64 0.4 4.06 0 ## 11 factor(IDsosci)0KAKHF 2.2 0.4 5.44 0 ## 12 factor(IDsosci)0KYYAJ -0.01 0.4 -0.02 0.98 ## 13 factor(IDsosci)0ONV4O 0.33 0.4 0.82 0.41 ## 14 factor(IDsosci)0PKFWT -0.09 0.4 -0.22 0.83 ## 15 factor(IDsosci)0ZCKB5 0.32 0.4 0.79 0.43 ## 16 factor(IDsosci)114OWA 0.33 0.4 0.82 0.41 ## 17 factor(IDsosci)11KVRK -0.17 0.4 -0.43 0.67 ## # … with 560 more rows Der Punktschätzer \\(b_{X}\\) entspricht genau dem Punktschätzer nach der within-person Transformation. Zusätzlich gibt die Regressionskonstante den Mittelwert für Person 1 an und die \\(n - 1\\) Koeffizienten der Dummy-Variablen die Abweichung der übrigen Personen von diesem Mittelwert. Es gelten die üblichen Regeln für die Interpretation solcher Koeffizienten. Welche Modellspezifikation soll ich nutzen? Der Schätzer des durchschnittlichen kausalen Effekts in der no pooling Spezifikation ist im Vergleich zu den beiden anderen Varianten weniger effizient. Außerdem ist er praktisch schwieriger zu ermitteln, da er erst aus den Schätzern der Einzel-Modelle berechnet werden muss. Wenn wir die Annahme eines homogenen kausalen Effekts treffen (und das tun wir üblicherweise), dann gibt es keinen Grund, das no pooling Modell in der Praxis zu verwenden. Die Spezifikationen mit within-person Transformation und LSDV ergeben dieselben Punktschätzer für den kausalen Effekt und sind insofern austauschbar. Die Standardfehler des Modells mit einer naiven within-person Transformation (wie oben dargestellt) sind zu klein, da wir die Stichprobenmittelwerte und nicht die (mit Unsicherheit behafteten) Schätzer der Populationsmittelwerte zur Zentrierung verwenden. Die Standardfehler müssen daher angepasst werden (passiert in spezialisierten Software-Paketen automatisch). Die LSDV Spezifikation ist in fast jedem Softwarepaket einfach umzusetzen. Mit großen Datensätzen wird aber die Schätzung langsam und der Output unübersichtlich. Unabhängig von der Spezifikation gelten weiterhin alle Annahmen der (OLS) Regression. Besonders gern vergessen wird der omitted variable bias durch nicht gemessene, über die Zeit variierdene \\(Z\\). Fixed effects Modelle kontrollieren nur die \\(Z\\), die auf konstante Merkmale der als fixed effects spezifizierten Einheiten zurückgehen. Insgesamt sind viele quantitative Sozialforscher (v.a. die mit einer Ökonometrie-Ausbildung) der Ansicht, dass fixed effects Modelle die beste Methode sind, um kausale Effekte aus nicht-experimentellen Daten zu schätzen. Mehre fixed effects in einem Modell – Perioden-Effekte Grundsätzlich können in einem Modell beliebig viele fixed effects spezifiziert werden. In Paneldaten ist der Erhebungszeitpunkt bzw. die Ergebungsperiode (Panelwelle) eine typische Variable, über die verschiedene, für alle Personen konstante Effekte kontrolliert werden können. Einige Lehrbücher empfehlen, dies immer zu tun, da kausale Effekte von Ereignissen, die für alle Einheiten konstant sind, statistisch nicht identifiziert sind. Eine typische Spezifikation ist die Aufnahme eines fixed effects für den Indikator der Panelwelle. In der LSDV-Spezifikation kann einfach ein weiterer Dummy-Faktor hinzugefügt werden. Die within-person Transformation ist mathematisch komplizierter, wird aber in spezialisierten Software-Pakten im Hintergrund erledigt. Es können auch beide Spezifikationen kombiniert werden, wenn z.B. die Periodeneffekte von inhaltlichem Interesse sind und im Output angezeigt werden sollen (siehe nächsten Teilabschnitt). Ein Beispiel mit fixed effects für Personen und Perioden d %&gt;% lm(verh1 ~ verhint1 + factor(wave) + factor(IDsosci), data = .) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) %&gt;% print(n = 17) ## # A tibble: 580 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 0.6 0.28 2.13 0.03 ## 2 verhint1 0.33 0.02 19.8 0 ## 3 factor(wave)2 0.02 0.03 0.6 0.55 ## 4 factor(wave)3 0.14 0.03 4.15 0 ## 5 factor(wave)4 0.12 0.03 3.41 0 ## 6 factor(IDsosci)02E6C8 -0.33 0.4 -0.83 0.41 ## 7 factor(IDsosci)050IPY 1.26 0.4 3.15 0 ## 8 factor(IDsosci)05J4R8 0.34 0.4 0.85 0.39 ## 9 factor(IDsosci)08BDZJ 1.01 0.4 2.53 0.01 ## 10 factor(IDsosci)0BHGLF 0.59 0.4 1.48 0.14 ## 11 factor(IDsosci)0EB6C1 0 0.4 0 1 ## 12 factor(IDsosci)0EO9L2 2.02 0.4 5.01 0 ## 13 factor(IDsosci)0F5L9Z 1.68 0.4 4.2 0 ## 14 factor(IDsosci)0KAKHF 2.27 0.4 5.63 0 ## 15 factor(IDsosci)0KYYAJ 0 0.4 0.01 0.99 ## 16 factor(IDsosci)0ONV4O 0.34 0.4 0.84 0.4 ## 17 factor(IDsosci)0PKFWT -0.08 0.4 -0.21 0.84 ## # … with 563 more rows \\(b_{verhint1}\\) quantifiziert weiterhin den kausalen Effekt von Interesse. Er ist robust gegen die Kontrolle des Periodeneffekts. Die \\(b_{wave_t}\\) zeigen den Kontrast zur ersten Welle. In diesem Fall sind liegen in der dritten und vierten Welle die Häufigkeiten des Rausgehens höher als noch in den ersten beiden Wellen. Die \\(b_{id_i}\\) zeigen weiterhin den Kontrast zu Person 1 (substantiell nicht sonderlich interessant). 3.2 Übungsaufgaben 1 Schätze den kausalen Effekt der Informationshäufigkeit aus öffentlich-rechtlichen TV-Programmen (med2) auf die Intention, weniger als 1.5m Abstand zu einer Person zu halten, die nicht im eigenen Haushalt lebt (verhint3). Schätze zuerst das falsche pooled OLS Modell. Schätze dann das einfache fixed effects Modell mit einer Spezifikation freier Wahl. Vergleiche schließlich die Modelle mit und ohne Periodeneffekt. Spezifiziere, schätze und interpretiere ein eigenes bivariates fixed effects Modell mit Daten aus dem Beispieldatensatz. 3.3 Fixed effects Modelle in der praktischen Anwendung Auch wenn wir das fixed effects Modell nur mit stats::lm() und der LSDV-Spezifikation schätzen können, ist die weitere Arbeit mit diesen Modellen nicht ideal - besonders, wenn wir tiefer in Detail-Anpassungen einsteigen. Zudem wird das Schätzen mit stats::lm() und LSDV bei großen Datensätzen und mit vielen fixed effects langsam. plm (Croissant, Millo, and Tappe 2020) ist das etablierte Paket für das Schätzen von ökonometrischen Panel-Modellen in R. Es bietet ein einfaches Interface zu allen Standardmodellen (und zu den übrigen Klassikern der Ökonometrie, instrumental variables, differences in differences). Das Schätzen der Modelle basiert auf OLS mit Datentransformationen im Hintergrund. Dadurch ist das Schätzen wesentlich schneller als mit einer LSDV-Spezifikation. Die notwendigen Anpassungen der Standardfehler werden ebenfalls vorgenommen. Spezifikation eines einfachen fixed effects Modells mit plm Das fixed effects Modell wird über model = &quot;within&quot; angefordert. Mit index = &quot;IDsosci&quot; wird der Indikator für die Einheiten angegeben. d %&gt;% plm(verh1 ~ verhint1, data = ., index = &quot;IDsosci&quot;, model = &quot;within&quot;) %&gt;% summary() ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., model = &quot;within&quot;, index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -3.000000 -0.163516 0.000000 0.095937 3.000000 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## verhint1 0.345937 0.016061 21.539 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 702.5 ## Residual Sum of Squares: 553.75 ## R-Squared: 0.21175 ## Adj. R-Squared: -0.051155 ## F-statistic: 463.924 on 1 and 1727 DF, p-value: &lt; 2.22e-16 Der Output von summary() liefert eine korrekte Beschreibung der Fallzahlen im Datensatz. Beachte: Das angepasste \\(R^2\\) ist hier (wie in vielen fixed effects Modellen) negativ. Das ist kein Grund zur Beunruhigung. Die Logik dahinter kann gut nachvollzogen werden, wenn wir uns die LSDV-Spezifikation in Erinnerung rufen. Zusätzlich zu den inhaltlich relevanten Prädiktoren enthält das Modell \\(n - 1\\) Prädiktoren für die Einheiten. Mehre fixed effects in einem Modell – Perioden-Effekte mit plm plm bietet zwei Möglichkeiten, die Perioden-Effekte zu spezifizieren (identische Ergebnisse, anderer Output): Zwei Indices index=c(&quot;IDsosci&quot;, &quot;wave&quot;) und effect = &quot;twoways&quot; für die within-Transformation. Es wird “still” für Personen und Perioden kontrolliert, beide werden nicht im Output angezeigt. Das \\(R^2\\) bezieht sich nur auf die Varianzaufklärung durch die Prädiktoren. Perioden-Effekt als Dummies hinzufügen. Praktisch, wenn es nur wenige Perioden gibt und wir die Ergebnisse dazu direkt im Output sehen wollen. Das \\(R^2\\) bezieht sich auf die Varianzaufklärung durch die Prädiktoren und den Perioden-Effekt. d %&gt;% plm(verh1 ~ verhint1, data = ., index = c(&quot;IDsosci&quot;, &quot;wave&quot;), model = &quot;within&quot;, effect = &quot;twoways&quot;) %&gt;% summary() ## Twoways effects Within Model ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., effect = &quot;twoways&quot;, ## model = &quot;within&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;)) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -3.070526 -0.180571 0.011669 0.131626 3.049432 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## verhint1 0.328779 0.016614 19.789 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 669.68 ## Residual Sum of Squares: 545.72 ## R-Squared: 0.1851 ## Adj. R-Squared: -0.088576 ## F-statistic: 391.609 on 1 and 1724 DF, p-value: &lt; 2.22e-16 mdl_pfe_pdv = d %&gt;% plm(verh1 ~ verhint1 + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;within&quot;) mdl_pfe_pdv %&gt;% summary() ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = verh1 ~ verhint1 + factor(wave), data = ., model = &quot;within&quot;, ## index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -3.070526 -0.180571 0.011669 0.131626 3.049432 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## verhint1 0.328779 0.016614 19.7891 &lt; 2.2e-16 *** ## factor(wave)2 0.019997 0.033589 0.5954 0.5516856 ## factor(wave)3 0.139955 0.033691 4.1540 3.426e-05 *** ## factor(wave)4 0.117763 0.034484 3.4150 0.0006526 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 702.5 ## Residual Sum of Squares: 545.72 ## R-Squared: 0.22318 ## Adj. R-Squared: -0.037717 ## F-statistic: 123.824 on 4 and 1724 DF, p-value: &lt; 2.22e-16 Robuste Standardfehler In der ökonometrischen Diskussion ist die Wahl der korrekten (robusten) Standardfehler sehr prominent. Diese sind robust gegen Verletzung verschiedener Annahmen, z.B. durch serielle Korrelationen der Residuen oder Heteroskedastizität. Das lmtest Paket (Hothorn et al. 2019) ist kompatibel mit Modellen aus plm. Es implementiert zahlreiche robuste Schätzer bzw. Korrekturen. Hier die “normalen” Standardfehler und bei Heteroskedastizität robuste Standardfehler sowie die darauf basierenden Konfidenzintervalle im Vergleich. Weiter wollen wir dieses Thema hier nicht vertiefen. Ich empfehle für die Details der Umsetzung in plm Millo (2017) und zu einer kritischen Auseinandersetzung King and Roberts (2015). # Normale SE und CI mdl_pfe_pdv %&gt;% coeftest() %&gt;% round(3) ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## verhint1 0.329 0.017 19.789 &lt;2e-16 *** ## factor(wave)2 0.020 0.034 0.595 0.552 ## factor(wave)3 0.140 0.034 4.154 &lt;2e-16 *** ## factor(wave)4 0.118 0.034 3.415 0.001 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 mdl_pfe_pdv %&gt;% coefci() %&gt;% round(3) ## 2.5 % 97.5 % ## verhint1 0.296 0.361 ## factor(wave)2 -0.046 0.086 ## factor(wave)3 0.074 0.206 ## factor(wave)4 0.050 0.185 # Heteroskedasticity-robust SE and CI mdl_pfe_pdv %&gt;% coeftest(vcov. = vcovHC) %&gt;% round(3) ## ## t test of coefficients: ## ## Estimate Std. Error t value Pr(&gt;|t|) ## verhint1 0.329 0.028 11.868 &lt;2e-16 *** ## factor(wave)2 0.020 0.029 0.688 0.491 ## factor(wave)3 0.140 0.036 3.849 &lt;2e-16 *** ## factor(wave)4 0.118 0.032 3.701 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 mdl_pfe_pdv %&gt;% coefci(vcov. = vcovHC) %&gt;% round(3) ## 2.5 % 97.5 % ## verhint1 0.274 0.383 ## factor(wave)2 -0.037 0.077 ## factor(wave)3 0.069 0.211 ## factor(wave)4 0.055 0.180 Aufnahme weiterer über die Zeit variierender Prädiktoren Die Aufnahme weiterer Prädiktoren, die über die Zeit variieren, erfolgt prinzipiell wie im bekannten OLS Modell. Wichtig ist, dass es bei fixed effects Modellen explizit um das Schätzen von kausalen Effekten geht. Entsprechend bedacht sollte die Auswahl von weiteren Prädiktoren sein. Ein “kitchen sink” Ansatz, den man vor allem in OLS mit Querschnittsdaten sieht, ist hier nicht angebracht. Es muss (wie eigentlich immer) darauf geachtet werden, welche Koeffizienten eines Regressionsmodells kausal interpretiert werden dürfen (Keele, Stevenson, and Elwert 2019). Im fixed effects Modell müssen wir uns das ganz explizit vergegenwärtigen und in der Ergebnisdarstellung berücksichtigen, da die Modellklasse kausale Effekte impliziert. Nach der TPB dürfen wir dieses Modell annehmen, da die drei Prädiktoren auf derselben kausalen Stufe stehen: Verhaltensintention ~ Einstellung + Deskriptive Norm + Injunktive Norm. Hier schätzen wir das Modell für die Verhaltensintention Rausgehen ohne triftigen Grund. d %&gt;% plm(verhint1 ~ ein1 + desnormp1 + injnormp1 + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;within&quot;) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) ## # A tibble: 6 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ein1 0.31 0.02 12.4 0 ## 2 desnormp1 0.05 0.03 1.56 0.12 ## 3 injnormp1 0.1 0.03 3.31 0 ## 4 factor(wave)2 0.21 0.05 4.69 0 ## 5 factor(wave)3 0.24 0.05 5.3 0 ## 6 factor(wave)4 0.39 0.05 8.32 0 Vor allem die Einstellung zum Verhalten und die wahrgenommenen normativen Erwartungen haben stärkere kausale Effekte auf die Verhaltensintention. Aufnahme eines Personenmerkmals (funktioniert nicht, ohne Warnung!) In einer typischen Regresssionanalyse würden wir uns z.B. auch dafür interessieren, ob sich das Verhalten nach dem Geschlecht unterscheidet. Wir nehmen also C_sex in die Formel auf, mit der wir das Modell in plm spezifizieren. d %&gt;% plm(verh1 ~ verhint1 + C_sex + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;within&quot;) %&gt;% summary ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = verh1 ~ verhint1 + C_sex + factor(wave), data = ., ## model = &quot;within&quot;, index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -3.070526 -0.180571 0.011669 0.131626 3.049432 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## verhint1 0.328779 0.016614 19.7891 &lt; 2.2e-16 *** ## factor(wave)2 0.019997 0.033589 0.5954 0.5516856 ## factor(wave)3 0.139955 0.033691 4.1540 3.426e-05 *** ## factor(wave)4 0.117763 0.034484 3.4150 0.0006526 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 702.5 ## Residual Sum of Squares: 545.72 ## R-Squared: 0.22318 ## Adj. R-Squared: -0.037717 ## F-statistic: 123.824 on 4 and 1724 DF, p-value: &lt; 2.22e-16 Geschlecht wird nicht in das Modell aufgenommen. Vorsicht: Es taucht einfach nicht im Ergebnis auf, obwohl es in der Formel steht (siehe Call in der Summary) Warum wird das Personenmerkmal nicht ins Modell aufgenomen? Within-person Transformation entfernt die gesamte between-person Varianz aus den Daten: \\(\\bar{y_{i}} = 0\\). Daher können innerhalb der Personen invariante Merkmale keine Unterschiede erklären. id_smple = sample(unique(d$IDsosci), 100) d %&gt;% filter(IDsosci %in% id_smple) %&gt;% select(IDsosci, wave, verh1) %&gt;% group_by(IDsosci) %&gt;% mutate(verh1_within = verh1 - mean(verh1)) %&gt;% ungroup() %&gt;% gather(transformation, value, -IDsosci, -wave) %&gt;% ggplot(aes(wave, value, group = IDsosci)) + geom_line(position = position_jitter(width = 0, height = 0.3), show.legend = FALSE, alpha = 0.5) + facet_wrap(&quot;transformation&quot;) Die Abbildung verdeutlicht dies anhand von 100 zufällig ausgewählten Personen aus dem Datensatz. Vor der Transformation gibt es (etwas) Varianz im Level des berichteten Verhaltens zwischen den Personen. Durch die Transformation verschwinden diese Unterschiede, es bleibt nur die Variation innhalb der Personen über die Zeit. Das gleiche gilt für Prädiktoren, die als Merkmale anderer Einheiten, die wir als fixed effects spezifiziert haben, konstant sind. In diesem Beispiel wären dies Eigenschaften der Perioden, also z.B. neue Schutzmaßnahmen bzw. deren Lockerung, soweit sie alle Personen gleichermaßen im gleichen Zeitraum betreffen. Interaktionen mit Personenmerkmalen Wir können jedoch Interaktionen zwischen über die Zeit variierenden Prädiktoren und Personenmerkmalen (oder Merkmalen anderer fixed effects Einheiten) ins Modell aufnehmen. Bei kategoriellen Moderator-Variablen erhalten wir Schätzer der Unterschiede zwischen gruppenspezifischen Effekten, z.B. den Unterschied zwischen den Effekten der Verhaltensintention auf das Verhalten für Frauen und Männer. Bei kontinuierlichen Moderator-Variablen gelten die üblichen Fallstricke: Der Koeffizient des Prädiktors ist nun der einfache Effekt für den Fall, dass der Moderator gleich 0 ist. Der Koeffizient des Interaktionsterms quantifiziert den Unterschied des Effekts zwischen zwei Personen, die sich auf dem Moderator um eine Einheit unterscheiden. d %&gt;% plm(verh1 ~ verhint1 * C_sex + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;within&quot;) %&gt;% tidy() %&gt;% mutate_if(is.numeric, round, 2) ## # A tibble: 5 x 5 ## term estimate std.error statistic p.value ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 verhint1 0.34 0.03 13.2 0 ## 2 factor(wave)2 0.02 0.03 0.59 0.55 ## 3 factor(wave)3 0.14 0.03 4.14 0 ## 4 factor(wave)4 0.12 0.03 3.42 0 ## 5 verhint1:C_sex -0.01 0.03 -0.39 0.7 Der Effekt ist in der Stichprobe für Frauen minimal schwächer als für Männer. Der Unterschied ist jedoch weder substantiell noch statistisch bedeutsam. 3.4 Conclusio: Vor- und Nachteile des fixed effects Modells In many applications the whole point of using panel data is to allow for \\(a_i\\) to be arbitrarily correlated with the \\(x_{it}\\). A fixed effects analysis achieves this purpose explicitly. — Wooldridge (2010), S. 300 By controlling out context, FE models effectively cut out much of what is going on — goings-on that are usually of interest to the researcher, the reader and the policy maker. We contend that models that control out, rather than explicitly model, context and heterogeneity offer overly simplistic and impoverished results that can lead to misleading interpretations. — Bell and Jones (2015), S. 134 Das fixed effects Modell ist nützlich, wenn wir einen kausalen Effekt, der sich innerhalb von Einheiten (Personen) abspielt, schätzen wollen. Das fixed effects Modell kann keine Merkmale der Einheiten (Personen) als Prädiktoren berücksichtigen, da die gesamten einheiten(personen)spezifischen Unterschiede bereits durch die fixed effects erklärt werden. Wir interessieren uns aber häufig (auch) für die Unterschiede zwischen Einheiten (Personen). Das fixed effects Modell macht Antworten auf solche Fragen unmöglich. Ein weiterer, damit unverbundener Nachteil des fixed effects Modells ist die starke Anfälligkeit für Messfehler. Die Transformation verringert die wahre Varianz deutlich, während große Teile der Messfehlervarianz erhalten bleiben (sie sind nicht personenspezifisch). 3.5 Übungsaufgaben 2 Schätze den kausalen Effekt der Informationshäufigkeit aus öffentlich-rechtlichen TV-Programmen (med2) auf die Intention, weniger als 1.5m Abstand zu einer Person zu halten, die nicht im eigenen Haushalt lebt (verhint3). Berücksichtige dabei auch die Periodeneffekte der Panelwellen. Siehe dazu auch Übung 1. Verwende jetzt plm für die Schätzung. Nimm zusätzlich die Information aus Zeitungen und Zeitschriften (med1) in das Modell auf. Prüfe, ob sich der Effekt der Information aus Zeitungen und Zeitschriften nach Geschlecht (C_sex) unterscheidet. Spezifiziere, schätze und interpretiere ein eigenes fixed effects Modell mit Daten aus dem Beispieldatensatz. Nutze dabei alle Techniken (unterschiedliche Spezifikation, Standardfehler, Moderation, mehrere Prädiktoren), die du ausprobieren und zu denen du ggf. Fragen stellen willst. Literatur "],
["random-effects-modelle.html", "Abschnitt 4 Random effects Modelle 4.1 Einführung: Random effects Modelle für Paneldaten 4.2 Random effects Modelle mit plm 4.3 Kurze Einführung zu mixed effects Modellen 4.4 Übungsaufgaben 3", " Abschnitt 4 Random effects Modelle In diesem Abschnitt beschäftigen wir uns mit random effects Modellen. Zuerst führen wir die Modellklasse ein. Dann betrachten wir kurz, wie die Modelle in der Tradition der Ökonometrie mit plm spezifiziert werden können, bevor wir zur allgemeineren Umsetzung mit dem Paket für Mehrebenen- bzw. mixed effects Modelle lme4 kommen. 4.1 Einführung: Random effects Modelle für Paneldaten Modellspezifikation Anstatt für jede Einheit (Person) eine separate Konstante \\(\\alpha_i\\) zu schätzen, können wir den “soft constraint” (Gelman and Hill 2006, S. 257) setzen, dass die personenspezifischen Konstanten bzw. Residuen einer Verteilung folgen: \\(\\alpha_{i} ∼ \\mathcal{N}(\\mu_{\\alpha},\\sigma^2_\\alpha)\\) mit \\(i = 1,...,n\\) Das random effects Panel-Modell wird geschätzt als \\(y_{it}=x_{it}&#39;\\beta + z_i&#39;\\gamma + v_{it}\\) \\(v_{it} = \\alpha_{i} + u_{it}\\) mit \\(y_{it}\\) über Personen (\\(i\\)) und Zeit (\\(t\\)) variierendes Kriterium, \\(x_{it}&#39;\\) über Personen und Zeit variierende Prädiktoren, \\(\\beta\\) Koeffizienten der über Personen und Zeit variierenden Prädiktoren, \\(z_i&#39;\\) über Personen variierende Prädiktoren, \\(\\gamma\\) Koeffizienten der über Personen variierenden Prädiktoren, \\(v_{it}\\) gesamter Fehlerterm, \\(\\alpha_{i}\\) personenspezifische Konstanten, \\(u_{it}\\) Residuen. Damit die Schätzer für \\(\\beta&#39;\\) unverzerrt sind, müssen zwei Annahmen erfüllt sein: Keine über die Zeit konstante Heterogenität, deren Ursache nicht im Modell ist \\({\\displaystyle \\operatorname {E} (\\alpha _{i}|x_{it})=\\operatorname {E} (\\alpha _{i})=0}\\) Keine über die Zeit variierende Heterogenität, deren Ursache nicht im Modell ist \\({\\displaystyle \\operatorname {E} (u_{it}|x_{it},\\alpha _{i})=0,\\quad t=1,...,T.}\\) Vorteile der random effects Modelle für Panel-Daten Schätzer für über die Zeit konstante Prädiktoren und gleichzeitig Konstante für jede Person. Schätzer von über die Zeit variierenden und über die Zeit konstanten Prädiktoren können verglichen werden. Vorhersagen für neue Personen außerhab der Stichprobe können unter Einbeziehung aller Informationen und unter Berücksichtigung der gesamten Unsicherheit gemacht werden. Die Annahme honogener Treatment-Effekte kann gelockert werden (mit dem within-between-Modell; siehe nächsten Abschnitt). Sind die Annahmen des random effects Modell für Paneldaten jemals erfüllt? The only difference between RE and FE lies in the assumption they make about the relationship between υ and the observed predictors: RE models assume that the observed predictors in the model are not correlated with \\(v\\) while FE models allow them to be correlated. A moment’s reflection on what \\(v\\) represents—–all unmeasured time-constant factors about the respondent—–should lead anyone to realize that the RE assumption is heroic in social research, to say the least. The idea that the characteristics we don’t (or can’t) measure (like personality or genetic influences) are uncorrelated with the things we usually do measure (like income or church attendance) is implausible. — Vaisey and Miles (2017), S. 47 Hausman-Test Der Hausman-Test prüft, ob das random effects Modell konsistent ist (~ geschätzt werden darf). Nach der traditionellen Sichtweise der Ökonometrie spricht das Verwerfen der \\(H_0\\) im Hausman-Test gegen das Schätzen eines random effects Modells. Da das random effecs Modell in der Lage ist, Forschungsfragen zu beantworten, an denen das fixed effects Modell per Definition scheitert, lässt sich die Wahl des random effects Modells auch inhaltlich begründen — ohne einen Hausman-Test durchzuführen. Der Hausman-Test kann mit der Funktion plm::phtest() durchgeführt werden. phtest(verh1 ~ verhint1, data = d, index = &quot;IDsosci&quot;) ## ## Hausman Test ## ## data: verh1 ~ verhint1 ## chisq = 300.58, df = 1, p-value &lt; 2.2e-16 ## alternative hypothesis: one model is inconsistent In diesem Beispiel spricht der Hausman-Test dagegen, ein random effects Modell zu schätzen. 4.2 Random effects Modelle mit plm Random effects Modelle für Paneldaten in der ökonometrischen Tradition lassen sich mit plm schätzen. Die Schätzung erfolgt auf Basis von Transformationen im Least-squares-Framework (ich habe keine Ahnung, wie das funktioniert). Ich selbst nutze diese Funktionalität in der Praxis nicht. Die Modellspezifikationen sind im Folgenden der Vollständigkeit halber kurz aufgeführt. # Einfaches RE Modell d %&gt;% plm(verh1 ~ verhint1, data = ., index = &quot;IDsosci&quot;, model = &quot;random&quot;) %&gt;% summary() ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., model = &quot;random&quot;, index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.32064 0.56625 0.812 ## individual 0.07443 0.27283 0.188 ## theta: 0.2799 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.444787 -0.105500 -0.072748 0.038935 3.647334 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.56905 0.02764 20.587 &lt; 2.2e-16 *** ## verhint1 0.53198 0.01195 44.517 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1531.9 ## Residual Sum of Squares: 823.22 ## R-Squared: 0.46262 ## Adj. R-Squared: 0.46239 ## Chisq: 1981.77 on 1 DF, p-value: &lt; 2.22e-16 # Mit zusätzlichem Faktor Welle d %&gt;% plm(verh1 ~ verhint1, data = ., index = c(&quot;IDsosci&quot;, &quot;wave&quot;), model = &quot;random&quot;, effect = &quot;twoways&quot;) %&gt;% summary() ## Twoways effects Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1, data = ., effect = &quot;twoways&quot;, ## model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;)) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.316542 0.562621 0.802 ## individual 0.075459 0.274699 0.191 ## time 0.002634 0.051326 0.007 ## theta: 0.2845 (id) 0.5845 (time) 0.2541 (total) ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.479856 -0.114351 -0.069742 0.041790 3.672248 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.572357 0.038978 14.684 &lt; 2.2e-16 *** ## verhint1 0.530146 0.012141 43.666 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1494.2 ## Residual Sum of Squares: 817.26 ## R-Squared: 0.45304 ## Adj. R-Squared: 0.4528 ## Chisq: 1906.68 on 1 DF, p-value: &lt; 2.22e-16 # Mit FE für Welle d %&gt;% plm(verh1 ~ verhint1 + factor(wave), data = ., index = &quot;IDsosci&quot;, model = &quot;random&quot;) %&gt;% summary() ## Oneway (individual) effect Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1 + factor(wave), data = ., model = &quot;random&quot;, ## index = &quot;IDsosci&quot;) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.31654 0.56262 0.808 ## individual 0.07546 0.27470 0.192 ## theta: 0.2845 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.504920 -0.134512 -0.067223 0.050991 3.693574 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.5664150 0.0330635 17.1311 &lt; 2e-16 *** ## verhint1 0.5300058 0.0121863 43.4918 &lt; 2e-16 *** ## factor(wave)2 -0.0453317 0.0353413 -1.2827 0.19960 ## factor(wave)3 0.0672896 0.0353937 1.9012 0.05728 . ## factor(wave)4 0.0028266 0.0358023 0.0789 0.93707 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1521.3 ## Residual Sum of Squares: 816.62 ## R-Squared: 0.46322 ## Adj. R-Squared: 0.46229 ## Chisq: 1983.94 on 4 DF, p-value: &lt; 2.22e-16 # Mit Prädiktor auf Personenebene (funktioniert nicht in FE, siehe oben) d %&gt;% plm(verh1 ~ verhint1 + C_sex, data = ., index = c(&quot;IDsosci&quot;, &quot;wave&quot;), model = &quot;random&quot;, effect = &quot;twoways&quot;) %&gt;% summary() ## Twoways effects Random Effect Model ## (Swamy-Arora&#39;s transformation) ## ## Call: ## plm(formula = verh1 ~ verhint1 + C_sex, data = ., effect = &quot;twoways&quot;, ## model = &quot;random&quot;, index = c(&quot;IDsosci&quot;, &quot;wave&quot;)) ## ## Balanced Panel: n = 576, T = 4, N = 2304 ## ## Effects: ## var std.dev share ## idiosyncratic 0.316542 0.562621 0.803 ## individual 0.074785 0.273468 0.190 ## time 0.002634 0.051326 0.007 ## theta: 0.283 (id) 0.5845 (time) 0.2527 (total) ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -2.443232 -0.153532 -0.048115 0.047936 3.701927 ## ## Coefficients: ## Estimate Std. Error z-value Pr(&gt;|z|) ## (Intercept) 0.642039 0.045454 14.1249 &lt; 2.2e-16 *** ## verhint1 0.527641 0.012153 43.4168 &lt; 2.2e-16 *** ## C_sex -0.106628 0.035587 -2.9963 0.002733 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 1497.8 ## Residual Sum of Squares: 815.06 ## R-Squared: 0.45581 ## Adj. R-Squared: 0.45534 ## Chisq: 1927.32 on 2 DF, p-value: &lt; 2.22e-16 4.3 Kurze Einführung zu mixed effects Modellen Auch bekannt als random effects, multilevel/Mehrebenen- oder hierarchical/hierarchische Modelle; das Begriffswirrwarr ist ein großes Problem, das Denglisch macht es nicht besser (Gelman and Hill 2006). Wer mit diesen Modellen bereits vertraut ist, kann diesen Absatz übersrpingen. Ganz allgemein gesprochen sind mixed effects Modelle Regressionsmodelle für Beobachtungen von Einheiten, die in irgendeiner Art miteinander zu tun haben, also nicht unabhängig voneinander sind. Typische Beispiele sind Schüler*innen in Klassen in Schulen, Patient*innen in Krankenhäusern, Wähler*innen in Wahlkreisen, … . Paneldaten haben immer eine hierarchische Struktur: Beobachtungen (Level 1) sind innerhalb der Personen (Level 2) gruppiert. Die Bezeichnung mixed effects geht darauf zurück, dass in den Modellen sowohl random effects (Koeffizienten, die zwischen den Fällen innerhalb einer Gruppierung auf einer höheren Ebene variieren) als auch fixed effects (Koeffizienten, die für alle Fälle gleich sind) spezifiziert werden. Warum wir in den Sozialwissenschaften nicht nur die traditionellen ökonometrischen Modelle verwenden Econometrics deal mostly with non-experimental data. Great emphasis is put on specification procedures and misspecification testing. Model specifications tend therefore to be very simple, while great attention is put on the issues of endogeneity of the regressors, dependence structures in the errors and robustness of the estimators under deviations from normality. — Croissant and Millo (2008) Historische Gründe und disziplinäre Entwicklungen: z.B. Ökonometriker bevorzugen fast immer Least Squares, andere Disziplinen Maximum Likelihood oder Bayesianische Methoden. Viele Sozialwissenschaften haben kompliziertere Datenstrukturen als das typische ökonometrische Panel, z.B. mehr als zwei Ebenen, nicht-hierarchische Datenstrukturen, heterogene Treatment-Effkte, … . Die flexible Modellierung solcher Strukturen gilt oft als wichtiger als die enger gefassten Schätz- und Identifikationsfragen, die Ökonometriker umtreiben. Die Ökonometrie betrachtet Abhängigkeitsstrukturen als eine Störgröße, deren Einfluss in den Modellen beschränkt werden soll. Andere sozialwissenschaftliche Disziplinen interessieren sich (auch, gerade) für diese Strukturen und ihre Konsequenzen. 4.3.1 Vorteile der mixed effects Modelle Mixed effects Modelle bieten einen einheitlichen Rahmen für die Modellierung von Datensätzen mit jeder Art von Abhängigkeitstrukturen, seien sie hierarchisch, längsschnittlich oder eine Kombination aus beidem. Die Schätzung basiert auf (Restricted) Maximum Likelihood, der Umstieg auf bayesianische Schätzmethoden ist relativ einfach. Im Vergleich dazu erfordern die Optionen, Tests und transformationsbasierten Least-Squares-Schätzer in der ökonometrischen Tradition erheblich mehr Einarbeitung, wenn man nicht auf eine entsprechende Ausbildung aufbauen kann. Wenn man die Logik von mixed effects Modellen einmal verstanden hat, kann man die Modelle für verschiedenste Forschungsfragen und -desings einsetzen, u.a. Ländervergleiche in der komparativen Forschung, experimentelle within-subject Desings, verschiedene Längsschnittsdesigns wie experience sampling, Tagebücher, digitale Kommunikations- und Verhaltensspuren, … . Das Denken in Varianzkomponenten (siehe nächster Absatz) hilft uns, konzeptionell über die Bedeutung von Prädiktoren auf verschiedenen Ebenen nachzudenken. Einfache praktische Umsetzung: Das Paket lme4 ist einfach zu verwenden, wenn man bereits etwas Erfahrung mit stats::lm() hat, und auch ein guter Einstieg in ähnlich aufgebaute Pakte zur bayesianischen Schätzung solcher Modelle (z.B. rstanarm, brms). Varianzdekomposition und Intraklassen-Korrelation Wir interessieren uns dafür, welcher Anteil in der Varianz in \\(Y\\) auf stabile Unterschiede zwischen den Personen zurück geht und welcher auf Veränderungen innerhalb von Personen (potentielle kausale Effekte). In mixed effects Modellen können wir die Varianz-Anteile in einem sogenannten Null-Modell, das nur die Struktur der Daten abbildet, aber keine Prädiktoren enthält, bestimmen: \\(y_{it}= \\alpha + v_{it}\\) und \\(v_{it} = \\alpha_{i}+ u_{it}\\) Ohne die Konstante \\(\\alpha\\) erhalten wir \\(y_{it} = \\alpha_{i}+ u_{it}\\) Da die Varianzen von \\(\\alpha_i\\) und \\(u_{it}\\) im Modell geschätzt werden, können wir den Anteil der personenspezifischen (Level 2) Varianz und den Anteil der idiosynkratischen Varianz in \\(Y\\) berechnen. Der Anteil der Level 2 Varianz an der gesamten Varianz wird auch als Intraklassen-Korrelation (intra-class correlation, ICC, \\(\\rho\\)) bezeichnet. In unserem Beispiel möchten wir wissen, welcher Anteil der Varianz im Verlassen der Wohnung ohne trifftigen Grund auf konstante Unterschiede zwischen den Personen zurückgeht (manche Personen wollen oder müssen, aus welchen Gründen auch immer, die Wohnung häufiger verlassen als andere). Dazu spzifizieren wir das Null-Modell mit lme4::lmer(). Das genaue Vorgehen beim Spezifizieren der Modelle folgt im nächsten Abschnitt. Wichtig ist an dieser Stelle, dass mit (1 | IDsosci) jede Person eine eigene Konstante erhält (\\(\\alpha_i\\) in der Gleichung oben), die als Abweichung vom Gesamtmittel (\\(\\alpha\\)) geschätzt wird. # Null-Modell m0 = d %&gt;% lmer(verh1 ~ 1 + (1 | IDsosci), data = .) m0 %&gt;% summary() ## Linear mixed model fit by REML [&#39;lmerMod&#39;] ## Formula: verh1 ~ 1 + (1 | IDsosci) ## Data: . ## ## REML criterion at convergence: 5576.4 ## ## Scaled residuals: ## Min 1Q Median 3Q Max ## -4.1387 -0.2268 -0.1212 -0.1212 4.8131 ## ## Random effects: ## Groups Name Variance Std.Dev. ## IDsosci (Intercept) 0.5938 0.7706 ## Residual 0.4065 0.6376 ## Number of obs: 2304, groups: IDsosci, 576 ## ## Fixed effects: ## Estimate Std. Error t value ## (Intercept) 1.52865 0.03475 43.99 # ICC &#39;von Hand&#39; round(0.5938/(0.5938 + 0.4065), 3) ## [1] 0.594 # Mit performance::icc() icc(m0) ## # Intraclass Correlation Coefficient ## ## Adjusted ICC: 0.594 ## Conditional ICC: 0.594 # icc(lmer(verh1 ~ 1 + (1 | IDsosci) + (1 | wave), data = d), by_group = TRUE) Die Informationen zu den Varianzkomponenten findet sich im Output von summary() unter Random effects. Aus diesen Angaben können wir die ICC berechnen. Oder wir nutzen die Funktion performance::icc(). Fast 60% der Varianz im Verlassen der Wohnung geht auf Unterschiede zwischen Personen zurück. Im fixed effects Modell wird diese Varianz einfach aus den Daten entfernt. Über mehr als die Hälfte der Unterschiede können wir mit diesen Modellen also per Spezifikationslogik nichts aussagen. Kausale Effekte innerhalb der Personen können damit maximal für 40% der Varianz verantwortlich sein. Allerdings müssen wir dabei beachten, dass auch der gesamte Messfehler (zumindest die zufällige Messfehlervarianz nach der CTT) ebenfalls in diesem Varianzanteil steckt. Wir können die Schätzer der random effects für die Personen im Null-Modell auch dazu nutzen, uns einen Überblick zu verschaffen über die Verteilung der personenspezifischen Tendenz, die Wohnung ohne triftigen Grund zu verlassen. Die Schätzer können wir mit ranef() extrahieren, mit broom.mixed::augment() erhalten wir zusätzlich Standardfehler und Konfidenzintervalle in einem tidy data.frame. # Verteilung der RE als Histogramm m0 %&gt;% ranef() %&gt;% augment(ci.level = 0.95) %&gt;% ggplot(aes(estimate)) + geom_histogram() # RE mit 95%-CIs (aus Darstellungsgründen nur jede fünfte Person) m0 %&gt;% ranef() %&gt;% augment(ci.level = 0.95) %&gt;% slice(seq(1, nrow(.), by = 5)) %&gt;% ggplot(aes(estimate, level, xmin = lb, xmax = ub)) + geom_pointrangeh() + labs(y = &quot;IDsosci&quot;) Der random effects Schätzer quantifziert die Abweichung vom Schätzer der Konstanten in der Gesamtpopulation, hier die Abweichung von 1.5. Die diskreten Werte kommen zustande, da es (wie bei einer Index-Bildung) mit 5 Ausprägungen und 4 Wellen nur eine begrenzte Anzahl an möglichen Personen-Mittelwerten gibt. Die Mehrheit der Personen tendiert dazu, eher selten ihre Wohnung ohne trifftigen Grund zu verlassen. Mehr als ein Gruppierungsfaktor Mit lme4 können prinzipiell beliebig viele und arbiträr angeordnete (sie müssen nicht hierarchisch sein) random effects in ein Modell aufgenommen werden. Zu viele Faktoren oder Faktoren mit zu wenigen Ausprägungen können aber zu Problemen bei der (restricted) maximum likelihood Schätzung führen (Bayesianische Schätzverfahren können hier helfen). Wir könnten z.B. die geographische Region, in der die Personen leben, als einen weiteren, hierarchisch überhalb der Person angesiedelten Faktor aufnehmen. Hätten wir eine sehr große Stichprobe mit ausreichend geographischer Variation, wäre dies spannend, da wir uns durchaus regionale Unterschiede vorstellen könnten. In Panel-Modellen liegt die Idee nahe, random effects für die Panel-Wellen aufzunehmen. Dieser Faktor ist nicht hierarchisch zu den Personen. Stattdessen gehört jede Messung zu genau einer Person und genau einer Welle. Diese Spezifikation wird auch kreuzklassifiziert / cross-classified / crossed genannt. Wir nehmen den Faktor Welle auf, indem wir + (1 | wave) in der Modell-Formel ergänzen. Da wir nur Daten aus vier Wellen haben und die Varianz zwischen den Wellen sehr klein ist, kommt die restricted maximum likelihood Schätzung hier an ihre Grenzen. Eine Warnung wird ausgegeben. Wir könnten das Problem durch Herumfrickeln an den Einstellungen des Optimizer beheben, würden aber inhaltlich zu keiner anderen Schlussfolgerungen kommen. Um den Einstieg in die technischen Details zu vermeiden, verwenden wir hier aber das Modell mit der Warnmeldung. Im Weiteren lösen wir das Problem, indem wir fixed effects für die Wellen aufnehmen. # Null-Modell mit zwei Gruppierungsfaktoren d %&gt;% lmer(verh1 ~ 1 + (1 | IDsosci) + (1 | wave), data = .) %&gt;% icc(by_group = TRUE) ## Warning in checkConv(attr(opt, &quot;derivs&quot;), opt$par, ctrl = control$checkConv, : ## Model failed to converge with max|grad| = 0.00262857 (tol = 0.002, component 1) ## # ICC by Group ## ## Group | ICC ## --------------- ## IDsosci | 0.595 ## wave | 0.018 Nur ein sehr geringer Teil der gesamten Varianz geht auf über alle Personen homogene Veränderungen zwischen den Wellen zurück. 4.4 Übungsaufgaben 3 Analysiere die Varianzkomponenten in der Intention, weniger als 1.5m Abstand zu einer Person zu halten, die nicht im eigenen Haushalt lebt (verhint3). Spezifiziere zuerst ein Modell mit random effects für die Personen. Nimm dann die Welle als zweiten Gruppierungsfaktor auf. Analysiere die Varianzkomponenten in weiteren Variablen, die dich interessieren. Literatur "],
["within-between-models.html", "Abschnitt 5 Within-between models", " Abschnitt 5 Within-between models XXX "],
["literatur.html", "Literatur", " Literatur "]
]
