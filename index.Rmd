--- 
title: "Mini-Workshop Panel Data Analysis"
author: "Marko Bachl (mit Material von Michael Scharkow)"
date: "Sommersemester 2020 | IJK Hannover"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib, packages.bib, references.bib]
biblio-style: apalike
link-citations: yes
description: "Material für den Mini-Workshop Panel Data Analysis"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(scipen = 10, digits = 2)
```

# Überblick

## Inhalt des virtuellen Mini-Workshops

* Der Mini-Workshop bietet eine *pragmatische* Einführung in die Analyse von Panel-Daten aus Erhebungen mit mindestens drei Wellen. Konkret liegt der Fokus auf so genannten *micro panels*, also Datensätzen mit relativ vielen Fällen und relativ wenigen Messzeitpunkten (das klassische Befragungspanel).

* In der Analyse beschränken uns hier auf Varianten der *linearen* Regressionsmodelle. Wir beginnen mit den grundlegenden *fixed effects* und *random effects* Modellen. Dann betrachten wir das *within-between* Modell, das als eine Integration des *fixed effects* Modell in das *random effects* Modell verstanden werden kann. Dies ist auch eine gute Grundlage für den Einstieg in verschiedene Erweiterungen, zum Beispiel zu verallgemeinerten linearen Modellen oder zu Wachstumskurvenmodellen. Diese sind aber nicht Teil dieses Mini-Workshops.

* Wir schätzen die Modelle mit etablierten *least-squares* und *maximum likelihood* Methoden. Gerade bei den *within-between* Modellen sind bayesianische Schätzmethoden, z.B. *MCMC sampling* (implementiert in [Stan](https://mc-stan.org/)), unabhängig von statistisch-philosophischen Überlegungen sehr interessant. Bei Interesse kann ich nur empfehlen, hier einen Einstieg zu finden.

* Zur Aufbereitung der Daten, Visualisierung und Modell-Schätzung verwenden wir `R` mit dem `tidyverse` und eine kleine Zahl spezialisierter Pakete für die Modellschätzung. Der Fokus des Workshops liegt aber auf der substantiellen Arbeit mit den Modellen, nicht auf der Umsetzung in `R`.

## Welche Inhalte wir nicht behandeln

* Der Workshop ist kein Statistik- oder Ökonometrie-Kurs. Ich bin --- wie auch ihr --- ausgebildeter Sozialwissenschaftler. Die statistischen Grundlagen, auf denen der Workshop aufbaut, gehen aus den Grundlagentexten [@bellExplainingFixedEffects2015; @vaiseyWhatYouCan2017] hervor.

* Grundkenntnisse in `R` setze ich voraus, insbesondere Datentransformationen innerhalb des `tidyverse`. Wir werden aber keine komplizierten Dinge in `R` tun. Auch ohne weiterführende `R`-Kenntnisse sollten die Inhalte des Workshops in Bezug auf die datenanalytischen Verfahren klar werden.

* Wir werden nicht viel Zeit auf die verschiedenen Schätzer, deren Effizienz und Bias, die verschiedenen Algorithmen und Datentransformationen verwenden.

* Wir werden keine Beweise oder Ableitungen besprechen. Wir setzen keine Kenntnisse in Matrixalgebra voraus --- weder meiner- noch eurerseits.

* Wir behandeln einen sehr kleinen Ausschnitt möglicher Modelle für Panel-Daten. Wir konzentrieren uns auf regressionsbasierte Modelle zur Schätzung kausaler Effekte. Damit behandeln wir insbesondere nicht die vielfältigen Verfahren, die in einem SEM-Framework verortet sind: längsschnittliche Messmodelle, Prozessmodelle, (random intercept) cross-lagged panel Modelle, Latent State-Trait Modelle, etc. Auch Modelle, in denen die Zeit-Variable als kontinuierlich (z.B. Tag der Erhebung im Gegensatz zu Indikator für Panelwelle) verwendet wird (z.B. Continuous Time Structural Equation Modeling), behandeln wir nicht.

* Fehlende Daten (Panelmortalität, Ausfall von Einheiten in einzelnen Wellen) sind ein großes Thema in der Längsschnittanalyse. Wir werden es hier ignorieren, bis auf den Hinweis, dass alle Fälle, die in mindestens zwei bzw. drei Wellen Daten haben, grundsätzlich Informationen zur Schätzung beitragen.

## Aufbau des Workshops

* Inhaltlicher Aufbau: Siehe Kapitel-Gliederung

### Material {-}

* Dieses Dokument + R Skripte: (Hoffentlich) mehr oder weniger selbsterklärendes Material
  * Kuratierte Form ist dieses HTML-Dokument
  * Es gibt auch ein PDF, das ich aber nicht formatiert habe

* Screencast: Ich gehe über das Material und erkläre es auf der Audio-Spur. Mal sehen, wie hilfreich das ist. Die Screencasts stelle ich über das LMS zur Verfügung.

* Übungen: Zu einigen Analysen gibt es Übungsaufgaben.
  * Bei der *Wiederholung* geht es darum, die Modelle leicht zu verändern (durch Anpassen der `R`-Skripte aus dem Material) und die Ergebnisse der angepassten Modelle zu interpretieren.
  * Bei der *Anwendung* geht es darum, in Anlehnung an die Beispiele eigene Modelle zu spezifizieren und diese zu interpretieren.


### Pakete {-}

Wir verwenden die folgenden Pakete

```{r, echo=FALSE, cache=FALSE}
knitr::read_chunk("R/packages.R")
```

```{r packages, eval=TRUE, tidy=TRUE, message=FALSE}

```

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```
